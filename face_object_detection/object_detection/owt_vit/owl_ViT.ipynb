{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-11T21:21:06.644251Z",
     "start_time": "2025-06-11T21:20:35.598688Z"
    }
   },
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "OWL-ViT Implementation for Digital Forensics\n",
    "Open-World Localization with Vision Transformer for text-based evidence detection\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "from transformers import OwlViTProcessor, OwlViTForObjectDetection\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from pathlib import Path\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# Installation requirements:\n",
    "# pip install transformers torch pillow matplotlib\n",
    "\n",
    "# =============================================================================\n",
    "# CONFIGURATION\n",
    "# =============================================================================\n",
    "\n",
    "CONFIG = {\n",
    "    # Input/Output Paths\n",
    "    'input_folder': '../datasets/images/objects/raw',           # Folder with evidence images\n",
    "    'output_folder': '../datasets/images/objects/detection',  # Output folder for results\n",
    "    'single_image_path': \"../datasets/images/objects/raw/knife_161.jpg\",                               # Path for single image analysis\n",
    "\n",
    "    # Model Configuration\n",
    "    'model_name': 'google/owlvit-base-patch32',              # owlvit-base-patch32, owlvit-base-patch16, owlvit-large-patch14\n",
    "    'confidence_threshold': 0.15,                           # Minimum confidence for detections\n",
    "    'device': 'auto',                                       # 'auto', 'cuda', 'cpu'\n",
    "\n",
    "    # Search Configuration\n",
    "    'search_mode': 'comprehensive',                         # 'comprehensive', 'targeted', 'custom'\n",
    "    'custom_queries': [],                                   # Custom search queries (for custom mode)\n",
    "    'target_categories': ['weapons', 'drugs', 'money'],     # Categories to search (for targeted mode)\n",
    "\n",
    "    # Forensic Analysis Settings\n",
    "    'priority_threshold': 7.0,                             # Minimum score for high priority findings\n",
    "    'enable_threat_assessment': True,                      # Enable threat level assessment\n",
    "    'save_detailed_analysis': True,                       # Save detailed forensic analysis\n",
    "\n",
    "    # Processing Options\n",
    "    'batch_processing': True,                              # Enable batch processing\n",
    "    'max_images': None,                                    # Maximum images to process (None = all)\n",
    "    'show_progress': True,                                 # Show progress information\n",
    "    'create_investigation_report': True,                   # Create comprehensive investigation report\n",
    "\n",
    "    # Output Options\n",
    "    'save_visualizations': True,                          # Save detection visualizations\n",
    "    'save_json_reports': True,                            # Save JSON analysis reports\n",
    "    'visualization_dpi': 300,                             # DPI for saved visualizations\n",
    "    'include_confidence_scores': True,                    # Include confidence scores in outputs\n",
    "\n",
    "    # Forensic Search Queries by Category\n",
    "    'forensic_queries': {\n",
    "        'weapons': [\n",
    "            \"gun\", \"pistol\", \"rifle\", \"firearm\", \"weapon\",\n",
    "            \"knife\", \"blade\", \"sword\", \"machete\", \"dagger\",\n",
    "            \"brass knuckles\", \"baton\", \"club\", \"taser\",\n",
    "            \"modified weapon\", \"sawed-off shotgun\"\n",
    "        ],\n",
    "        'drugs': [\n",
    "            \"white powder\", \"pills\", \"tablets\", \"capsules\",\n",
    "            \"syringe\", \"needle\", \"drug paraphernalia\", \"pipe\", \"bong\",\n",
    "            \"scale\", \"drug scale\", \"baggies with drugs\", \"marijuana\",\n",
    "            \"cocaine powder\", \"heroin\", \"methamphetamine\", \"drug lab equipment\"\n",
    "        ],\n",
    "        'money': [\n",
    "            \"stack of money\", \"cash bundle\", \"hundred dollar bills\",\n",
    "            \"large amount of money\", \"currency\", \"banknotes\",\n",
    "            \"money counting machine\", \"briefcase with money\", \"cash in bags\"\n",
    "        ],\n",
    "        'electronics': [\n",
    "            \"cell phone\", \"smartphone\", \"laptop computer\", \"tablet\",\n",
    "            \"hard drive\", \"USB drive\", \"memory card\", \"SIM card\",\n",
    "            \"gaming console\", \"router\", \"burner phone\", \"encrypted device\"\n",
    "        ],\n",
    "        'documents': [\n",
    "            \"passport\", \"driver license\", \"identity card\", \"fake ID\",\n",
    "            \"credit card\", \"forged document\", \"bank statement\",\n",
    "            \"legal document\", \"counterfeit passport\", \"birth certificate\"\n",
    "        ],\n",
    "        'containers': [\n",
    "            \"suitcase\", \"duffel bag\", \"backpack\", \"briefcase\",\n",
    "            \"safe\", \"lockbox\", \"hidden compartment\", \"secret stash\",\n",
    "            \"weapon case\", \"drug packaging\", \"evidence bag\"\n",
    "        ],\n",
    "        'tools': [\n",
    "            \"lock picking tools\", \"crowbar\", \"bolt cutters\", \"drill\",\n",
    "            \"saw\", \"hacking device\", \"surveillance equipment\",\n",
    "            \"wiretapping device\", \"burglary tools\", \"break-in tools\"\n",
    "        ],\n",
    "        'vehicles': [\n",
    "            \"getaway car\", \"motorcycle\", \"stolen vehicle\", \"van\",\n",
    "            \"truck with hidden compartment\", \"modified vehicle\"\n",
    "        ]\n",
    "    },\n",
    "\n",
    "    # Priority scoring weights for different categories\n",
    "    'category_weights': {\n",
    "        'weapons': 9.0,\n",
    "        'drugs': 8.0,\n",
    "        'money': 6.0,\n",
    "        'tools': 7.0,\n",
    "        'electronics': 5.0,\n",
    "        'documents': 6.0,\n",
    "        'containers': 4.0,\n",
    "        'vehicles': 5.0\n",
    "    },\n",
    "\n",
    "    # Supported image formats\n",
    "    'supported_formats': {'.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.webp'}\n",
    "}\n",
    "\n",
    "class ForensicOWLViT:\n",
    "    def __init__(self, config=None):\n",
    "        \"\"\"Initialize OWL-ViT model with configuration\"\"\"\n",
    "        self.config = config or CONFIG\n",
    "\n",
    "        # Load model and processor\n",
    "        self.processor = OwlViTProcessor.from_pretrained(self.config['model_name'])\n",
    "        self.model = OwlViTForObjectDetection.from_pretrained(self.config['model_name'])\n",
    "\n",
    "        # Set device\n",
    "        if self.config['device'] == 'auto':\n",
    "            self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        else:\n",
    "            self.device = self.config['device']\n",
    "        self.model.to(self.device)\n",
    "\n",
    "        # Create output directories\n",
    "        self._setup_output_directories()\n",
    "\n",
    "        if self.config['show_progress']:\n",
    "            print(f\"üéØ OWL-ViT Forensic Analyzer initialized\")\n",
    "            print(f\"   Model: {self.config['model_name']}\")\n",
    "            print(f\"   Device: {self.device}\")\n",
    "            print(f\"   Search mode: {self.config['search_mode']}\")\n",
    "            print(f\"   Confidence threshold: {self.config['confidence_threshold']}\")\n",
    "\n",
    "    def analyze_single_image(self, image_path=None):\n",
    "        \"\"\"Analyze a single image for forensic evidence\"\"\"\n",
    "        image_path = image_path or self.config['single_image_path']\n",
    "        if not image_path:\n",
    "            raise ValueError(\"No image path provided\")\n",
    "\n",
    "        if self.config['show_progress']:\n",
    "            print(f\"üîç Analyzing: {Path(image_path).name}\")\n",
    "\n",
    "        # Get search queries based on mode\n",
    "        search_queries = self._get_search_queries()\n",
    "\n",
    "        # Perform search\n",
    "        analysis = self._search_image(image_path, search_queries)\n",
    "\n",
    "        # Enhanced forensic analysis\n",
    "        if self.config['save_detailed_analysis']:\n",
    "            analysis = self._enhance_forensic_analysis(analysis)\n",
    "\n",
    "        # Save outputs\n",
    "        if self.config['save_json_reports']:\n",
    "            self._save_analysis_report(analysis, single_image=True)\n",
    "\n",
    "        if self.config['save_visualizations']:\n",
    "            self._create_visualization(analysis, search_queries)\n",
    "\n",
    "        return analysis\n",
    "\n",
    "    def analyze_batch(self):\n",
    "        \"\"\"Analyze all images in the input folder\"\"\"\n",
    "        input_path = Path(self.config['input_folder'])\n",
    "        if not input_path.exists():\n",
    "            raise FileNotFoundError(f\"Input folder not found: {input_path}\")\n",
    "\n",
    "        # Get image files\n",
    "        image_files = self._get_image_files(input_path)\n",
    "\n",
    "        if self.config['max_images']:\n",
    "            image_files = image_files[:self.config['max_images']]\n",
    "\n",
    "        if self.config['show_progress']:\n",
    "            print(f\"üìÅ Processing {len(image_files)} images from {input_path}\")\n",
    "\n",
    "        batch_results = []\n",
    "        high_priority_findings = []\n",
    "        search_queries = self._get_search_queries()\n",
    "\n",
    "        for i, image_file in enumerate(image_files, 1):\n",
    "            if self.config['show_progress']:\n",
    "                print(f\"   [{i}/{len(image_files)}] {image_file.name}\")\n",
    "\n",
    "            try:\n",
    "                analysis = self._analyze_image_file(image_file, search_queries)\n",
    "                batch_results.append(analysis)\n",
    "\n",
    "                # Check for high-priority findings\n",
    "                if analysis.get('threat_assessment', {}).get('priority_score', 0) >= self.config['priority_threshold']:\n",
    "                    high_priority_findings.append(analysis)\n",
    "\n",
    "            except Exception as e:\n",
    "                if self.config['show_progress']:\n",
    "                    print(f\"      ‚ùå Error: {e}\")\n",
    "\n",
    "        # Create comprehensive report\n",
    "        investigation_report = self._create_investigation_report(batch_results, high_priority_findings, search_queries)\n",
    "\n",
    "        # Save outputs\n",
    "        if self.config['save_json_reports']:\n",
    "            self._save_batch_results(batch_results, investigation_report)\n",
    "\n",
    "        if self.config['show_progress']:\n",
    "            print(f\"‚úÖ Investigation complete!\")\n",
    "            print(f\"   Total processed: {len(batch_results)}\")\n",
    "            print(f\"   High priority: {len(high_priority_findings)}\")\n",
    "            print(f\"   Results saved to: {self.config['output_folder']}\")\n",
    "\n",
    "        return {\n",
    "            'batch_results': batch_results,\n",
    "            'investigation_report': investigation_report,\n",
    "            'high_priority_findings': high_priority_findings\n",
    "        }\n",
    "\n",
    "    def custom_investigation(self, image_path, custom_queries):\n",
    "        \"\"\"Perform custom investigation with user-defined queries\"\"\"\n",
    "        if self.config['show_progress']:\n",
    "            print(f\"üïµÔ∏è Custom investigation: {len(custom_queries)} search terms\")\n",
    "            for i, query in enumerate(custom_queries, 1):\n",
    "                print(f\"  {i}. '{query}'\")\n",
    "\n",
    "        analysis = self._search_image(image_path, custom_queries)\n",
    "        analysis['investigation_type'] = 'custom'\n",
    "        analysis['custom_queries'] = custom_queries\n",
    "\n",
    "        if self.config['save_detailed_analysis']:\n",
    "            analysis = self._enhance_forensic_analysis(analysis)\n",
    "\n",
    "        # Save results\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        if self.config['save_json_reports']:\n",
    "            filename = f\"custom_investigation_{timestamp}.json\"\n",
    "            output_file = Path(self.config['output_folder']) / 'custom_investigations' / filename\n",
    "            output_file.parent.mkdir(parents=True, exist_ok=True)\n",
    "            with open(output_file, 'w') as f:\n",
    "                json.dump(analysis, f, indent=2)\n",
    "\n",
    "            if self.config['show_progress']:\n",
    "                print(f\"üìÑ Investigation saved: {output_file}\")\n",
    "\n",
    "        return analysis\n",
    "\n",
    "    def _get_search_queries(self):\n",
    "        \"\"\"Get search queries based on configured mode\"\"\"\n",
    "        if self.config['search_mode'] == 'custom':\n",
    "            return self.config['custom_queries']\n",
    "\n",
    "        elif self.config['search_mode'] == 'targeted':\n",
    "            queries = []\n",
    "            for category in self.config['target_categories']:\n",
    "                if category in self.config['forensic_queries']:\n",
    "                    queries.extend(self.config['forensic_queries'][category])\n",
    "            return queries\n",
    "\n",
    "        elif self.config['search_mode'] == 'comprehensive':\n",
    "            queries = []\n",
    "            for category_queries in self.config['forensic_queries'].values():\n",
    "                queries.extend(category_queries)\n",
    "            return queries\n",
    "\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown search mode: {self.config['search_mode']}\")\n",
    "\n",
    "    def _search_image(self, image_path, search_queries):\n",
    "        \"\"\"Search for specific items in image using text queries\"\"\"\n",
    "        # Load and process image\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "\n",
    "        # Prepare inputs\n",
    "        inputs = self.processor(text=search_queries, images=image, return_tensors=\"pt\")\n",
    "        inputs = {k: v.to(self.device) for k, v in inputs.items()}\n",
    "\n",
    "        # Run detection\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(**inputs)\n",
    "\n",
    "        # Process results\n",
    "        target_sizes = torch.Tensor([image.size[::-1]]).to(self.device)\n",
    "        results = self.processor.post_process_object_detection(\n",
    "            outputs=outputs,\n",
    "            target_sizes=target_sizes,\n",
    "            threshold=self.config['confidence_threshold']\n",
    "        )\n",
    "\n",
    "        detections = []\n",
    "        for i, query in enumerate(search_queries):\n",
    "            boxes = results[0][\"boxes\"][results[0][\"labels\"] == i]\n",
    "            scores = results[0][\"scores\"][results[0][\"labels\"] == i]\n",
    "\n",
    "            for box, score in zip(boxes, scores):\n",
    "                if score >= self.config['confidence_threshold']:\n",
    "                    detections.append({\n",
    "                        'query': query,\n",
    "                        'bbox': box.cpu().numpy().tolist(),\n",
    "                        'confidence': float(score.cpu().numpy()),\n",
    "                        'query_index': i,\n",
    "                        'category': self._get_query_category(query)\n",
    "                    })\n",
    "\n",
    "        return {\n",
    "            'image_path': str(image_path),\n",
    "            'timestamp': datetime.now().isoformat(),\n",
    "            'search_queries': search_queries,\n",
    "            'search_mode': self.config['search_mode'],\n",
    "            'detections': detections,\n",
    "            'image_size': image.size,\n",
    "            'total_detections': len(detections),\n",
    "            'config_used': {\n",
    "                'model_name': self.config['model_name'],\n",
    "                'confidence_threshold': self.config['confidence_threshold']\n",
    "            }\n",
    "        }\n",
    "\n",
    "    def _enhance_forensic_analysis(self, analysis):\n",
    "        \"\"\"Add enhanced forensic analysis to results\"\"\"\n",
    "        detections = analysis['detections']\n",
    "\n",
    "        # Group detections by category\n",
    "        category_analysis = {}\n",
    "        for detection in detections:\n",
    "            category = detection['category']\n",
    "            if category not in category_analysis:\n",
    "                category_analysis[category] = {\n",
    "                    'count': 0,\n",
    "                    'max_confidence': 0,\n",
    "                    'items': []\n",
    "                }\n",
    "\n",
    "            category_analysis[category]['count'] += 1\n",
    "            category_analysis[category]['max_confidence'] = max(\n",
    "                category_analysis[category]['max_confidence'],\n",
    "                detection['confidence']\n",
    "            )\n",
    "            category_analysis[category]['items'].append(detection['query'])\n",
    "\n",
    "        # Calculate threat assessment\n",
    "        threat_assessment = self._calculate_threat_assessment(category_analysis)\n",
    "\n",
    "        # Add enhanced analysis\n",
    "        analysis.update({\n",
    "            'category_analysis': category_analysis,\n",
    "            'threat_assessment': threat_assessment,\n",
    "            'evidence_summary': self._create_evidence_summary(category_analysis),\n",
    "            'recommendations': self._generate_recommendations(category_analysis, threat_assessment)\n",
    "        })\n",
    "\n",
    "        return analysis\n",
    "\n",
    "    def _calculate_threat_assessment(self, category_analysis):\n",
    "        \"\"\"Calculate comprehensive threat assessment\"\"\"\n",
    "        priority_score = 0\n",
    "        threat_indicators = []\n",
    "\n",
    "        for category, data in category_analysis.items():\n",
    "            # Base score from category weight and detection confidence\n",
    "            if category in self.config['category_weights']:\n",
    "                weight = self.config['category_weights'][category]\n",
    "                confidence_bonus = data['max_confidence'] * 2\n",
    "                count_bonus = min(data['count'] * 0.5, 2.0)  # Cap count bonus\n",
    "\n",
    "                category_score = (weight + confidence_bonus + count_bonus)\n",
    "                priority_score += category_score\n",
    "\n",
    "                threat_indicators.append({\n",
    "                    'category': category,\n",
    "                    'severity': self._get_severity_level(weight),\n",
    "                    'count': data['count'],\n",
    "                    'confidence': data['max_confidence'],\n",
    "                    'score_contribution': category_score\n",
    "                })\n",
    "\n",
    "        # Determine overall threat level\n",
    "        if priority_score >= 20:\n",
    "            threat_level = \"CRITICAL\"\n",
    "        elif priority_score >= 15:\n",
    "            threat_level = \"HIGH\"\n",
    "        elif priority_score >= 8:\n",
    "            threat_level = \"MEDIUM\"\n",
    "        elif priority_score >= 3:\n",
    "            threat_level = \"LOW\"\n",
    "        else:\n",
    "            threat_level = \"MINIMAL\"\n",
    "\n",
    "        return {\n",
    "            'threat_level': threat_level,\n",
    "            'priority_score': min(priority_score, 10.0),\n",
    "            'threat_indicators': threat_indicators,\n",
    "            'assessment_timestamp': datetime.now().isoformat()\n",
    "        }\n",
    "\n",
    "    def _get_severity_level(self, weight):\n",
    "        \"\"\"Get severity level based on category weight\"\"\"\n",
    "        if weight >= 8:\n",
    "            return \"CRITICAL\"\n",
    "        elif weight >= 6:\n",
    "            return \"HIGH\"\n",
    "        elif weight >= 4:\n",
    "            return \"MEDIUM\"\n",
    "        else:\n",
    "            return \"LOW\"\n",
    "\n",
    "    def _get_query_category(self, query):\n",
    "        \"\"\"Determine which category a query belongs to\"\"\"\n",
    "        for category, queries in self.config['forensic_queries'].items():\n",
    "            if query in queries:\n",
    "                return category\n",
    "        return 'unknown'\n",
    "\n",
    "    def _create_evidence_summary(self, category_analysis):\n",
    "        \"\"\"Create summary of evidence found\"\"\"\n",
    "        summary = {\n",
    "            'categories_detected': list(category_analysis.keys()),\n",
    "            'total_evidence_items': sum(data['count'] for data in category_analysis.values()),\n",
    "            'highest_confidence_category': max(\n",
    "                category_analysis.items(),\n",
    "                key=lambda x: x[1]['max_confidence'],\n",
    "                default=(None, {'max_confidence': 0})\n",
    "            )[0],\n",
    "            'most_items_category': max(\n",
    "                category_analysis.items(),\n",
    "                key=lambda x: x[1]['count'],\n",
    "                default=(None, {'count': 0})\n",
    "            )[0]\n",
    "        }\n",
    "        return summary\n",
    "\n",
    "    def _generate_recommendations(self, category_analysis, threat_assessment):\n",
    "        \"\"\"Generate investigative recommendations\"\"\"\n",
    "        recommendations = []\n",
    "\n",
    "        # High-priority recommendations based on findings\n",
    "        for category in category_analysis:\n",
    "            if category == 'weapons':\n",
    "                recommendations.append(\"URGENT: Secure scene and implement weapon safety protocols\")\n",
    "                recommendations.append(\"Conduct ballistics analysis and weapon tracing\")\n",
    "            elif category == 'drugs':\n",
    "                recommendations.append(\"Implement evidence preservation for substance analysis\")\n",
    "                recommendations.append(\"Consider drug trafficking investigation\")\n",
    "            elif category == 'money':\n",
    "                recommendations.append(\"Financial investigation recommended\")\n",
    "                recommendations.append(\"Check for money laundering indicators\")\n",
    "            elif category == 'electronics':\n",
    "                recommendations.append(\"Digital forensics analysis required\")\n",
    "                recommendations.append(\"Secure devices for data extraction\")\n",
    "\n",
    "        # General recommendations based on threat level\n",
    "        threat_level = threat_assessment['threat_level']\n",
    "        if threat_level in ['CRITICAL', 'HIGH']:\n",
    "            recommendations.append(\"Priority case classification recommended\")\n",
    "            recommendations.append(\"Additional resources and expertise required\")\n",
    "            recommendations.append(\"Consider multi-agency coordination\")\n",
    "\n",
    "        return recommendations\n",
    "\n",
    "    def _analyze_image_file(self, image_file, search_queries):\n",
    "        \"\"\"Analyze single image file\"\"\"\n",
    "        analysis = self._search_image(str(image_file), search_queries)\n",
    "\n",
    "        if self.config['save_detailed_analysis']:\n",
    "            analysis = self._enhance_forensic_analysis(analysis)\n",
    "\n",
    "        # Save individual outputs\n",
    "        if self.config['save_visualizations']:\n",
    "            self._create_visualization(analysis, search_queries)\n",
    "\n",
    "        return analysis\n",
    "\n",
    "    def _create_visualization(self, analysis, search_queries):\n",
    "        \"\"\"Create and save visualization\"\"\"\n",
    "        image_path = analysis['image_path']\n",
    "        image = Image.open(image_path)\n",
    "\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(15, 10))\n",
    "        ax.imshow(image)\n",
    "\n",
    "        # Color mapping for different categories\n",
    "        colors = {\n",
    "            'weapons': 'red',\n",
    "            'drugs': 'purple',\n",
    "            'money': 'green',\n",
    "            'electronics': 'blue',\n",
    "            'documents': 'orange',\n",
    "            'containers': 'brown',\n",
    "            'tools': 'pink',\n",
    "            'vehicles': 'cyan',\n",
    "            'unknown': 'gray'\n",
    "        }\n",
    "\n",
    "        # Draw detections\n",
    "        for detection in analysis['detections']:\n",
    "            bbox = detection['bbox']\n",
    "            query = detection['query']\n",
    "            confidence = detection['confidence']\n",
    "            category = detection.get('category', 'unknown')\n",
    "\n",
    "            color = colors.get(category, 'gray')\n",
    "\n",
    "            # Draw bounding box\n",
    "            rect = patches.Rectangle(\n",
    "                (bbox[0], bbox[1]),\n",
    "                bbox[2] - bbox[0],\n",
    "                bbox[3] - bbox[1],\n",
    "                linewidth=2,\n",
    "                edgecolor=color,\n",
    "                facecolor='none'\n",
    "            )\n",
    "            ax.add_patch(rect)\n",
    "\n",
    "            # Add label\n",
    "            if self.config['include_confidence_scores']:\n",
    "                label = f\"{query}\\n{confidence:.2f}\"\n",
    "            else:\n",
    "                label = query\n",
    "\n",
    "            ax.text(bbox[0], bbox[1] - 10, label,\n",
    "                   bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=color, alpha=0.8),\n",
    "                   fontsize=8, color='white', weight='bold')\n",
    "\n",
    "        # Title with threat assessment if available\n",
    "        title = f\"OWL-ViT Forensic Analysis: {Path(image_path).name}\\n\"\n",
    "        title += f\"{len(analysis['detections'])} detections found\"\n",
    "\n",
    "        if 'threat_assessment' in analysis:\n",
    "            threat = analysis['threat_assessment']\n",
    "            title += f\" | Threat Level: {threat['threat_level']}\"\n",
    "            title += f\" | Priority Score: {threat['priority_score']:.1f}\"\n",
    "\n",
    "        ax.set_title(title)\n",
    "        ax.axis('off')\n",
    "\n",
    "        # Add legend\n",
    "        legend_elements = [patches.Patch(color=color, label=category.title())\n",
    "                          for category, color in colors.items()\n",
    "                          if any(d.get('category') == category for d in analysis['detections'])]\n",
    "        if legend_elements:\n",
    "            ax.legend(handles=legend_elements, loc='upper right', bbox_to_anchor=(1.15, 1))\n",
    "\n",
    "        # Save visualization\n",
    "        output_path = Path(self.config['output_folder']) / 'visualizations'\n",
    "        output_file = output_path / f\"{Path(image_path).stem}_analysis.png\"\n",
    "        plt.savefig(output_file, dpi=self.config['visualization_dpi'], bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "        return str(output_file)\n",
    "\n",
    "    def _create_investigation_report(self, batch_results, high_priority_findings, search_queries):\n",
    "        \"\"\"Create comprehensive investigation report\"\"\"\n",
    "        return {\n",
    "            'investigation_summary': {\n",
    "                'timestamp': datetime.now().isoformat(),\n",
    "                'search_mode': self.config['search_mode'],\n",
    "                'total_images_analyzed': len(batch_results),\n",
    "                'high_priority_cases': len(high_priority_findings),\n",
    "                'search_queries_used': len(search_queries),\n",
    "                'config_used': {\n",
    "                    'model_name': self.config['model_name'],\n",
    "                    'confidence_threshold': self.config['confidence_threshold'],\n",
    "                    'priority_threshold': self.config['priority_threshold']\n",
    "                }\n",
    "            },\n",
    "            'evidence_statistics': self._calculate_evidence_statistics(batch_results),\n",
    "            'threat_analysis': self._analyze_batch_threats(batch_results),\n",
    "            'high_priority_cases': [\n",
    "                {\n",
    "                    'image_path': result['image_path'],\n",
    "                    'threat_level': result.get('threat_assessment', {}).get('threat_level', 'UNKNOWN'),\n",
    "                    'priority_score': result.get('threat_assessment', {}).get('priority_score', 0),\n",
    "                    'categories_found': list(result.get('category_analysis', {}).keys()),\n",
    "                    'total_detections': result['total_detections']\n",
    "                }\n",
    "                for result in high_priority_findings\n",
    "            ],\n",
    "            'search_effectiveness': self._analyze_search_effectiveness(batch_results, search_queries)\n",
    "        }\n",
    "\n",
    "    def _calculate_evidence_statistics(self, batch_results):\n",
    "        \"\"\"Calculate comprehensive evidence statistics\"\"\"\n",
    "        category_totals = {}\n",
    "        total_detections = 0\n",
    "        images_with_evidence = 0\n",
    "\n",
    "        for result in batch_results:\n",
    "            total_detections += result['total_detections']\n",
    "            if result['total_detections'] > 0:\n",
    "                images_with_evidence += 1\n",
    "\n",
    "            category_analysis = result.get('category_analysis', {})\n",
    "            for category, data in category_analysis.items():\n",
    "                if category not in category_totals:\n",
    "                    category_totals[category] = {'count': 0, 'images': 0}\n",
    "                category_totals[category]['count'] += data['count']\n",
    "                category_totals[category]['images'] += 1\n",
    "\n",
    "        return {\n",
    "            'total_detections': total_detections,\n",
    "            'images_with_evidence': images_with_evidence,\n",
    "            'evidence_categories': category_totals,\n",
    "            'detection_rate': images_with_evidence / len(batch_results) if batch_results else 0\n",
    "        }\n",
    "\n",
    "    def _analyze_batch_threats(self, batch_results):\n",
    "        \"\"\"Analyze threat levels across batch\"\"\"\n",
    "        threat_levels = {}\n",
    "        priority_scores = []\n",
    "\n",
    "        for result in batch_results:\n",
    "            threat_assessment = result.get('threat_assessment', {})\n",
    "            level = threat_assessment.get('threat_level', 'MINIMAL')\n",
    "            score = threat_assessment.get('priority_score', 0)\n",
    "\n",
    "            threat_levels[level] = threat_levels.get(level, 0) + 1\n",
    "            priority_scores.append(score)\n",
    "\n",
    "        return {\n",
    "            'threat_level_distribution': threat_levels,\n",
    "            'average_priority_score': sum(priority_scores) / len(priority_scores) if priority_scores else 0,\n",
    "            'max_priority_score': max(priority_scores) if priority_scores else 0,\n",
    "            'critical_threat_percentage': (threat_levels.get('CRITICAL', 0) / len(batch_results)) * 100 if batch_results else 0\n",
    "        }\n",
    "\n",
    "    def _analyze_search_effectiveness(self, batch_results, search_queries):\n",
    "        \"\"\"Analyze effectiveness of different search queries\"\"\"\n",
    "        query_performance = {}\n",
    "\n",
    "        for result in batch_results:\n",
    "            for detection in result['detections']:\n",
    "                query = detection['query']\n",
    "                if query not in query_performance:\n",
    "                    query_performance[query] = {\n",
    "                        'hits': 0,\n",
    "                        'total_confidence': 0,\n",
    "                        'avg_confidence': 0\n",
    "                    }\n",
    "\n",
    "                query_performance[query]['hits'] += 1\n",
    "                query_performance[query]['total_confidence'] += detection['confidence']\n",
    "\n",
    "        # Calculate averages\n",
    "        for query, data in query_performance.items():\n",
    "            if data['hits'] > 0:\n",
    "                data['avg_confidence'] = data['total_confidence'] / data['hits']\n",
    "\n",
    "        # Sort by effectiveness (hits * avg_confidence)\n",
    "        effectiveness_scores = {\n",
    "            query: data['hits'] * data['avg_confidence']\n",
    "            for query, data in query_performance.items()\n",
    "        }\n",
    "\n",
    "        return {\n",
    "            'query_performance': query_performance,\n",
    "            'most_effective_queries': sorted(\n",
    "                effectiveness_scores.items(),\n",
    "                key=lambda x: x[1],\n",
    "                reverse=True\n",
    "            )[:10],\n",
    "            'total_unique_queries_with_hits': len(query_performance),\n",
    "            'query_hit_rate': len(query_performance) / len(search_queries) if search_queries else 0\n",
    "        }\n",
    "\n",
    "    def _save_analysis_report(self, analysis, single_image=False):\n",
    "        \"\"\"Save analysis report to JSON\"\"\"\n",
    "        if single_image:\n",
    "            output_path = Path(self.config['output_folder']) / 'single_analysis'\n",
    "            filename = f\"{Path(analysis['image_path']).stem}_analysis.json\"\n",
    "        else:\n",
    "            output_path = Path(self.config['output_folder']) / 'individual_reports'\n",
    "            filename = f\"{Path(analysis['image_path']).stem}_report.json\"\n",
    "\n",
    "        output_path.mkdir(parents=True, exist_ok=True)\n",
    "        output_file = output_path / filename\n",
    "\n",
    "        with open(output_file, 'w') as f:\n",
    "            json.dump(analysis, f, indent=2)\n",
    "\n",
    "        return str(output_file)\n",
    "\n",
    "    def _save_batch_results(self, batch_results, investigation_report):\n",
    "        \"\"\"Save batch processing results\"\"\"\n",
    "        output_path = Path(self.config['output_folder'])\n",
    "\n",
    "        # Save complete batch results\n",
    "        batch_file = output_path / 'batch_investigation_results.json'\n",
    "        with open(batch_file, 'w') as f:\n",
    "            json.dump(batch_results, f, indent=2)\n",
    "\n",
    "        # Save investigation report\n",
    "        report_file = output_path / 'investigation_report.json'\n",
    "        with open(report_file, 'w') as f:\n",
    "            json.dump(investigation_report, f, indent=2)\n",
    "\n",
    "        if self.config['show_progress']:\n",
    "            print(f\"   üìÑ Batch results: {batch_file}\")\n",
    "            print(f\"   üìã Investigation report: {report_file}\")\n",
    "\n",
    "    def _get_image_files(self, input_path):\n",
    "        \"\"\"Get list of image files from input directory\"\"\"\n",
    "        image_files = []\n",
    "        for file_path in input_path.glob('*'):\n",
    "            if file_path.suffix.lower() in self.config['supported_formats']:\n",
    "                image_files.append(file_path)\n",
    "        return sorted(image_files)\n",
    "\n",
    "    def _setup_output_directories(self):\n",
    "        \"\"\"Create necessary output directories\"\"\"\n",
    "        output_path = Path(self.config['output_folder'])\n",
    "\n",
    "        directories = ['visualizations', 'individual_reports', 'single_analysis', 'custom_investigations']\n",
    "        for directory in directories:\n",
    "            (output_path / directory).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# =============================================================================\n",
    "# MAIN EXECUTION\n",
    "# =============================================================================\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main execution function\"\"\"\n",
    "\n",
    "    # Initialize detector with configuration\n",
    "    detector = ForensicOWLViT(CONFIG)\n",
    "\n",
    "    print(\"=== OWL-ViT Forensic Investigation System ===\")\n",
    "    print(f\"Configuration loaded:\")\n",
    "    print(f\"  Input folder: {CONFIG['input_folder']}\")\n",
    "    print(f\"  Output folder: {CONFIG['output_folder']}\")\n",
    "    print(f\"  Model: {CONFIG['model_name']}\")\n",
    "    print(f\"  Search mode: {CONFIG['search_mode']}\")\n",
    "    print(f\"  Confidence threshold: {CONFIG['confidence_threshold']}\")\n",
    "\n",
    "    # Choose analysis mode\n",
    "    if CONFIG['single_image_path']:\n",
    "        print(\"\\nüñºÔ∏è  Single Image Analysis Mode\")\n",
    "        try:\n",
    "            result = detector.analyze_single_image()\n",
    "            print(f\"‚úÖ Analysis complete!\")\n",
    "            print(f\"   Total detections: {result['total_detections']}\")\n",
    "            if 'threat_assessment' in result:\n",
    "                threat = result['threat_assessment']\n",
    "                print(f\"   Threat level: {threat['threat_level']}\")\n",
    "                print(f\"   Priority score: {threat['priority_score']:.1f}\")\n",
    "            if result.get('category_analysis'):\n",
    "                categories = list(result['category_analysis'].keys())\n",
    "                print(f\"   Evidence categories: {categories}\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error: {e}\")\n",
    "\n",
    "    elif CONFIG['batch_processing']:\n",
    "        print(\"\\nüìÅ Batch Investigation Mode\")\n",
    "        try:\n",
    "            results = detector.analyze_batch()\n",
    "            report = results['investigation_report']\n",
    "            summary = report['investigation_summary']\n",
    "\n",
    "            print(f\"‚úÖ Investigation complete!\")\n",
    "            print(f\"   Images analyzed: {summary['total_images_analyzed']}\")\n",
    "            print(f\"   High priority cases: {summary['high_priority_cases']}\")\n",
    "            print(f\"   Evidence detection rate: {report['evidence_statistics']['detection_rate']:.1%}\")\n",
    "\n",
    "            # Show threat distribution\n",
    "            threat_dist = report['threat_analysis']['threat_level_distribution']\n",
    "            print(f\"   Threat distribution: {threat_dist}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error: {e}\")\n",
    "\n",
    "    elif CONFIG['search_mode'] == 'custom' and CONFIG['custom_queries']:\n",
    "        print(\"\\nüïµÔ∏è Custom Investigation Mode\")\n",
    "        image_path = CONFIG['single_image_path'] or input(\"Enter image path: \")\n",
    "        try:\n",
    "            result = detector.custom_investigation(image_path, CONFIG['custom_queries'])\n",
    "            print(f\"‚úÖ Custom investigation complete!\")\n",
    "            print(f\"   Detections found: {result['total_detections']}\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error: {e}\")\n",
    "\n",
    "    else:\n",
    "        print(\"\\n‚ö†Ô∏è  No analysis mode configured. Please set:\")\n",
    "        print(\"     - CONFIG['single_image_path'] for single image analysis\")\n",
    "        print(\"     - CONFIG['batch_processing'] = True for batch processing\")\n",
    "        print(\"     - CONFIG['search_mode'] = 'custom' with custom_queries for custom investigation\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/392 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "477e8defc7814ebf84b160d1322d2652"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Interpreter\\Python\\Projects\\ai_cyberforensics\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in D:\\Models\\Hugging_Face\\cache_root\\hub\\models--google--owlvit-base-patch32. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/775 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ae523d89e64b4297934573a4012e95f1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.06M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3dbef6009f9e4ee992bbd2942ea19bf8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "merges.txt:   0%|          | 0.00/525k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1f55f0b2c01a4e8fbe5177854e089f35"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/460 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c4d9d8e6897a42e7a9477a62e357f325"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/4.42k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "efd71bad3940433ea727250e524c3334"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/613M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6a7961dbeeb54c4ca54d83a5ab80e0db"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ OWL-ViT Forensic Analyzer initialized\n",
      "   Model: google/owlvit-base-patch32\n",
      "   Device: cpu\n",
      "   Search mode: comprehensive\n",
      "   Confidence threshold: 0.15\n",
      "=== OWL-ViT Forensic Investigation System ===\n",
      "Configuration loaded:\n",
      "  Input folder: ../datasets/images/objects/raw\n",
      "  Output folder: ../datasets/images/objects/detection\n",
      "  Model: google/owlvit-base-patch32\n",
      "  Search mode: comprehensive\n",
      "  Confidence threshold: 0.15\n",
      "\n",
      "üñºÔ∏è  Single Image Analysis Mode\n",
      "üîç Analyzing: knife_161.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Interpreter\\Python\\Projects\\ai_cyberforensics\\.venv\\Lib\\site-packages\\transformers\\models\\owlvit\\processing_owlvit.py:233: FutureWarning: `post_process_object_detection` method is deprecated for OwlVitProcessor and will be removed in v5. Use `post_process_grounded_object_detection` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Analysis complete!\n",
      "   Total detections: 0\n",
      "   Threat level: MINIMAL\n",
      "   Priority score: 0.0\n"
     ]
    }
   ],
   "execution_count": 1
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
