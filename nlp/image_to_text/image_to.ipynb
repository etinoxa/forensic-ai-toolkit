{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import os\n",
    "os.listdir('../../datasets/images/text_ocr')\n"
   ],
   "id": "3ff4156f9d6b5889"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Pure Transformer OCR Image Text Search System\n",
    "import os, json, sqlite3, shutil, warnings, time\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from typing import List, Dict, Any, Optional\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Disable analytics to prevent connection errors\n",
    "os.environ['DISABLE_TELEMETRY'] = '1'\n",
    "os.environ['HF_HUB_DISABLE_TELEMETRY'] = '1'\n",
    "os.environ['HUB_ANALYTICS'] = 'False'\n",
    "\n",
    "# Configuration for Pure Transformer OCR\n",
    "CONFIG = {\n",
    "    'OCR_MODEL': 'microsoft_trocr',\n",
    "    'OCR_CONFIDENCE_THRESHOLD': 0.6,\n",
    "    'EMBEDDING_MODEL': 'sentence-transformers/all-MiniLM-L6-v2',\n",
    "    'VECTOR_STORE_PATH': './image_vectorstore',\n",
    "    'CHUNK_SIZE': 500,\n",
    "    'CHUNK_OVERLAP': 50,\n",
    "    'IMAGE_GALLERY_PATH': '../../datasets/images/text_ocr',\n",
    "    'DATABASE_PATH': './image_analysis_db',\n",
    "    'RESULTS_OUTPUT_PATH': '../../datasets/images/forensic_results',\n",
    "    'BATCH_SIZE': 4,\n",
    "    'MAX_RESULTS_DISPLAY': 10,\n",
    "    'DEVICE': 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "}\n",
    "\n",
    "# Pure Transformer OCR model options (no BLIP, no Ollama dependency)\n",
    "TRANSFORMER_OCR_MODELS = {\n",
    "    'microsoft_trocr': {\n",
    "        'name': 'Microsoft TrOCR Base (Printed)',\n",
    "        'model_id': 'microsoft/trocr-base-printed',\n",
    "        'desc': 'End-to-end transformer for printed text',\n",
    "        'strengths': 'Clean printed documents, forms, receipts',\n",
    "        'type': 'vision_encoder_decoder'\n",
    "    },\n",
    "    'microsoft_trocr_handwritten': {\n",
    "        'name': 'Microsoft TrOCR Base (Handwritten)',\n",
    "        'model_id': 'microsoft/trocr-base-handwritten',\n",
    "        'desc': 'Specialized for handwritten text recognition',\n",
    "        'strengths': 'Handwritten notes, signatures, cursive text',\n",
    "        'type': 'vision_encoder_decoder'\n",
    "    },\n",
    "    'microsoft_trocr_large': {\n",
    "        'name': 'Microsoft TrOCR Large (Printed)',\n",
    "        'model_id': 'microsoft/trocr-large-printed',\n",
    "        'desc': 'Large model for high-accuracy printed text',\n",
    "        'strengths': 'Complex documents, high accuracy needs',\n",
    "        'type': 'vision_encoder_decoder'\n",
    "    },\n",
    "    'allenai_olmo_ocr': {\n",
    "        'name': 'AllenAI OLMo OCR 7B',\n",
    "        'model_id': 'allenai/OLMo-7B-0724-hf',\n",
    "        'desc': 'Large multimodal model with OCR capabilities',\n",
    "        'strengths': 'Complex documents, reasoning about text content',\n",
    "        'type': 'multimodal_llm',\n",
    "        'note': 'Requires special implementation - placeholder for now'\n",
    "    }\n",
    "}\n",
    "\n",
    "print(f\"üîç PURE TRANSFORMER OCR SEARCH | Device: {CONFIG['DEVICE']} | üîí 100% Local Processing\")\n",
    "\n",
    "# Dependency check for Pure Transformer setup\n",
    "def check_pure_transformer_deps():\n",
    "    deps = {\n",
    "        'transformers': 'Hugging Face Transformers',\n",
    "        'torch': 'PyTorch',\n",
    "        'torchvision': 'TorchVision', \n",
    "        'chromadb': 'ChromaDB',\n",
    "        'sentence_transformers': 'Sentence Transformers',\n",
    "        'accelerate': 'Hugging Face Accelerate'\n",
    "    }\n",
    "    \n",
    "    print(\"üîß Checking Pure Transformer OCR Dependencies...\")\n",
    "    for dep, name in deps.items():\n",
    "        try: \n",
    "            __import__(dep.replace('-', '_')); \n",
    "            print(f\"‚úÖ {name}\")\n",
    "        except ImportError: \n",
    "            print(f\"‚ùå {name} - Install: pip install {dep}\")\n",
    "\n",
    "def check_gpu_availability():\n",
    "    \"\"\"Check GPU availability for faster inference\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        gpu_name = torch.cuda.get_device_name(0)\n",
    "        gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
    "        print(f\"‚úÖ GPU: {gpu_name} ({gpu_memory:.1f}GB)\")\n",
    "        return True\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è GPU not available, using CPU (slower)\")\n",
    "        return False\n",
    "\n",
    "check_pure_transformer_deps()\n",
    "gpu_available = check_gpu_availability()\n",
    "\n",
    "# Pure Transformer OCR System (No Ollama, No BLIP)\n",
    "class PureTransformerOCRSystem:\n",
    "    def __init__(self, config=None):\n",
    "        self.config = config or CONFIG.copy()\n",
    "        self.device = self.config['DEVICE']\n",
    "        self._setup_dirs()\n",
    "        self._init_db()\n",
    "        self._init_ocr()\n",
    "        self._init_embeddings()\n",
    "\n",
    "    def _setup_dirs(self):\n",
    "        for k in ['IMAGE_GALLERY_PATH', 'DATABASE_PATH', 'RESULTS_OUTPUT_PATH', 'VECTOR_STORE_PATH']:\n",
    "            os.makedirs(self.config[k], exist_ok=True)\n",
    "\n",
    "    def _init_db(self):\n",
    "        db_path = os.path.join(self.config['DATABASE_PATH'], 'image_text.db')\n",
    "        self.conn = sqlite3.connect(db_path)\n",
    "        self.conn.execute('''CREATE TABLE IF NOT EXISTS image_texts (\n",
    "            id INTEGER PRIMARY KEY,\n",
    "            filename TEXT UNIQUE,\n",
    "            full_path TEXT,\n",
    "            extracted_text TEXT,\n",
    "            ocr_confidence REAL,\n",
    "            ocr_model TEXT,\n",
    "            processed_date TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
    "            text_keywords TEXT,\n",
    "            text_length INTEGER,\n",
    "            relevance_score REAL,\n",
    "            vector_stored BOOLEAN DEFAULT 0,\n",
    "            processing_time REAL\n",
    "        )''')\n",
    "        self.conn.execute('''CREATE TABLE IF NOT EXISTS text_searches (\n",
    "            id INTEGER PRIMARY KEY,\n",
    "            query TEXT,\n",
    "            search_date TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
    "            results_json TEXT,\n",
    "            matched_images TEXT,\n",
    "            model_used TEXT,\n",
    "            processing_time REAL\n",
    "        )''')\n",
    "        self.conn.commit()\n",
    "\n",
    "    def _init_ocr(self):\n",
    "        \"\"\"Initialize selected Transformer OCR model\"\"\"\n",
    "        try:\n",
    "            ocr_model = self.config['OCR_MODEL']\n",
    "            model_info = TRANSFORMER_OCR_MODELS[ocr_model]\n",
    "            model_id = model_info['model_id']\n",
    "            model_type = model_info['type']\n",
    "            \n",
    "            print(f\"üîÑ Loading {model_info['name']}...\")\n",
    "            \n",
    "            if model_type == 'vision_encoder_decoder':\n",
    "                from transformers import TrOCRProcessor, VisionEncoderDecoderModel\n",
    "                self.ocr_processor = TrOCRProcessor.from_pretrained(model_id)\n",
    "                self.ocr_model = VisionEncoderDecoderModel.from_pretrained(model_id)\n",
    "                self.ocr_model.to(self.device)\n",
    "                self.ocr_type = 'trocr'\n",
    "                \n",
    "            elif model_type == 'multimodal_llm':\n",
    "                # For OLMo OCR - placeholder implementation\n",
    "                print(\"‚ö†Ô∏è OLMo OCR requires custom implementation\")\n",
    "                self.ocr_type = 'olmo'\n",
    "                self.ocr_processor = None\n",
    "                self.ocr_model = None\n",
    "                return\n",
    "\n",
    "            elif model_type == 'multimodal_vlm':\n",
    "                # AllenAI Molmo 7B\n",
    "                from transformers import AutoModelForCausalLM, AutoProcessor\n",
    "                self.ocr_processor = AutoProcessor.from_pretrained(model_id, trust_remote_code=True)\n",
    "                self.ocr_model = AutoModelForCausalLM.from_pretrained(\n",
    "                    model_id, trust_remote_code=True,\n",
    "                    torch_dtype=torch.float16 if self.device == 'cuda' else torch.float32,\n",
    "                    device_map='auto' if self.device == 'cuda' else 'cpu'\n",
    "                )\n",
    "                self.ocr_type = 'molmo'\n",
    "\n",
    "            elif model_type == 'multimodal_vlm':\n",
    "                # AllenAI Molmo 7B - requires specific setup\n",
    "                print(\"ü§ñ Loading AllenAI Molmo 7B (large download ~13GB)...\")\n",
    "                try:\n",
    "                    from transformers import AutoModelForCausalLM, AutoProcessor\n",
    "                    import torch\n",
    "\n",
    "                    # Check transformers version\n",
    "                    import transformers\n",
    "                    version = transformers.__version__\n",
    "                    print(f\"Transformers version: {version}\")\n",
    "\n",
    "                    self.ocr_processor = AutoProcessor.from_pretrained(\n",
    "                        model_id,\n",
    "                        trust_remote_code=True,\n",
    "                        torch_dtype='auto'\n",
    "                    )\n",
    "\n",
    "                    self.ocr_model = AutoModelForCausalLM.from_pretrained(\n",
    "                        model_id,\n",
    "                        trust_remote_code=True,\n",
    "                        torch_dtype=torch.bfloat16 if self.device == 'cuda' else torch.float32,\n",
    "                        device_map='auto' if self.device == 'cuda' else None\n",
    "                    )\n",
    "\n",
    "                    if self.device == 'cpu':\n",
    "                        self.ocr_model = self.ocr_model.to('cpu')\n",
    "\n",
    "                    self.ocr_type = 'molmo'\n",
    "                    print(\"‚úÖ Molmo 7B loaded successfully\")\n",
    "\n",
    "                except ImportError as e:\n",
    "                    print(f\"‚ùå Missing dependency: {e}\")\n",
    "                    print(\"üí° Install: pip install transformers>=4.44.0 einops\")\n",
    "                    self.ocr_processor = None\n",
    "                    self.ocr_model = None\n",
    "                    self.ocr_type = None\n",
    "                    return\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ùå Molmo 7B load failed: {e}\")\n",
    "                    print(\"üí° Try: pip install --upgrade transformers accelerate\")\n",
    "                    self.ocr_processor = None\n",
    "                    self.ocr_model = None\n",
    "                    self.ocr_type = None\n",
    "                    return\n",
    "\n",
    "                \n",
    "            print(f\"‚úÖ {model_info['name']} loaded on {self.device}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå OCR initialization error: {e}\")\n",
    "            self.ocr_processor = None\n",
    "            self.ocr_model = None\n",
    "            self.ocr_type = None\n",
    "\n",
    "    def _init_embeddings(self):\n",
    "        \"\"\"Initialize embeddings and vector store (no LLM needed)\"\"\"\n",
    "        try:\n",
    "            from sentence_transformers import SentenceTransformer\n",
    "            from chromadb import Client\n",
    "            from chromadb.config import Settings\n",
    "            import chromadb.utils.embedding_functions as embedding_functions\n",
    "            \n",
    "            # Initialize sentence transformer for embeddings\n",
    "            self.embedding_model = SentenceTransformer(self.config['EMBEDDING_MODEL'])\n",
    "            \n",
    "            # Initialize ChromaDB\n",
    "            self.chroma_client = Client(Settings(\n",
    "                persist_directory=self.config['VECTOR_STORE_PATH'],\n",
    "                anonymized_telemetry=False\n",
    "            ))\n",
    "            \n",
    "            # Create or get collection\n",
    "            self.collection_name = \"ocr_texts\"\n",
    "            try:\n",
    "                self.collection = self.chroma_client.get_collection(name=self.collection_name)\n",
    "            except:\n",
    "                self.collection = self.chroma_client.create_collection(\n",
    "                    name=self.collection_name,\n",
    "                    metadata={\"hnsw:space\": \"cosine\"}\n",
    "                )\n",
    "            \n",
    "            print(\"‚úÖ Pure embedding system ready (no LLM required)\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Embedding system error: {e}\")\n",
    "            self.embedding_model = None\n",
    "            self.collection = None\n",
    "\n",
    "    def extract_text(self, img_path: str) -> Dict[str, Any]:\n",
    "        \"\"\"Extract text using pure Transformer OCR models\"\"\"\n",
    "        start_time = time.time()\n",
    "        \n",
    "        try:\n",
    "            img = Image.open(img_path).convert(\"RGB\")\n",
    "            result = {\n",
    "                'filename': os.path.basename(img_path),\n",
    "                'full_path': img_path,\n",
    "                'extracted_text': '',\n",
    "                'ocr_confidence': 0.0,\n",
    "                'ocr_model': self.config['OCR_MODEL'],\n",
    "                'processing_time': 0.0,\n",
    "                'error': None\n",
    "            }\n",
    "            if not self.ocr_processor or not self.ocr_model:\n",
    "                result['error'] = \"OCR model not initialized\"\n",
    "                return result\n",
    "\n",
    "            if self.ocr_type == 'trocr':\n",
    "                # Microsoft TrOCR processing\n",
    "                pixel_values = self.ocr_processor(images=img, return_tensors=\"pt\").pixel_values\n",
    "                pixel_values = pixel_values.to(self.device)\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    generated_ids = self.ocr_model.generate(\n",
    "                        pixel_values, \n",
    "                        max_length=512,\n",
    "                        num_beams=4,\n",
    "                        early_stopping=True\n",
    "                    )\n",
    "                \n",
    "                text = self.ocr_processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "                \n",
    "                if text.strip():\n",
    "                    result.update({\n",
    "                        'extracted_text': text.strip(),\n",
    "                        'ocr_confidence': 0.95  # TrOCR doesn't provide confidence, use high default\n",
    "                    })\n",
    "                    \n",
    "            elif self.ocr_type == 'olmo':\n",
    "                # OLMo OCR placeholder\n",
    "                result.update({\n",
    "                    'extracted_text': '',\n",
    "                    'ocr_confidence': 0.0,\n",
    "                    'error': 'OLMo OCR not implemented yet'\n",
    "                })\n",
    "\n",
    "            elif self.ocr_type == 'molmo':\n",
    "                # AllenAI Molmo 7B processing\n",
    "                ocr_prompt = \"Extract all text from this image. Provide only the text content.\"\n",
    "                inputs = self.ocr_processor.process(images=[img], text=ocr_prompt)\n",
    "                inputs = {k: v.to(self.ocr_model.device) for k, v in inputs.items()}\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    output = self.ocr_model.generate_from_batch(\n",
    "                        inputs, generation_config={\"max_new_tokens\": 200}\n",
    "                    )\n",
    "\n",
    "                generated_tokens = output[0, inputs['input_ids'].size(1):]\n",
    "                text = self.ocr_processor.decode(generated_tokens, skip_special_tokens=True)\n",
    "\n",
    "                if text.strip():\n",
    "                    result.update({\n",
    "                        'extracted_text': text.strip(),\n",
    "                        'ocr_confidence': 0.90\n",
    "                    })\n",
    "\n",
    "            \n",
    "        except Exception as e:\n",
    "            return {\n",
    "                'filename': os.path.basename(img_path),\n",
    "                'full_path': img_path,\n",
    "                'extracted_text': '',\n",
    "                'ocr_confidence': 0.0,\n",
    "                'ocr_model': self.config['OCR_MODEL'],\n",
    "                'processing_time': time.time() - start_time,\n",
    "                'error': str(e)\n",
    "            }\n",
    "\n",
    "    def analyze_text_simple(self, text: str, filename: str) -> Dict[str, Any]:\n",
    "        \"\"\"Simple text analysis without LLM dependency\"\"\"\n",
    "        words = text.lower().split()\n",
    "        \n",
    "        # Extract basic features\n",
    "        keywords = []\n",
    "        entities = {'numbers': [], 'emails': [], 'urls': []}\n",
    "        \n",
    "        for word in words:\n",
    "            # Simple keyword extraction (words > 3 chars, not common words)\n",
    "            if len(word) > 3 and word not in ['the', 'and', 'for', 'are', 'but', 'not', 'you', 'all', 'can', 'had', 'her', 'was', 'one', 'our', 'out', 'day', 'get', 'has', 'him', 'his', 'how', 'may', 'new', 'now', 'old', 'see', 'two', 'who', 'its', 'said', 'each', 'make', 'most', 'over', 'said', 'some', 'time', 'very', 'when', 'with', 'have', 'from', 'they', 'know', 'want', 'been', 'good', 'much', 'some', 'time', 'very', 'when', 'come', 'could', 'state', 'there', 'think', 'where', 'being', 'every', 'great', 'might', 'shall', 'still', 'those', 'under', 'while']:\n",
    "                keywords.append(word)\n",
    "                \n",
    "        # Simple entity detection\n",
    "        import re\n",
    "        numbers = re.findall(r'\\b\\d+\\.?\\d*\\b', text)\n",
    "        emails = re.findall(r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b', text)\n",
    "        urls = re.findall(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', text)\n",
    "        \n",
    "        return {\n",
    "            'text_length': len(text),\n",
    "            'word_count': len(words),\n",
    "            'keywords': keywords[:10],  # Top 10 keywords\n",
    "            'entities': {\n",
    "                'numbers': numbers[:5],\n",
    "                'emails': emails[:3],\n",
    "                'urls': urls[:3]\n",
    "            },\n",
    "            'has_numbers': len(numbers) > 0,\n",
    "            'has_emails': len(emails) > 0,\n",
    "            'has_urls': len(urls) > 0,\n",
    "            'readability_score': min(len(words) / 50.0, 1.0),\n",
    "            'relevance_score': min(len(keywords) / 20.0, 1.0)\n",
    "        }\n",
    "\n",
    "    def add_to_vectorstore(self, text: str, metadata: Dict[str, Any]):\n",
    "        \"\"\"Add text to vector store using pure embeddings\"\"\"\n",
    "        try:\n",
    "            if not self.embedding_model or not self.collection:\n",
    "                return False\n",
    "                \n",
    "            # Generate embedding\n",
    "            embedding = self.embedding_model.encode([text])[0].tolist()\n",
    "            \n",
    "            # Create unique ID\n",
    "            doc_id = f\"{metadata['filename']}_{int(time.time() * 1000)}\"\n",
    "            \n",
    "            # Add to ChromaDB\n",
    "            self.collection.add(\n",
    "                embeddings=[embedding],\n",
    "                documents=[text],\n",
    "                metadatas=[metadata],\n",
    "                ids=[doc_id]\n",
    "            )\n",
    "            \n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Vector store error: {e}\")\n",
    "            return False\n",
    "\n",
    "    def process_images(self):\n",
    "        \"\"\"Process all images using pure Transformer OCR\"\"\"\n",
    "        start_time = time.time()\n",
    "        gallery_path = Path(self.config['IMAGE_GALLERY_PATH'])\n",
    "        \n",
    "        print(f\"üîç PROCESSING: {gallery_path}\")\n",
    "        print(f\"ü§ñ OCR Model: {TRANSFORMER_OCR_MODELS[self.config['OCR_MODEL']]['name']}\")\n",
    "        print(f\"‚ö° Device: {self.device}\")\n",
    "        print(f\"üìä Pure Transformer processing (no LLM required)\")\n",
    "\n",
    "        if not gallery_path.exists():\n",
    "            print(f\"‚ùå Path not found: {gallery_path}\")\n",
    "            return\n",
    "\n",
    "        # Find all image files\n",
    "        exts = ['.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.webp']\n",
    "        files = [f for ext in exts\n",
    "                for f in list(gallery_path.glob(f\"**/*{ext}\")) +\n",
    "                         list(gallery_path.glob(f\"**/*{ext.upper()}\"))]\n",
    "        \n",
    "        total = len(files)\n",
    "        print(f\"üì∏ Found {total} images\")\n",
    "        \n",
    "        if total == 0:\n",
    "            print(\"‚ö†Ô∏è No images found!\")\n",
    "            return\n",
    "\n",
    "        processed, vectorized = 0, 0\n",
    "        total_ocr_time = 0\n",
    "\n",
    "        for i, img_path in enumerate(files, 1):\n",
    "            filename = img_path.name\n",
    "            print(f\"[{i:3d}/{total}] ({i/total*100:5.1f}%) Processing {filename[:40]}...\", end='')\n",
    "\n",
    "            # Skip if already processed with same model\n",
    "            existing = self.conn.execute(\n",
    "                \"SELECT id FROM image_texts WHERE filename = ? AND ocr_model = ?\",\n",
    "                (filename, self.config['OCR_MODEL'])\n",
    "            ).fetchone()\n",
    "            \n",
    "            if existing:\n",
    "                print(\" ‚è≠Ô∏è SKIP\")\n",
    "                continue\n",
    "\n",
    "            # Extract text using Transformer OCR\n",
    "            ocr_result = self.extract_text(img_path)\n",
    "            \n",
    "            if ocr_result.get('error'):\n",
    "                print(f\" ‚ùå ERROR: {ocr_result['error'][:30]}\")\n",
    "                continue\n",
    "\n",
    "            text = ocr_result['extracted_text']\n",
    "            processing_time = ocr_result['processing_time']\n",
    "            total_ocr_time += processing_time\n",
    "\n",
    "            analysis = None\n",
    "            vector_stored = False\n",
    "\n",
    "            if text.strip():\n",
    "                # Simple analysis (no LLM needed)\n",
    "                analysis = self.analyze_text_simple(text, filename)\n",
    "                \n",
    "                # Add to vector store\n",
    "                metadata = {\n",
    "                    'filename': filename,\n",
    "                    'full_path': str(img_path),\n",
    "                    'ocr_model': self.config['OCR_MODEL'],\n",
    "                    'ocr_confidence': ocr_result['ocr_confidence']\n",
    "                }\n",
    "                \n",
    "                if self.add_to_vectorstore(text, metadata):\n",
    "                    vector_stored = True\n",
    "                    vectorized += 1\n",
    "\n",
    "            # Store in database\n",
    "            relevance = analysis['relevance_score'] if analysis else 0.0\n",
    "            keywords_json = json.dumps(analysis['keywords']) if analysis else None\n",
    "            text_length = len(text)\n",
    "            \n",
    "            self.conn.execute('''INSERT OR REPLACE INTO image_texts\n",
    "                (filename, full_path, extracted_text, ocr_confidence, ocr_model,\n",
    "                 text_keywords, text_length, relevance_score, vector_stored, processing_time)\n",
    "                VALUES (?,?,?,?,?,?,?,?,?,?)''',\n",
    "                (filename, str(img_path), text, ocr_result['ocr_confidence'],\n",
    "                 self.config['OCR_MODEL'], keywords_json, text_length,\n",
    "                 relevance, vector_stored, processing_time))\n",
    "\n",
    "            if text.strip():\n",
    "                words = len(text.split())\n",
    "                print(f\" ‚úÖ TEXT ({words} words, {processing_time:.2f}s)\")\n",
    "            else:\n",
    "                print(f\" ‚ö™ NO TEXT ({processing_time:.2f}s)\")\n",
    "\n",
    "            processed += 1\n",
    "            \n",
    "            # Commit every 10 images\n",
    "            if i % 10 == 0:\n",
    "                self.conn.commit()\n",
    "                if self.device == 'cuda':\n",
    "                    torch.cuda.empty_cache()\n",
    "\n",
    "        self.conn.commit()\n",
    "        total_time = time.time() - start_time\n",
    "        avg_ocr_time = total_ocr_time / processed if processed > 0 else 0\n",
    "        \n",
    "        print(f\"\\nüîç PROCESSING COMPLETE:\")\n",
    "        print(f\"   üìä Processed: {processed}/{total} images\")\n",
    "        print(f\"   üíæ Vectorized: {vectorized} for search\")\n",
    "        print(f\"   ‚è±Ô∏è Total time: {total_time:.1f}s\")\n",
    "        print(f\"   ‚ö° Avg OCR time: {avg_ocr_time:.2f}s per image\")\n",
    "        print(f\"   ü§ñ Model: {TRANSFORMER_OCR_MODELS[self.config['OCR_MODEL']]['name']}\")\n",
    "\n",
    "    def semantic_search(self, query: str, k: int = 10) -> Dict[str, Any]:\n",
    "        \"\"\"Pure embedding-based semantic search\"\"\"\n",
    "        print(f\"üîç PURE SEMANTIC SEARCH: '{query}'\")\n",
    "        start_time = time.time()\n",
    "        \n",
    "        try:\n",
    "            if not self.embedding_model or not self.collection:\n",
    "                return {\n",
    "                    'matches': [],\n",
    "                    'summary': 'Embedding system not available',\n",
    "                    'total_matches': 0,\n",
    "                    'search_type': 'error'\n",
    "                }\n",
    "\n",
    "            # Generate query embedding\n",
    "            query_embedding = self.embedding_model.encode([query])[0].tolist()\n",
    "            \n",
    "            # Search in ChromaDB\n",
    "            results = self.collection.query(\n",
    "                query_embeddings=[query_embedding],\n",
    "                n_results=k,\n",
    "                include=['documents', 'metadatas', 'distances']\n",
    "            )\n",
    "            \n",
    "            if not results['documents'][0]:\n",
    "                return {\n",
    "                    'matches': [],\n",
    "                    'summary': 'No semantic matches found',\n",
    "                    'total_matches': 0,\n",
    "                    'search_type': 'semantic'\n",
    "                }\n",
    "\n",
    "            # Process results\n",
    "            matches = []\n",
    "            documents = results['documents'][0]\n",
    "            metadatas = results['metadatas'][0]\n",
    "            distances = results['distances'][0]\n",
    "            \n",
    "            for i, (doc, metadata, distance) in enumerate(zip(documents, metadatas, distances)):\n",
    "                filename = metadata.get('filename', f'unknown_{i}')\n",
    "                similarity = 1.0 - distance  # Convert distance to similarity\n",
    "                \n",
    "                # Get full info from database\n",
    "                db_result = self.conn.execute('''SELECT extracted_text, ocr_confidence, \n",
    "                    text_keywords, text_length, processing_time, full_path\n",
    "                    FROM image_texts WHERE filename = ?''', (filename,)).fetchone()\n",
    "\n",
    "                if db_result:\n",
    "                    full_text, confidence, keywords_json, text_len, proc_time, full_path = db_result\n",
    "                    keywords = json.loads(keywords_json) if keywords_json else []\n",
    "                    \n",
    "                    matches.append({\n",
    "                        'filename': filename,\n",
    "                        'full_path': full_path,\n",
    "                        'extracted_text': full_text,\n",
    "                        'ocr_confidence': confidence,\n",
    "                        'ocr_model': self.config['OCR_MODEL'],\n",
    "                        'processing_time': proc_time,\n",
    "                        'similarity_score': similarity,\n",
    "                        'matching_text': doc[:200],  # Preview of matching text\n",
    "                        'keywords': keywords[:5],\n",
    "                        'text_length': text_len\n",
    "                    })\n",
    "\n",
    "            # Sort by similarity score\n",
    "            matches.sort(key=lambda x: x['similarity_score'], reverse=True)\n",
    "            \n",
    "            search_time = time.time() - start_time\n",
    "            \n",
    "            results = {\n",
    "                'matches': matches,\n",
    "                'summary': f\"Found {len(matches)} semantically similar images\",\n",
    "                'total_matches': len(matches),\n",
    "                'query': query,\n",
    "                'search_type': 'pure_semantic',\n",
    "                'search_time': search_time\n",
    "            }\n",
    "\n",
    "            # Store search in database\n",
    "            self.conn.execute('''INSERT INTO text_searches\n",
    "                (query, results_json, matched_images, model_used, processing_time)\n",
    "                VALUES (?,?,?,?,?)''',\n",
    "                (query, json.dumps(results),\n",
    "                 json.dumps([m['filename'] for m in matches]),\n",
    "                 f\"pure_transformer_{self.config['OCR_MODEL']}\",\n",
    "                 search_time))\n",
    "            self.conn.commit()\n",
    "\n",
    "            print(f\"‚úÖ Found {len(matches)} matches in {search_time:.2f}s\")\n",
    "            return results\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Search error: {e}\")\n",
    "            return {\n",
    "                'matches': [],\n",
    "                'summary': f'Search error: {e}',\n",
    "                'total_matches': 0,\n",
    "                'search_type': 'error'\n",
    "            }\n",
    "\n",
    "    def keyword_search(self, query: str) -> Dict[str, Any]:\n",
    "        \"\"\"Simple keyword-based search in extracted text\"\"\"\n",
    "        print(f\"üîç KEYWORD SEARCH: '{query}'\")\n",
    "        start_time = time.time()\n",
    "        \n",
    "        try:\n",
    "            query_words = query.lower().split()\n",
    "            \n",
    "            # Search in database using SQL LIKE\n",
    "            like_conditions = ' AND '.join(['LOWER(extracted_text) LIKE ?' for _ in query_words])\n",
    "            like_params = [f'%{word}%' for word in query_words]\n",
    "            \n",
    "            sql = f'''SELECT filename, full_path, extracted_text, ocr_confidence,\n",
    "                text_keywords, text_length, processing_time FROM image_texts\n",
    "                WHERE {like_conditions} AND extracted_text != \"\"\n",
    "                ORDER BY ocr_confidence DESC LIMIT 20'''\n",
    "            \n",
    "            results = self.conn.execute(sql, like_params).fetchall()\n",
    "            \n",
    "            matches = []\n",
    "            for result in results:\n",
    "                filename, full_path, text, confidence, keywords_json, text_len, proc_time = result\n",
    "                keywords = json.loads(keywords_json) if keywords_json else []\n",
    "                \n",
    "                # Calculate simple relevance score\n",
    "                text_lower = text.lower()\n",
    "                relevance = sum(1 for word in query_words if word in text_lower) / len(query_words)\n",
    "                \n",
    "                matches.append({\n",
    "                    'filename': filename,\n",
    "                    'full_path': full_path,\n",
    "                    'extracted_text': text,\n",
    "                    'ocr_confidence': confidence,\n",
    "                    'ocr_model': self.config['OCR_MODEL'],\n",
    "                    'processing_time': proc_time,\n",
    "                    'relevance_score': relevance,\n",
    "                    'keywords': keywords[:5],\n",
    "                    'text_length': text_len\n",
    "                })\n",
    "            \n",
    "            search_time = time.time() - start_time\n",
    "            \n",
    "            search_results = {\n",
    "                'matches': matches,\n",
    "                'summary': f\"Found {len(matches)} keyword matches\",\n",
    "                'total_matches': len(matches),\n",
    "                'query': query,\n",
    "                'search_type': 'keyword',\n",
    "                'search_time': search_time\n",
    "            }\n",
    "            \n",
    "            print(f\"‚úÖ Found {len(matches)} keyword matches in {search_time:.2f}s\")\n",
    "            return search_results\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Keyword search error: {e}\")\n",
    "            return {\n",
    "                'matches': [],\n",
    "                'summary': f'Keyword search error: {e}',\n",
    "                'total_matches': 0,\n",
    "                'search_type': 'error'\n",
    "            }\n",
    "\n",
    "    def get_model_performance_stats(self):\n",
    "        \"\"\"Get performance statistics for current OCR model\"\"\"\n",
    "        stats = self.conn.execute('''SELECT \n",
    "            COUNT(*) as total_processed,\n",
    "            AVG(ocr_confidence) as avg_confidence,\n",
    "            AVG(processing_time) as avg_processing_time,\n",
    "            COUNT(CASE WHEN extracted_text != '' THEN 1 END) as texts_found,\n",
    "            AVG(text_length) as avg_text_length\n",
    "            FROM image_texts WHERE ocr_model = ?''',\n",
    "            (self.config['OCR_MODEL'],)).fetchone()\n",
    "            \n",
    "        return {\n",
    "            'model_name': TRANSFORMER_OCR_MODELS[self.config['OCR_MODEL']]['name'],\n",
    "            'total_processed': stats[0] or 0,\n",
    "            'avg_confidence': stats[1] or 0,\n",
    "            'avg_processing_time': stats[2] or 0,\n",
    "            'texts_found': stats[3] or 0,\n",
    "            'success_rate': (stats[3] or 0) / (stats[0] or 1) * 100,\n",
    "            'avg_text_length': stats[4] or 0\n",
    "        }\n",
    "\n",
    "    def export_pure_results(self, results: Dict[str, Any], query: str) -> str:\n",
    "        \"\"\"Export search results with pure transformer info\"\"\"\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        query_safe = query.replace(' ', '_')[:30]\n",
    "        output_path = Path(self.config['RESULTS_OUTPUT_PATH']) / f\"pure_transformer_search_{query_safe}_{timestamp}\"\n",
    "        output_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        # Copy matching images\n",
    "        copied = []\n",
    "        for i, match in enumerate(results.get('matches', []), 1):\n",
    "            if Path(match['full_path']).exists():\n",
    "                dest = output_path / f\"{i:03d}_{match['filename']}\"\n",
    "                shutil.copy2(match['full_path'], dest)\n",
    "                copied.append(str(dest))\n",
    "\n",
    "        # Get performance stats\n",
    "        perf_stats = self.get_model_performance_stats()\n",
    "        \n",
    "        # Pure transformer report\n",
    "        report = {\n",
    "            'query': query,\n",
    "            'timestamp': timestamp,\n",
    "            'pure_transformer_ocr_model': self.config['OCR_MODEL'],\n",
    "            'model_info': TRANSFORMER_OCR_MODELS[self.config['OCR_MODEL']],\n",
    "            'device_used': self.device,\n",
    "            'search_type': 'pure_transformer_no_llm',\n",
    "            'performance_stats': perf_stats,\n",
    "            'search_results': results,\n",
    "            'copied_files': copied\n",
    "        }\n",
    "\n",
    "        with open(output_path / \"pure_transformer_report.json\", 'w') as f:\n",
    "            json.dump(report, f, indent=2)\n",
    "\n",
    "        # Summary report\n",
    "        with open(output_path / \"summary.txt\", 'w') as f:\n",
    "            f.write(f\"PURE TRANSFORMER OCR SEARCH REPORT\\n\")\n",
    "            f.write(f\"=\" * 50 + \"\\n\")\n",
    "            f.write(f\"Query: {query}\\n\")\n",
    "            f.write(f\"Date: {timestamp}\\n\")\n",
    "            f.write(f\"OCR Model: {perf_stats['model_name']}\\n\")\n",
    "            f.write(f\"Device: {self.device}\\n\")\n",
    "            f.write(f\"Search Type: {results.get('search_type', 'unknown')}\\n\")\n",
    "            f.write(f\"Processing: Pure Transformer (No LLM/Ollama)\\n\")\n",
    "            f.write(f\"Matches: {len(results.get('matches', []))}\\n\")\n",
    "            f.write(f\"Search Time: {results.get('search_time', 0):.2f}s\\n\\n\")\n",
    "            \n",
    "            f.write(f\"MODEL PERFORMANCE:\\n\")\n",
    "            f.write(f\"  Total Processed: {perf_stats['total_processed']}\\n\")\n",
    "            f.write(f\"  Success Rate: {perf_stats['success_rate']:.1f}%\\n\")\n",
    "            f.write(f\"  Avg Confidence: {perf_stats['avg_confidence']:.3f}\\n\")\n",
    "            f.write(f\"  Avg Processing Time: {perf_stats['avg_processing_time']:.2f}s\\n\")\n",
    "            f.write(f\"  Avg Text Length: {perf_stats['avg_text_length']:.0f} chars\\n\\n\")\n",
    "\n",
    "            f.write(f\"SEARCH RESULTS:\\n\")\n",
    "            f.write(f\"-\" * 30 + \"\\n\")\n",
    "            for i, match in enumerate(results.get('matches', []), 1):\n",
    "                f.write(f\"{i}. {match['filename']}\\n\")\n",
    "                f.write(f\"   OCR Confidence: {match['ocr_confidence']:.3f}\\n\")\n",
    "                f.write(f\"   Similarity Score: {match.get('similarity_score', match.get('relevance_score', 0)):.3f}\\n\")\n",
    "                f.write(f\"   Processing Time: {match.get('processing_time', 0):.2f}s\\n\")\n",
    "                f.write(f\"   Text Length: {match.get('text_length', 0)} chars\\n\")\n",
    "                f.write(f\"   Text Preview: {match['extracted_text'][:150]}...\\n\")\n",
    "                \n",
    "                if match.get('keywords'):\n",
    "                    f.write(f\"   Keywords: {', '.join(match['keywords'][:5])}\\n\")\n",
    "                f.write(\"\\n\")\n",
    "\n",
    "        print(f\"üìã Pure Transformer results exported to: {output_path}\")\n",
    "        return str(output_path)\n",
    "\n",
    "    def close(self):\n",
    "        \"\"\"Cleanup resources\"\"\"\n",
    "        if hasattr(self, 'conn') and self.conn:\n",
    "            self.conn.close()\n",
    "        if hasattr(self, 'ocr_model') and self.ocr_model and self.device == 'cuda':\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "# Pure Transformer OCR GUI (No Ollama, No BLIP)\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def create_pure_transformer_gui():\n",
    "    \"\"\"Create GUI for Pure Transformer OCR system\"\"\"\n",
    "\n",
    "    # Model selection (only TrOCR and OLMo)\n",
    "    model_options = []\n",
    "    for key, info in TRANSFORMER_OCR_MODELS.items():\n",
    "        if key != 'salesforce_blip':  # Exclude BLIP\n",
    "            desc = f\"{info['name']} - {info['strengths']}\"\n",
    "            model_options.append((desc, key))\n",
    "\n",
    "    ocr_selector = widgets.Dropdown(\n",
    "        options=model_options,\n",
    "        value='microsoft_trocr',\n",
    "        description='Transformer OCR:',\n",
    "        style={'description_width': 'initial'},\n",
    "        layout=widgets.Layout(width='600px')\n",
    "    )\n",
    "\n",
    "    # Device selection\n",
    "    device_options = [('Auto (GPU if available)', 'auto')]\n",
    "    if torch.cuda.is_available():\n",
    "        device_options.append(('Force GPU', 'cuda'))\n",
    "    device_options.append(('Force CPU', 'cpu'))\n",
    "\n",
    "    device_selector = widgets.Dropdown(\n",
    "        options=device_options,\n",
    "        value='auto',\n",
    "        description='Processing Device:',\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "\n",
    "    # Paths and settings\n",
    "    gallery_path = widgets.Text(\n",
    "        value='../../datasets/images/text_ocr',\n",
    "        description='Image Directory:',\n",
    "        style={'description_width': 'initial'},\n",
    "        layout=widgets.Layout(width='500px')\n",
    "    )\n",
    "\n",
    "    batch_size = widgets.IntSlider(\n",
    "        value=4,\n",
    "        min=1, max=16, step=1,\n",
    "        description='Batch Size:',\n",
    "        style={'description_width': 'initial'},\n",
    "        tooltip='Higher = faster but more memory usage'\n",
    "    )\n",
    "\n",
    "    confidence_threshold = widgets.FloatSlider(\n",
    "        value=0.6,\n",
    "        min=0.1, max=0.95, step=0.05,\n",
    "        description='Confidence Threshold:',\n",
    "        style={'description_width': 'initial'},\n",
    "        readout_format='.2f'\n",
    "    )\n",
    "\n",
    "    # Search interface\n",
    "    search_input = widgets.Textarea(\n",
    "        value='Enter search query...',\n",
    "        description='Search Query:',\n",
    "        style={'description_width': 'initial'},\n",
    "        layout=widgets.Layout(width='500px', height='80px')\n",
    "    )\n",
    "\n",
    "    search_type = widgets.RadioButtons(\n",
    "        options=[('Semantic Search', 'semantic'), ('Keyword Search', 'keyword')],\n",
    "        value='semantic',\n",
    "        description='Search Type:',\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "\n",
    "    # Search examples for pure OCR\n",
    "    search_examples = [\n",
    "        \"invoice numbers\", \"handwritten notes\", \"printed receipts\",\n",
    "        \"form fields\", \"technical documents\", \"certificates\",\n",
    "        \"phone numbers\", \"email addresses\", \"dates\"\n",
    "    ]\n",
    "    \n",
    "    quick_search_btns = [widgets.Button(\n",
    "        description=example,\n",
    "        tooltip=f\"Search for {example}\",\n",
    "        layout=widgets.Layout(width='140px', margin='2px')\n",
    "    ) for example in search_examples[:6]]\n",
    "\n",
    "    # Action buttons\n",
    "    model_info_btn = widgets.Button(description='üìã Model Info', button_style='info', layout=widgets.Layout(width='130px'))\n",
    "    test_setup_btn = widgets.Button(description='üîß Test Setup', button_style='info', layout=widgets.Layout(width='130px'))\n",
    "    process_btn = widgets.Button(description='üöÄ Process Images', button_style='primary', layout=widgets.Layout(width='150px'))\n",
    "    semantic_btn = widgets.Button(description='üîç Semantic Search', button_style='success', layout=widgets.Layout(width='150px'))\n",
    "    keyword_btn = widgets.Button(description='üî§ Keyword Search', button_style='warning', layout=widgets.Layout(width='150px'))\n",
    "    stats_btn = widgets.Button(description='üìä View Stats', button_style='info', layout=widgets.Layout(width='130px'))\n",
    "    export_btn = widgets.Button(description='üìã Export Results', button_style='success', layout=widgets.Layout(width='150px'), disabled=True)\n",
    "    clear_btn = widgets.Button(description='üóëÔ∏è Clear', layout=widgets.Layout(width='120px'))\n",
    "\n",
    "    # Status and progress\n",
    "    status_label = widgets.HTML(value=\"<b>Status:</b> Pure Transformer OCR Ready\")\n",
    "    progress_bar = widgets.IntProgress(value=0, min=0, max=100, layout=widgets.Layout(width='500px'))\n",
    "    memory_info = widgets.HTML(value=\"<b>Memory:</b> Not monitored\")\n",
    "    output_area = widgets.Output()\n",
    "\n",
    "    # State management\n",
    "    current_system = None\n",
    "    current_results = None\n",
    "\n",
    "    def update_status(msg, progress=None, memory_usage=None):\n",
    "        status_label.value = f\"<b>Status:</b> {msg}\"\n",
    "        if progress is not None:\n",
    "            progress_bar.value = progress\n",
    "        if memory_usage is not None:\n",
    "            memory_info.value = f\"<b>Memory:</b> {memory_usage}\"\n",
    "\n",
    "    def get_memory_usage():\n",
    "        \"\"\"Get current memory usage\"\"\"\n",
    "        if torch.cuda.is_available():\n",
    "            allocated = torch.cuda.memory_allocated() / 1024**3\n",
    "            cached = torch.cuda.memory_reserved() / 1024**3\n",
    "            return f\"GPU: {allocated:.1f}GB allocated, {cached:.1f}GB cached\"\n",
    "        return \"CPU mode\"\n",
    "\n",
    "    def init_system():\n",
    "        nonlocal current_system\n",
    "        try:\n",
    "            config = CONFIG.copy()\n",
    "            \n",
    "            # Handle device selection\n",
    "            if device_selector.value == 'auto':\n",
    "                config['DEVICE'] = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "            else:\n",
    "                config['DEVICE'] = device_selector.value\n",
    "                \n",
    "            config.update({\n",
    "                'OCR_MODEL': ocr_selector.value,\n",
    "                'IMAGE_GALLERY_PATH': gallery_path.value,\n",
    "                'BATCH_SIZE': batch_size.value,\n",
    "                'OCR_CONFIDENCE_THRESHOLD': confidence_threshold.value\n",
    "            })\n",
    "            \n",
    "            if current_system:\n",
    "                current_system.close()\n",
    "                \n",
    "            current_system = PureTransformerOCRSystem(config)\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå System initialization error: {e}\")\n",
    "            return False\n",
    "\n",
    "    # Quick search button handlers\n",
    "    def on_quick_search(search_text):\n",
    "        def handler(b):\n",
    "            search_input.value = search_text\n",
    "        return handler\n",
    "\n",
    "    for i, btn in enumerate(quick_search_btns):\n",
    "        btn.on_click(on_quick_search(search_examples[i]))\n",
    "\n",
    "    # Button handlers\n",
    "    def on_model_info(b):\n",
    "        with output_area:\n",
    "            clear_output(wait=True)\n",
    "            print(\"üìã PURE TRANSFORMER OCR MODEL INFORMATION\")\n",
    "            print(\"=\" * 60)\n",
    "            \n",
    "            current_model = ocr_selector.value\n",
    "            model_info = TRANSFORMER_OCR_MODELS[current_model]\n",
    "            \n",
    "            print(f\"ü§ñ Selected Model: {model_info['name']}\")\n",
    "            print(f\"üè∑Ô∏è Model ID: {model_info['model_id']}\")\n",
    "            print(f\"üìù Description: {model_info['desc']}\")\n",
    "            print(f\"üí™ Strengths: {model_info['strengths']}\")\n",
    "            print(f\"üîß Type: {model_info['type']}\")\n",
    "            \n",
    "            if 'note' in model_info:\n",
    "                print(f\"‚ö†Ô∏è Note: {model_info['note']}\")\n",
    "            \n",
    "            print(f\"\\nüñ•Ô∏è Device: {device_selector.value}\")\n",
    "            if torch.cuda.is_available():\n",
    "                gpu_name = torch.cuda.get_device_name(0)\n",
    "                gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
    "                print(f\"üéÆ GPU Available: {gpu_name} ({gpu_memory:.1f}GB)\")\n",
    "            else:\n",
    "                print(\"üíª CPU Only\")\n",
    "                \n",
    "            print(f\"\\n‚öôÔ∏è Configuration:\")\n",
    "            print(f\"  Batch Size: {batch_size.value}\")\n",
    "            print(f\"  Confidence Threshold: {confidence_threshold.value}\")\n",
    "            print(f\"  Processing: Pure Transformer (No LLM/Ollama)\")\n",
    "            print(f\"  Search: Embeddings + Keywords\")\n",
    "\n",
    "    def on_test_setup(b):\n",
    "        with output_area:\n",
    "            clear_output(wait=True)\n",
    "            update_status(\"Testing Pure Transformer setup...\", 10)\n",
    "            \n",
    "            print(\"üîß PURE TRANSFORMER OCR SETUP TEST\")\n",
    "            print(\"=\" * 50)\n",
    "            print(\"‚ú® No Ollama or BLIP dependencies required!\")\n",
    "            \n",
    "            # Test model availability\n",
    "            selected_model = ocr_selector.value\n",
    "            model_info = TRANSFORMER_OCR_MODELS[selected_model]\n",
    "            \n",
    "            print(f\"\\nü§ñ Testing {model_info['name']}...\")\n",
    "            try:\n",
    "                if model_info['type'] == 'vision_encoder_decoder':\n",
    "                    from transformers import TrOCRProcessor\n",
    "                    processor = TrOCRProcessor.from_pretrained(model_info['model_id'])\n",
    "                    print(f\"‚úÖ Model {model_info['model_id']} accessible\")\n",
    "                else:\n",
    "                    print(f\"‚ö†Ô∏è {model_info['name']} requires custom implementation\")\n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Model access error: {e}\")\n",
    "                \n",
    "            update_status(\"Testing dependencies...\", 40)\n",
    "            \n",
    "            # Test core dependencies (no Ollama needed)\n",
    "            deps = ['torch', 'torchvision', 'transformers', 'sentence_transformers', 'chromadb']\n",
    "            for dep in deps:\n",
    "                try:\n",
    "                    __import__(dep.replace('-', '_'))\n",
    "                    print(f\"‚úÖ {dep}\")\n",
    "                except ImportError:\n",
    "                    print(f\"‚ùå {dep}\")\n",
    "                    \n",
    "            update_status(\"Testing GPU/CPU...\", 70)\n",
    "            \n",
    "            # Test device\n",
    "            if device_selector.value == 'cuda' and not torch.cuda.is_available():\n",
    "                print(\"‚ö†Ô∏è GPU requested but not available\")\n",
    "            elif torch.cuda.is_available():\n",
    "                print(f\"‚úÖ GPU: {torch.cuda.get_device_name(0)}\")\n",
    "                print(f\"   Memory: {get_memory_usage()}\")\n",
    "            else:\n",
    "                print(\"‚úÖ CPU mode\")\n",
    "                \n",
    "            # Test image directory\n",
    "            img_path = Path(gallery_path.value)\n",
    "            if img_path.exists():\n",
    "                img_count = len([f for f in img_path.glob('**/*') \n",
    "                               if f.suffix.lower() in ['.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.webp']])\n",
    "                print(f\"‚úÖ Image directory: {img_count} images found\")\n",
    "            else:\n",
    "                print(f\"‚ö†Ô∏è Image directory not found: {gallery_path.value}\")\n",
    "                \n",
    "            update_status(\"Initializing pure system...\", 90)\n",
    "            \n",
    "            if init_system():\n",
    "                print(\"‚úÖ Pure Transformer OCR system ready!\")\n",
    "                print(\"üöÄ No external dependencies (Ollama/BLIP) required\")\n",
    "                update_status(\"Pure setup complete!\", 100, get_memory_usage())\n",
    "            else:\n",
    "                print(\"‚ùå System initialization failed\")\n",
    "                update_status(\"Setup failed\", 0)\n",
    "\n",
    "    def on_process(b):\n",
    "        with output_area:\n",
    "            clear_output(wait=True)\n",
    "            update_status(\"Initializing processing...\", 10)\n",
    "            \n",
    "            if not init_system():\n",
    "                update_status(\"Initialization failed\", 0)\n",
    "                return\n",
    "                \n",
    "            print(\"üöÄ PURE TRANSFORMER OCR PROCESSING\")\n",
    "            print(\"=\" * 50)\n",
    "            print(f\"ü§ñ Model: {TRANSFORMER_OCR_MODELS[ocr_selector.value]['name']}\")\n",
    "            print(f\"üñ•Ô∏è Device: {current_system.device}\")\n",
    "            print(f\"üì¶ Batch Size: {batch_size.value}\")\n",
    "            print(f\"üìÅ Directory: {gallery_path.value}\")\n",
    "            print(\"‚ú® Pure processing - no LLM/Ollama required\")\n",
    "            \n",
    "            try:\n",
    "                update_status(\"Processing with Pure Transformer OCR...\", 50, get_memory_usage())\n",
    "                current_system.process_images()\n",
    "                \n",
    "                # Show performance summary\n",
    "                stats = current_system.get_model_performance_stats()\n",
    "                print(f\"\\nüìä PROCESSING SUMMARY:\")\n",
    "                print(f\"  üéØ Success Rate: {stats['success_rate']:.1f}%\")\n",
    "                print(f\"  ‚ö° Avg Processing Time: {stats['avg_processing_time']:.2f}s per image\")\n",
    "                print(f\"  üìè Avg Text Length: {stats['avg_text_length']:.0f} characters\")\n",
    "                print(f\"  üéöÔ∏è Avg Confidence: {stats['avg_confidence']:.3f}\")\n",
    "                \n",
    "                update_status(\"Pure processing complete!\", 100, get_memory_usage())\n",
    "                \n",
    "            except Exception as e:\n",
    "                update_status(\"Processing error\", 0)\n",
    "                print(f\"‚ùå Processing error: {e}\")\n",
    "\n",
    "    def on_semantic_search(b):\n",
    "        nonlocal current_results\n",
    "        with output_area:\n",
    "            clear_output(wait=True)\n",
    "            \n",
    "            if not current_system and not init_system():\n",
    "                print(\"‚ùå System not ready\")\n",
    "                return\n",
    "                \n",
    "            query = search_input.value.strip()\n",
    "            if not query or query == \"Enter search query...\":\n",
    "                print(\"‚ö†Ô∏è Please enter a search query\")\n",
    "                return\n",
    "                \n",
    "            update_status(\"Performing semantic search...\", 30, get_memory_usage())\n",
    "            \n",
    "            try:\n",
    "                print(f\"üîç PURE SEMANTIC SEARCH\")\n",
    "                print(f\"Query: '{query}'\")\n",
    "                print(f\"Model: {TRANSFORMER_OCR_MODELS[current_system.config['OCR_MODEL']]['name']}\")\n",
    "                print(\"üöÄ Using pure embeddings (no LLM required)\")\n",
    "                \n",
    "                current_results = current_system.semantic_search(query, k=15)\n",
    "                matches = current_results.get('matches', [])\n",
    "                \n",
    "                if matches:\n",
    "                    update_status(f\"Found {len(matches)} semantic matches\", 100, get_memory_usage())\n",
    "                    export_btn.disabled = False\n",
    "                    \n",
    "                    print(f\"\\nüéØ SEARCH RESULTS ({current_results.get('search_time', 0):.2f}s):\")\n",
    "                    print(\"-\" * 60)\n",
    "                    \n",
    "                    for i, match in enumerate(matches[:8], 1):  # Show top 8\n",
    "                        print(f\"{i}. {match['filename']}\")\n",
    "                        print(f\"   üéØ Similarity: {match.get('similarity_score', 0):.3f}\")\n",
    "                        print(f\"   üéöÔ∏è OCR Confidence: {match['ocr_confidence']:.3f}\")\n",
    "                        print(f\"   üìè Text Length: {match.get('text_length', 0)} chars\")\n",
    "                        print(f\"   üìù Text: {match['extracted_text'][:120]}...\")\n",
    "                        \n",
    "                        if match.get('keywords'):\n",
    "                            print(f\"   üîë Keywords: {', '.join(match['keywords'][:4])}\")\n",
    "                        print()\n",
    "                        \n",
    "                    # Display results visually\n",
    "                    if matches:\n",
    "                        display_pure_results([m['filename'] for m in matches[:6]], current_system)\n",
    "                        \n",
    "                else:\n",
    "                    update_status(\"No semantic matches found\", 100)\n",
    "                    export_btn.disabled = True\n",
    "                    print(\"‚ùå No semantic matches found\")\n",
    "                    print(\"üí° Try different search terms or check if images are processed\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                update_status(\"Search error\", 0)\n",
    "                print(f\"‚ùå Search error: {e}\")\n",
    "\n",
    "    def on_keyword_search(b):\n",
    "        nonlocal current_results\n",
    "        with output_area:\n",
    "            clear_output(wait=True)\n",
    "            \n",
    "            if not current_system and not init_system():\n",
    "                print(\"‚ùå System not ready\")\n",
    "                return\n",
    "                \n",
    "            query = search_input.value.strip()\n",
    "            if not query or query == \"Enter search query...\":\n",
    "                print(\"‚ö†Ô∏è Please enter a search query\")\n",
    "                return\n",
    "                \n",
    "            update_status(\"Performing keyword search...\", 30)\n",
    "            \n",
    "            try:\n",
    "                print(f\"üî§ KEYWORD SEARCH\")\n",
    "                print(f\"Query: '{query}'\")\n",
    "                print(\"üîç Searching in extracted text\")\n",
    "                \n",
    "                current_results = current_system.keyword_search(query)\n",
    "                matches = current_results.get('matches', [])\n",
    "                \n",
    "                if matches:\n",
    "                    update_status(f\"Found {len(matches)} keyword matches\", 100)\n",
    "                    export_btn.disabled = False\n",
    "                    \n",
    "                    print(f\"\\nüìù KEYWORD RESULTS ({current_results.get('search_time', 0):.2f}s):\")\n",
    "                    print(\"-\" * 60)\n",
    "                    \n",
    "                    for i, match in enumerate(matches[:10], 1):  # Show top 10\n",
    "                        print(f\"{i}. {match['filename']}\")\n",
    "                        print(f\"   üéØ Relevance: {match.get('relevance_score', 0):.3f}\")\n",
    "                        print(f\"   üéöÔ∏è OCR Confidence: {match['ocr_confidence']:.3f}\")\n",
    "                        print(f\"   üìè Text Length: {match.get('text_length', 0)} chars\")\n",
    "                        print(f\"   üìù Text: {match['extracted_text'][:120]}...\")\n",
    "                        print()\n",
    "                        \n",
    "                    # Display results visually\n",
    "                    if matches:\n",
    "                        display_pure_results([m['filename'] for m in matches[:6]], current_system)\n",
    "                        \n",
    "                else:\n",
    "                    update_status(\"No keyword matches found\", 100)\n",
    "                    export_btn.disabled = True\n",
    "                    print(\"‚ùå No keyword matches found\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                update_status(\"Keyword search error\", 0)\n",
    "                print(f\"‚ùå Keyword search error: {e}\")\n",
    "\n",
    "    def on_stats(b):\n",
    "        with output_area:\n",
    "            clear_output(wait=True)\n",
    "            \n",
    "            if not current_system and not init_system():\n",
    "                print(\"‚ùå System not ready\")\n",
    "                return\n",
    "                \n",
    "            try:\n",
    "                print(\"üìä PURE TRANSFORMER OCR STATISTICS\")\n",
    "                print(\"=\" * 50)\n",
    "                \n",
    "                # Overall stats\n",
    "                stats = current_system.get_model_performance_stats()\n",
    "                print(f\"üìà MODEL PERFORMANCE:\")\n",
    "                print(f\"  Model: {stats['model_name']}\")\n",
    "                print(f\"  Total Processed: {stats['total_processed']} images\")\n",
    "                print(f\"  Success Rate: {stats['success_rate']:.1f}%\")\n",
    "                print(f\"  Avg Confidence: {stats['avg_confidence']:.3f}\")\n",
    "                print(f\"  Avg Processing Time: {stats['avg_processing_time']:.2f}s per image\")\n",
    "                print(f\"  Avg Text Length: {stats['avg_text_length']:.0f} characters\")\n",
    "                \n",
    "                # Recent activity\n",
    "                recent = current_system.conn.execute('''SELECT COUNT(*) FROM image_texts \n",
    "                    WHERE datetime(processed_date) > datetime('now', '-7 days')''').fetchone()[0]\n",
    "                print(f\"\\nüìÖ RECENT ACTIVITY:\")\n",
    "                print(f\"  Images processed (last 7 days): {recent}\")\n",
    "                \n",
    "                # Search history\n",
    "                searches = current_system.conn.execute('''SELECT COUNT(*) FROM text_searches \n",
    "                    WHERE datetime(search_date) > datetime('now', '-7 days')''').fetchone()[0]\n",
    "                print(f\"  Searches performed (last 7 days): {searches}\")\n",
    "                \n",
    "                # Top keywords\n",
    "                all_keywords = current_system.conn.execute('''SELECT text_keywords FROM image_texts \n",
    "                    WHERE text_keywords IS NOT NULL''').fetchall()\n",
    "                \n",
    "                keyword_counts = {}\n",
    "                for (keywords_json,) in all_keywords:\n",
    "                    try:\n",
    "                        keywords = json.loads(keywords_json)\n",
    "                        for keyword in keywords:\n",
    "                            keyword_counts[keyword] = keyword_counts.get(keyword, 0) + 1\n",
    "                    except:\n",
    "                        continue\n",
    "                \n",
    "                if keyword_counts:\n",
    "                    top_keywords = sorted(keyword_counts.items(), key=lambda x: x[1], reverse=True)[:10]\n",
    "                    print(f\"\\nüîë TOP KEYWORDS:\")\n",
    "                    for keyword, count in top_keywords:\n",
    "                        print(f\"  {keyword}: {count} occurrences\")\n",
    "                \n",
    "                update_status(\"Statistics displayed\", 100)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Statistics error: {e}\")\n",
    "\n",
    "    def on_export(b):\n",
    "        with output_area:\n",
    "            if not current_results:\n",
    "                print(\"‚ö†Ô∏è No search results to export\")\n",
    "                return\n",
    "            try:\n",
    "                update_status(\"Exporting pure results...\", 50)\n",
    "                path = current_system.export_pure_results(current_results, search_input.value or \"search\")\n",
    "                update_status(\"Export complete!\", 100)\n",
    "                print(f\"‚úÖ Pure Transformer results exported to: {path}\")\n",
    "            except Exception as e:\n",
    "                update_status(\"Export error\", 0)\n",
    "                print(f\"‚ùå Export error: {e}\")\n",
    "\n",
    "    def on_clear(b):\n",
    "        nonlocal current_results\n",
    "        current_results = None\n",
    "        export_btn.disabled = True\n",
    "        with output_area:\n",
    "            clear_output()\n",
    "            update_status(\"Output cleared\", 0)\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "                memory_info.value = f\"<b>Memory:</b> {get_memory_usage()}\"\n",
    "\n",
    "    # Connect events\n",
    "    model_info_btn.on_click(on_model_info)\n",
    "    test_setup_btn.on_click(on_test_setup)\n",
    "    process_btn.on_click(on_process)\n",
    "    semantic_btn.on_click(on_semantic_search)\n",
    "    keyword_btn.on_click(on_keyword_search)\n",
    "    stats_btn.on_click(on_stats)\n",
    "    export_btn.on_click(on_export)\n",
    "    clear_btn.on_click(on_clear)\n",
    "\n",
    "    # Layout\n",
    "    header = widgets.HTML(\"\"\"\n",
    "        <h2>ü§ñ Pure Transformer OCR Image Search System</h2>\n",
    "        <p><i>Microsoft TrOCR and AllenAI OLMo OCR - No Ollama or BLIP dependencies</i></p>\n",
    "        <p><b>Features:</b> Pure transformer processing, semantic search, GPU acceleration</p>\n",
    "    \"\"\")\n",
    "\n",
    "    config_section = widgets.VBox([\n",
    "        widgets.HTML(\"<h3>üîß Pure Transformer Configuration</h3>\"),\n",
    "        ocr_selector,\n",
    "        widgets.HBox([device_selector, batch_size]),\n",
    "        gallery_path,\n",
    "        confidence_threshold\n",
    "    ])\n",
    "\n",
    "    search_section = widgets.VBox([\n",
    "        widgets.HTML(\"<h3>üîç Search Interface</h3>\"),\n",
    "        search_input,\n",
    "        search_type,\n",
    "        widgets.HTML(\"<b>Quick Search Examples:</b>\"),\n",
    "        widgets.GridBox(quick_search_btns, layout=widgets.Layout(grid_template_columns='repeat(3, 1fr)', grid_gap='5px'))\n",
    "    ])\n",
    "\n",
    "    controls_section = widgets.VBox([\n",
    "        widgets.HTML(\"<h3>üéõÔ∏è Actions</h3>\"),\n",
    "        widgets.HBox([model_info_btn, test_setup_btn]),\n",
    "        widgets.HBox([process_btn, semantic_btn]),\n",
    "        widgets.HBox([keyword_btn, stats_btn]),\n",
    "        widgets.HBox([export_btn, clear_btn])\n",
    "    ])\n",
    "\n",
    "    status_section = widgets.VBox([\n",
    "        widgets.HTML(\"<hr>\"),\n",
    "        status_label,\n",
    "        progress_bar,\n",
    "        memory_info\n",
    "    ])\n",
    "\n",
    "    main_interface = widgets.VBox([\n",
    "        header,\n",
    "        config_section,\n",
    "        search_section,\n",
    "        controls_section,\n",
    "        status_section,\n",
    "        output_area\n",
    "    ])\n",
    "\n",
    "    return main_interface\n",
    "\n",
    "def display_pure_results(filenames: List[str], system: PureTransformerOCRSystem, max_images=6):\n",
    "    \"\"\"Display results from pure transformer OCR\"\"\"\n",
    "    if not filenames:\n",
    "        return\n",
    "\n",
    "    num = min(len(filenames), max_images)\n",
    "    cols = 3 if num > 4 else 2 if num > 1 else 1\n",
    "    rows = (num + cols - 1) // cols\n",
    "\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(16, 6*rows))\n",
    "    if num == 1:\n",
    "        axes = [axes]\n",
    "    elif rows == 1:\n",
    "        axes = axes if num > 1 else [axes]\n",
    "    else:\n",
    "        axes = axes.flatten()\n",
    "\n",
    "    for i, filename in enumerate(filenames[:num]):\n",
    "        ax = axes[i] if num > 1 else axes[0]\n",
    "        \n",
    "        try:\n",
    "            # Get info from database\n",
    "            result = system.conn.execute('''SELECT full_path, extracted_text, ocr_confidence, \n",
    "                text_keywords, text_length, ocr_model, processing_time FROM image_texts WHERE filename = ?''', \n",
    "                (filename,)).fetchone()\n",
    "\n",
    "            if not result:\n",
    "                ax.text(0.5, 0.5, f\"Not found\\n{filename}\", ha='center', va='center', transform=ax.transAxes)\n",
    "                ax.axis('off')\n",
    "                continue\n",
    "\n",
    "            full_path, text, confidence, keywords_json, text_len, ocr_model, proc_time = result\n",
    "\n",
    "            try:\n",
    "                img = plt.imread(full_path)\n",
    "                ax.imshow(img)\n",
    "            except:\n",
    "                ax.text(0.5, 0.5, f\"Image load error\\n{filename}\", ha='center', va='center', transform=ax.transAxes)\n",
    "                ax.axis('off')\n",
    "                continue\n",
    "\n",
    "            # Title with model info\n",
    "            model_name = TRANSFORMER_OCR_MODELS.get(ocr_model, {}).get('name', 'Unknown')[:20]\n",
    "            conf_color = \"green\" if confidence > 0.9 else \"orange\" if confidence > 0.7 else \"red\"\n",
    "            \n",
    "            title = f\"{filename}\\n{model_name}\\nConf: {confidence:.3f} | {proc_time:.2f}s\"\n",
    "            ax.set_title(title, fontsize=9, color=conf_color, fontweight='bold')\n",
    "\n",
    "            # Text preview\n",
    "            text_preview = text[:80] if text else \"No text detected\"\n",
    "            ax.text(0.02, 0.98, f\"üìù {text_preview}...\", transform=ax.transAxes, fontsize=8,\n",
    "                   verticalalignment='top', \n",
    "                   bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"lightblue\", alpha=0.9))\n",
    "\n",
    "            # Text statistics\n",
    "            ax.text(0.02, 0.12, f\"üìä Length: {text_len} chars\", transform=ax.transAxes, fontsize=7,\n",
    "                   verticalalignment='top',\n",
    "                   bbox=dict(boxstyle=\"round,pad=0.2\", facecolor=\"lightyellow\", alpha=0.8))\n",
    "                           \n",
    "            # Keywords if available\n",
    "            if keywords_json:\n",
    "                try:\n",
    "                    keywords = json.loads(keywords_json)[:3]\n",
    "                    if keywords:\n",
    "                        ax.text(0.02, 0.02, f\"üîë {', '.join(keywords)}\", transform=ax.transAxes, fontsize=7,\n",
    "                               verticalalignment='bottom',\n",
    "                               bbox=dict(boxstyle=\"round,pad=0.2\", facecolor=\"lightgreen\", alpha=0.7))\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "            ax.axis('off')\n",
    "\n",
    "        except Exception as e:\n",
    "            ax.text(0.5, 0.5, f\"Display Error\\n{filename}\\n{str(e)[:20]}\", \n",
    "                   ha='center', va='center', transform=ax.transAxes, fontsize=8)\n",
    "            ax.axis('off')\n",
    "\n",
    "    # Hide unused subplots\n",
    "    for j in range(num, len(axes)):\n",
    "        axes[j].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.suptitle('ü§ñ Pure Transformer OCR Results', fontsize=16, y=1.02)\n",
    "    plt.show()\n",
    "\n",
    "# Utility functions for Pure Transformer OCR\n",
    "def quick_pure_setup():\n",
    "    \"\"\"Quick setup check for Pure Transformer OCR\"\"\"\n",
    "    print(\"ü§ñ PURE TRANSFORMER OCR SETUP CHECK\")\n",
    "    print(\"=\" * 50)\n",
    "    print(\"‚ú® No Ollama or BLIP dependencies required!\")\n",
    "    \n",
    "    # Check PyTorch and GPU\n",
    "    print(f\"‚úÖ PyTorch: {torch.__version__}\")\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"‚úÖ CUDA: {torch.version.cuda}\")\n",
    "        print(f\"üéÆ GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    else:\n",
    "        print(\"üíª CPU only (slower processing)\")\n",
    "    \n",
    "    # Check Transformers\n",
    "    try:\n",
    "        import transformers\n",
    "        print(f\"‚úÖ Transformers: {transformers.__version__}\")\n",
    "    except:\n",
    "        print(\"‚ùå Transformers not found: pip install transformers\")\n",
    "    \n",
    "    # Check pure dependencies\n",
    "    deps = ['sentence_transformers', 'chromadb']\n",
    "    print(f\"\\nüì¶ Pure dependencies:\")\n",
    "    for dep in deps:\n",
    "        try:\n",
    "            __import__(dep.replace('-', '_'))\n",
    "            print(f\"‚úÖ {dep}\")\n",
    "        except:\n",
    "            print(f\"‚ùå {dep}\")\n",
    "\n",
    "def quick_pure_search(query: str, \n",
    "                     image_folder: str = '../../datasets/images/text_ocr',\n",
    "                     model: str = 'microsoft_trocr'):\n",
    "    \"\"\"Quick search using Pure Transformer OCR\"\"\"\n",
    "    print(f\"ü§ñ PURE TRANSFORMER OCR SEARCH\")\n",
    "    print(f\"Query: '{query}'\")\n",
    "    print(f\"Model: {TRANSFORMER_OCR_MODELS[model]['name']}\")\n",
    "    print(f\"Folder: {image_folder}\")\n",
    "    print(\"üöÄ Pure processing - no Ollama/BLIP required\")\n",
    "    \n",
    "    try:\n",
    "        config = CONFIG.copy()\n",
    "        config.update({\n",
    "            'IMAGE_GALLERY_PATH': image_folder,\n",
    "            'OCR_MODEL': model,\n",
    "            'DEVICE': 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        })\n",
    "        \n",
    "        system = PureTransformerOCRSystem(config)\n",
    "        \n",
    "        # Check if images are processed with this model\n",
    "        count = system.conn.execute(\n",
    "            \"SELECT COUNT(*) FROM image_texts WHERE vector_stored = 1 AND ocr_model = ?\",\n",
    "            (model,)\n",
    "        ).fetchone()[0]\n",
    "        \n",
    "        if count == 0:\n",
    "            print(\"üìÅ Processing images with Pure Transformer OCR...\")\n",
    "            system.process_images()\n",
    "        \n",
    "        # Perform semantic search\n",
    "        results = system.semantic_search(query, k=10)\n",
    "        matches = results.get('matches', [])\n",
    "        \n",
    "        if matches:\n",
    "            print(f\"\\n‚úÖ Found {len(matches)} semantic matches:\")\n",
    "            print(\"-\" * 50)\n",
    "            \n",
    "            for i, match in enumerate(matches[:5], 1):\n",
    "                print(f\"{i}. {match['filename']}\")\n",
    "                print(f\"   üéØ Similarity: {match.get('similarity_score', 0):.3f}\")\n",
    "                print(f\"   üéöÔ∏è OCR Confidence: {match['ocr_confidence']:.3f}\")\n",
    "                print(f\"   üìè Text Length: {match.get('text_length', 0)} chars\")\n",
    "                print(f\"   üìù Text: {match['extracted_text'][:100]}...\")\n",
    "                \n",
    "                if match.get('keywords'):\n",
    "                    print(f\"   üîë Keywords: {', '.join(match['keywords'][:4])}\")\n",
    "                print()\n",
    "            \n",
    "            # Export results\n",
    "            path = system.export_pure_results(results, query)\n",
    "            print(f\"üìã Results exported to: {path}\")\n",
    "            \n",
    "            # Show model performance\n",
    "            stats = system.get_model_performance_stats()\n",
    "            print(f\"\\nüìä MODEL PERFORMANCE:\")\n",
    "            print(f\"   Success Rate: {stats['success_rate']:.1f}%\")\n",
    "            print(f\"   Avg Processing Time: {stats['avg_processing_time']:.2f}s\")\n",
    "            print(f\"   Avg Confidence: {stats['avg_confidence']:.3f}\")\n",
    "            \n",
    "        else:\n",
    "            print(\"‚ùå No semantic matches found\")\n",
    "            print(\"üí° Try different search terms or check image content\")\n",
    "        \n",
    "        system.close()\n",
    "        return results\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error: {e}\")\n",
    "        return None\n",
    "\n",
    "def compare_pure_models(image_folder: str = '../../datasets/images/text_ocr',\n",
    "                       models: List[str] = ['microsoft_trocr', 'microsoft_trocr_handwritten']):\n",
    "    \"\"\"Compare Pure Transformer OCR models (no Ollama/BLIP)\"\"\"\n",
    "    print(\"üèÜ PURE TRANSFORMER OCR MODEL COMPARISON\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"‚ú® Comparing pure models - no external dependencies\")\n",
    "    \n",
    "    comparison_results = {}\n",
    "    \n",
    "    for model in models:\n",
    "        if model not in TRANSFORMER_OCR_MODELS or model == 'salesforce_blip':\n",
    "            print(f\"‚ö†Ô∏è Skipping model: {model}\")\n",
    "            continue\n",
    "            \n",
    "        print(f\"\\nü§ñ Testing: {TRANSFORMER_OCR_MODELS[model]['name']}\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        try:\n",
    "            config = CONFIG.copy()\n",
    "            config.update({\n",
    "                'IMAGE_GALLERY_PATH': image_folder,\n",
    "                'OCR_MODEL': model,\n",
    "                'DEVICE': 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "            })\n",
    "            \n",
    "            system = PureTransformerOCRSystem(config)\n",
    "            \n",
    "            # Process a sample of images\n",
    "            gallery_path = Path(image_folder)\n",
    "            if not gallery_path.exists():\n",
    "                print(f\"‚ùå Folder not found: {image_folder}\")\n",
    "                continue\n",
    "                \n",
    "            # Get first 10 images for quick comparison\n",
    "            exts = ['.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.webp']\n",
    "            sample_files = []\n",
    "            for ext in exts:\n",
    "                sample_files.extend(list(gallery_path.glob(f\"*{ext}\"))[:10])\n",
    "                if len(sample_files) >= 10:\n",
    "                    break\n",
    "            \n",
    "            if not sample_files:\n",
    "                print(\"‚ùå No images found for comparison\")\n",
    "                continue\n",
    "                \n",
    "            # Process sample images\n",
    "            start_time = time.time()\n",
    "            successful = 0\n",
    "            total_confidence = 0\n",
    "            total_text_length = 0\n",
    "            \n",
    "            for img_path in sample_files[:10]:\n",
    "                result = system.extract_text(img_path)\n",
    "                if result['extracted_text'].strip() and not result.get('error'):\n",
    "                    successful += 1\n",
    "                    total_confidence += result['ocr_confidence']\n",
    "                    total_text_length += len(result['extracted_text'])\n",
    "            \n",
    "            total_time = time.time() - start_time\n",
    "            \n",
    "            # Calculate metrics\n",
    "            success_rate = successful / len(sample_files) * 100\n",
    "            avg_confidence = total_confidence / successful if successful > 0 else 0\n",
    "            avg_time = total_time / len(sample_files)\n",
    "            avg_text_length = total_text_length / successful if successful > 0 else 0\n",
    "            \n",
    "            comparison_results[model] = {\n",
    "                'name': TRANSFORMER_OCR_MODELS[model]['name'],\n",
    "                'success_rate': success_rate,\n",
    "                'avg_confidence': avg_confidence,\n",
    "                'avg_time': avg_time,\n",
    "                'avg_text_length': avg_text_length,\n",
    "                'total_processed': len(sample_files),\n",
    "                'successful_extractions': successful\n",
    "            }\n",
    "            \n",
    "            print(f\"‚úÖ Success Rate: {success_rate:.1f}%\")\n",
    "            print(f\"‚ö° Avg Time: {avg_time:.2f}s per image\")\n",
    "            print(f\"üéöÔ∏è Avg Confidence: {avg_confidence:.3f}\")\n",
    "            print(f\"üìè Avg Text Length: {avg_text_length:.0f} chars\")\n",
    "            \n",
    "            system.close()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error testing {model}: {e}\")\n",
    "            \n",
    "    # Summary comparison\n",
    "    if len(comparison_results) > 1:\n",
    "        print(f\"\\nüèÜ PURE MODEL COMPARISON SUMMARY\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        # Sort by success rate\n",
    "        sorted_results = sorted(comparison_results.items(), \n",
    "                              key=lambda x: x[1]['success_rate'], \n",
    "                              reverse=True)\n",
    "        \n",
    "        for i, (model, data) in enumerate(sorted_results, 1):\n",
    "            print(f\"{i}. {data['name']}\")\n",
    "            print(f\"   üéØ Success: {data['success_rate']:.1f}%\")\n",
    "            print(f\"   ‚ö° Speed: {data['avg_time']:.2f}s\")\n",
    "            print(f\"   üéöÔ∏è Quality: {data['avg_confidence']:.3f}\")\n",
    "            print()\n",
    "            \n",
    "        best_model = sorted_results[0]\n",
    "        print(f\"üèÜ WINNER: {best_model[1]['name']}\")\n",
    "        print(f\"   Best pure transformer performance for your dataset\")\n",
    "        \n",
    "    return comparison_results\n",
    "\n",
    "# Create and display the Pure Transformer OCR interface\n",
    "print(\"ü§ñ Creating Pure Transformer OCR Interface...\")\n",
    "print(\"üéØ Features: TrOCR, OLMo OCR, GPU acceleration, pure processing\")\n",
    "print(\"‚ú® No Ollama or BLIP dependencies required!\")\n",
    "\n",
    "pure_transformer_interface = create_pure_transformer_gui()\n",
    "display(pure_transformer_interface)\n",
    "\n",
    "print(f\"\\nü§ñ PURE TRANSFORMER OCR SYSTEM READY!\")\n",
    "print(\"=\" * 70)\n",
    "print(\"üîí PRIVACY: 100% local processing with pure Transformer models\")\n",
    "print(\"ü§ñ MODELS: Microsoft TrOCR variants, AllenAI OLMo OCR (placeholder)\")\n",
    "print(\"‚ö° ACCELERATION: GPU support for faster processing\")\n",
    "print(\"üîç SEARCH: Pure semantic search with embeddings\")\n",
    "print(\"üìä ANALYSIS: Simple text analysis without LLM dependency\")\n",
    "print(\"üöÄ SETUP: Automatic model download, GPU detection\")\n",
    "print(\"‚ú® PURE: No Ollama, no BLIP, no external LLM required\")\n",
    "print(\"üí° QUICK: quick_pure_setup() | quick_pure_search('text', './images', 'microsoft_trocr')\")\n",
    "print(\"üèÜ COMPARE: compare_pure_models('./images', ['microsoft_trocr', 'microsoft_trocr_handwritten'])\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\nü§ñ PURE TRANSFORMER OCR USAGE GUIDE:\")\n",
    "print(\"1. Select your preferred Transformer OCR model (TrOCR variants)\")\n",
    "print(\"2. Choose GPU/CPU processing (GPU recommended for speed)\")\n",
    "print(\"3. Process images to extract text with pure AI models\")\n",
    "print(\"4. Perform semantic search using embeddings (no LLM needed)\")\n",
    "print(\"5. Use keyword search for exact text matching\")\n",
    "print(\"6. View statistics and performance metrics\")\n",
    "print(\"7. Export results with detailed analysis\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\nüìã PURE MODEL RECOMMENDATIONS:\")\n",
    "print(\"‚Ä¢ microsoft_trocr: Best for clean printed documents and forms\")\n",
    "print(\"‚Ä¢ microsoft_trocr_handwritten: Specialized for handwritten text\")\n",
    "print(\"‚Ä¢ microsoft_trocr_large: High accuracy for complex documents\")\n",
    "print(\"‚Ä¢ allenai_olmo_ocr: Advanced reasoning (requires implementation)\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\nüöÄ KEY BENEFITS OF PURE APPROACH:\")\n",
    "print(\"‚Ä¢ No external dependencies (Ollama/BLIP)\")\n",
    "print(\"‚Ä¢ Faster setup and processing\")\n",
    "print(\"‚Ä¢ Pure Transformer architecture\")\n",
    "print(\"‚Ä¢ GPU acceleration for speed\")\n",
    "print(\"‚Ä¢ Semantic search with embeddings\")\n",
    "print(\"‚Ä¢ Simple text analysis without LLM complexity\")\n",
    "print(\"‚Ä¢ 100% local and private processing\")\n",
    "print(\"=\" * 70)"
   ],
   "id": "7db1955974b0aaed"
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
