{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": "'../../../datasets/images/text_ocr'",
   "id": "7bc22bc60a24b8bd",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-25T18:37:45.655856Z",
     "start_time": "2025-07-25T18:37:43.396868Z"
    }
   },
   "source": [
    "# Compact Local Forensic OCR System with GUI\n",
    "import os, json, sqlite3, shutil, warnings, time\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from typing import List, Dict, Any, Optional\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "# Disable PaddleOCR analytics to prevent connection errors\n",
    "os.environ['DISABLE_TELEMETRY'] = '1'\n",
    "os.environ['PADDLEOCR_DISABLE_TELEMETRY'] = '1'\n",
    "os.environ['HUB_ANALYTICS'] = 'False'\n",
    "\n",
    "# Compact config with OCR options\n",
    "CONFIG = {\n",
    "    'OCR_MODEL': 'paddleocr', 'OCR_CONFIDENCE_THRESHOLD': 0.6,\n",
    "    'LLM_PROVIDER': 'ollama', 'LLM_MODEL': 'llama3.2:latest', 'LLM_BASE_URL': 'http://localhost:11434',\n",
    "    'LLM_TEMPERATURE': 0.1, 'LLM_MAX_TOKENS': 1000,\n",
    "    'EMBEDDING_PROVIDER': 'huggingface', 'EMBEDDING_MODEL': 'sentence-transformers/all-MiniLM-L6-v2',\n",
    "    'VECTOR_STORE_PATH': './forensic_vectorstore', 'CHUNK_SIZE': 500, 'CHUNK_OVERLAP': 50,\n",
    "    'SUSPECTS_GALLERY_PATH': '../../../datasets/images/text_ocr', 'DATABASE_PATH': './forensic_analysis_db',\n",
    "    'RESULTS_OUTPUT_PATH': './forensic_results', 'BATCH_SIZE': 4, 'MAX_RESULTS_DISPLAY': 10,\n",
    "}\n",
    "\n",
    "# OCR model options for different evidence types\n",
    "OCR_MODELS = {\n",
    "    'paddleocr': {'name': 'PaddleOCR', 'desc': 'Best overall, 80+ languages, handwriting capable', 'strengths': 'Asian text, complex layouts'},\n",
    "    'easyocr': {'name': 'EasyOCR', 'desc': 'Good for European languages, simple setup', 'strengths': 'European text, clean images'},\n",
    "    'tesseract': {'name': 'Tesseract', 'desc': 'Classic OCR, best for clean printed text', 'strengths': 'Printed documents, stable'},\n",
    "    'trocr': {'name': 'TrOCR (Transformers)', 'desc': 'AI-based, excellent for handwriting', 'strengths': 'Handwritten notes, degraded images'}\n",
    "}\n",
    "\n",
    "print(f\"üè† LOCAL FORENSIC SYSTEM | LLM: {CONFIG['LLM_PROVIDER']}-{CONFIG['LLM_MODEL']} | üîí 100% Private\")\n",
    "\n",
    "# Quick dependency check\n",
    "def check_deps():\n",
    "    deps = ['paddleocr', 'langchain', 'chromadb', 'sentence_transformers']\n",
    "    for dep in deps:\n",
    "        try: __import__(dep.replace('-', '_')); print(f\"‚úÖ {dep}\")\n",
    "        except ImportError: print(f\"‚ùå {dep} - Install: pip install {dep}\")\n",
    "\n",
    "def check_ollama():\n",
    "    try:\n",
    "        import requests\n",
    "        r = requests.get(f\"{CONFIG['LLM_BASE_URL']}/api/tags\", timeout=5)\n",
    "        if r.status_code == 200:\n",
    "            models = [m['name'] for m in r.json().get('models', [])]\n",
    "            print(f\"‚úÖ Ollama: {models}\")\n",
    "            return CONFIG['LLM_MODEL'] in models\n",
    "        return False\n",
    "    except: print(\"‚ùå Ollama not running\"); return False\n",
    "\n",
    "check_deps()\n",
    "ollama_ready = check_ollama() if CONFIG['LLM_PROVIDER'] == 'ollama' else True\n",
    "\n",
    "\n",
    "# Add error handling for OCR initialization\n",
    "def init_ocr_safe():\n",
    "    try:\n",
    "        from paddleocr import PaddleOCR\n",
    "        return PaddleOCR(\n",
    "            use_textline_orientation=True,\n",
    "            lang='en',\n",
    "            show_log=False,  # Disable logging\n",
    "            use_gpu=False    # Force CPU to avoid GPU errors\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"OCR initialization error: {e}\")\n",
    "        return None\n",
    "\n",
    "# Compact forensic system\n",
    "class CompactForensicSystem:\n",
    "    def __init__(self, config=None):\n",
    "        self.config = config or CONFIG.copy()\n",
    "        self._setup_dirs()\n",
    "        self._init_db()\n",
    "        self._init_ocr()\n",
    "        self._init_llm()\n",
    "\n",
    "    def _setup_dirs(self):\n",
    "        for k in ['SUSPECTS_GALLERY_PATH', 'DATABASE_PATH', 'RESULTS_OUTPUT_PATH', 'VECTOR_STORE_PATH']:\n",
    "            os.makedirs(self.config[k], exist_ok=True)\n",
    "\n",
    "    def _init_db(self):\n",
    "        db_path = os.path.join(self.config['DATABASE_PATH'], 'forensic.db')\n",
    "        self.conn = sqlite3.connect(db_path)\n",
    "        self.conn.execute('''CREATE TABLE IF NOT EXISTS forensic_images (\n",
    "            id INTEGER PRIMARY KEY, filename TEXT UNIQUE, full_path TEXT, extracted_text TEXT,\n",
    "            ocr_confidence REAL, processed_date TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
    "            local_analysis TEXT, risk_score REAL, contains_incriminating BOOLEAN DEFAULT 0,\n",
    "            vector_stored BOOLEAN DEFAULT 0)''')\n",
    "        self.conn.execute('''CREATE TABLE IF NOT EXISTS local_investigations (\n",
    "            id INTEGER PRIMARY KEY, query TEXT, investigation_date TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
    "            results_json TEXT, flagged_images TEXT, model_used TEXT, processing_time REAL)''')\n",
    "        self.conn.commit()\n",
    "\n",
    "\n",
    "    def _init_ocr(self):\n",
    "        try:\n",
    "            ocr_model = self.config['OCR_MODEL']\n",
    "            if ocr_model == 'paddleocr':\n",
    "                from paddleocr import PaddleOCR\n",
    "                self.ocr = init_ocr_safe()\n",
    "            elif ocr_model == 'easyocr':\n",
    "                import easyocr\n",
    "                self.ocr = easyocr.Reader(['en'], gpu=False)\n",
    "            elif ocr_model == 'tesseract':\n",
    "                import pytesseract\n",
    "                self.ocr = pytesseract\n",
    "            elif ocr_model == 'trocr':\n",
    "                from transformers import TrOCRProcessor, VisionEncoderDecoderModel\n",
    "                self.ocr_processor = TrOCRProcessor.from_pretrained('microsoft/trocr-base-printed')\n",
    "                self.ocr_model = VisionEncoderDecoderModel.from_pretrained('microsoft/trocr-base-printed')\n",
    "                self.ocr = 'trocr'\n",
    "            print(f\"‚úÖ {OCR_MODELS[ocr_model]['name']} ready\")\n",
    "        except Exception as e: print(f\"‚ùå OCR error: {e}\"); self.ocr = None\n",
    "\n",
    "    def _init_llm(self):\n",
    "        try:\n",
    "            if self.config['LLM_PROVIDER'] == 'ollama':\n",
    "                from langchain_community.llms import Ollama\n",
    "                self.llm = Ollama(model=self.config['LLM_MODEL'], base_url=self.config['LLM_BASE_URL'],\n",
    "                                temperature=self.config['LLM_TEMPERATURE'])\n",
    "            elif self.config['LLM_PROVIDER'] == 'transformers':\n",
    "                from langchain_community.llms import HuggingFacePipeline\n",
    "                from transformers import pipeline\n",
    "                pipe = pipeline(\"text-generation\", model=self.config['LLM_MODEL'],\n",
    "                              max_new_tokens=self.config['LLM_MAX_TOKENS'])\n",
    "                self.llm = HuggingFacePipeline(pipeline=pipe)\n",
    "\n",
    "            from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "            from langchain_community.vectorstores import Chroma\n",
    "            from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "            self.embeddings = HuggingFaceEmbeddings(model_name=self.config['EMBEDDING_MODEL'],\n",
    "                                                  model_kwargs={'device': 'cpu'})\n",
    "            self.vectorstore = Chroma(persist_directory=self.config['VECTOR_STORE_PATH'],\n",
    "                                    embedding_function=self.embeddings)\n",
    "            self.text_splitter = RecursiveCharacterTextSplitter(chunk_size=self.config['CHUNK_SIZE'],\n",
    "                                                              chunk_overlap=self.config['CHUNK_OVERLAP'])\n",
    "            print(\"‚úÖ LangChain ready\")\n",
    "        except Exception as e: print(f\"‚ùå LLM error: {e}\")\n",
    "\n",
    "    def extract_text(self, img_path: str) -> Dict[str, Any]:\n",
    "        try:\n",
    "            img = Image.open(img_path).convert(\"RGB\")\n",
    "            result = {'filename': os.path.basename(img_path), 'full_path': img_path,\n",
    "                     'extracted_text': '', 'ocr_confidence': 0.0, 'error': None}\n",
    "\n",
    "            if self.ocr:\n",
    "                ocr_model = self.config['OCR_MODEL']\n",
    "\n",
    "                if ocr_model == 'paddleocr':\n",
    "                    ocr_result = self.ocr.ocr(np.array(img), cls=True)\n",
    "                    if ocr_result and ocr_result[0]:\n",
    "                        texts, confs = [], []\n",
    "                        for line in ocr_result:\n",
    "                            for detection in line:\n",
    "                                bbox, (text, conf) = detection\n",
    "                                if conf >= self.config['OCR_CONFIDENCE_THRESHOLD']:\n",
    "                                    texts.append(text); confs.append(conf)\n",
    "                        result.update({'extracted_text': ' '.join(texts),\n",
    "                                     'ocr_confidence': np.mean(confs) if confs else 0.0})\n",
    "\n",
    "                elif ocr_model == 'easyocr':\n",
    "                    ocr_result = self.ocr.readtext(np.array(img))\n",
    "                    texts, confs = [], []\n",
    "                    for detection in ocr_result:\n",
    "                        bbox, text, conf = detection\n",
    "                        if conf >= self.config['OCR_CONFIDENCE_THRESHOLD']:\n",
    "                            texts.append(text); confs.append(conf)\n",
    "                    result.update({'extracted_text': ' '.join(texts),\n",
    "                                 'ocr_confidence': np.mean(confs) if confs else 0.0})\n",
    "\n",
    "                elif ocr_model == 'tesseract':\n",
    "                    import pytesseract\n",
    "                    text = pytesseract.image_to_string(img, config='--psm 6')\n",
    "                    if text.strip():\n",
    "                        result.update({'extracted_text': text.strip(), 'ocr_confidence': 0.8})\n",
    "\n",
    "                elif ocr_model == 'trocr':\n",
    "                    pixel_values = self.ocr_processor(images=img, return_tensors=\"pt\").pixel_values\n",
    "                    generated_ids = self.ocr_model.generate(pixel_values)\n",
    "                    text = self.ocr_processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "                    if text.strip():\n",
    "                        result.update({'extracted_text': text.strip(), 'ocr_confidence': 0.9})\n",
    "\n",
    "            return result\n",
    "        except Exception as e:\n",
    "            return {'filename': os.path.basename(img_path), 'full_path': img_path,\n",
    "                   'extracted_text': '', 'ocr_confidence': 0.0, 'error': str(e)}\n",
    "\n",
    "    def analyze_text(self, text: str, filename: str) -> Dict[str, Any]:\n",
    "        prompt = f'''Analyze text from image '{filename}' for criminal evidence:\n",
    "Text: {text}\n",
    "Look for: weapons, drugs, threats, violence, financial crimes, personal info theft.\n",
    "Respond with JSON only:\n",
    "{{\"contains_incriminating\": true/false, \"risk_score\": 0.0-1.0,\n",
    "\"categories\": [\"weapons\",\"drugs\",\"threats\",\"financial_crimes\",\"violence\",\"personal_info\"],\n",
    "\"analysis\": \"explanation\", \"keywords\": [\"words\"], \"evidence_summary\": \"summary\"}}'''\n",
    "\n",
    "        try:\n",
    "            response = str(self.llm.invoke(prompt)).strip()\n",
    "            response = response.replace('```json', '').replace('```', '').strip()\n",
    "            start, end = response.find('{'), response.rfind('}') + 1\n",
    "            if start >= 0 and end > start:\n",
    "                parsed = json.loads(response[start:end])\n",
    "                return {k: parsed.get(k, v) for k, v in [\n",
    "                    ('contains_incriminating', False), ('risk_score', 0.0), ('categories', []),\n",
    "                    ('analysis', ''), ('keywords', []), ('evidence_summary', '')]}\n",
    "            else: return self._fallback_analysis(response, filename)\n",
    "        except: return self._fallback_analysis(response if 'response' in locals() else '', filename)\n",
    "\n",
    "    def _fallback_analysis(self, response: str, filename: str) -> Dict[str, Any]:\n",
    "        keywords = {'weapons': ['weapon','gun','knife','bomb'], 'drugs': ['drug','cocaine','meth'],\n",
    "                   'threats': ['threat','kill','attack'], 'financial_crimes': ['fraud','steal']}\n",
    "        found_cats, found_words, risk = [], [], 0.0\n",
    "        resp_lower = response.lower()\n",
    "        for cat, words in keywords.items():\n",
    "            for word in words:\n",
    "                if word in resp_lower: found_cats.append(cat); found_words.append(word); risk += 0.15\n",
    "        return {'contains_incriminating': risk > 0.3, 'risk_score': min(risk, 1.0),\n",
    "               'categories': list(set(found_cats)), 'analysis': f'Fallback analysis: {response[:100]}',\n",
    "               'keywords': found_words, 'evidence_summary': f'Found {len(found_words)} terms'}\n",
    "\n",
    "    def add_to_vectorstore(self, text: str, metadata: Dict[str, Any]):\n",
    "        try:\n",
    "            from langchain_core.documents import Document\n",
    "            chunks = self.text_splitter.split_text(text)\n",
    "            docs = [Document(page_content=chunk, metadata={**metadata, 'chunk_id': i})\n",
    "                   for i, chunk in enumerate(chunks)]\n",
    "            self.vectorstore.add_documents(docs); self.vectorstore.persist(); return True\n",
    "        except: return False\n",
    "\n",
    "    def process_gallery(self):\n",
    "        start_time = time.time()\n",
    "        gallery_path = Path(self.config['SUSPECTS_GALLERY_PATH'])\n",
    "        print(f\"üè† PROCESSING: {gallery_path} | Model: {self.config['LLM_MODEL']}\")\n",
    "\n",
    "        if not gallery_path.exists(): print(f\"‚ùå Path not found: {gallery_path}\"); return\n",
    "\n",
    "        exts = ['.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.webp']\n",
    "        files = [f for ext in exts for f in list(gallery_path.glob(f\"**/*{ext}\")) + list(gallery_path.glob(f\"**/*{ext.upper()}\"))]\n",
    "        total, processed, vector_stored, incriminating = len(files), 0, 0, 0\n",
    "\n",
    "        print(f\"üì∏ Found {total} images\")\n",
    "        if total == 0: print(\"‚ö†Ô∏è No images found!\"); return\n",
    "\n",
    "        for i, img_path in enumerate(files, 1):\n",
    "            filename = img_path.name\n",
    "            print(f\"[{i:3d}/{total}] ({i/total*100:5.1f}%) {filename[:40]}...\", end='')\n",
    "\n",
    "            # Skip if processed\n",
    "            if self.conn.execute(\"SELECT id FROM forensic_images WHERE filename = ?\", (filename,)).fetchone():\n",
    "                print(\" ‚è≠Ô∏è SKIP\"); continue\n",
    "\n",
    "            # Extract and analyze\n",
    "            ocr_result = self.extract_text(img_path)\n",
    "            if ocr_result.get('error'): print(\" ‚ùå ERROR\"); continue\n",
    "\n",
    "            text = ocr_result['extracted_text']\n",
    "            analysis = None\n",
    "            if text.strip():\n",
    "                analysis = self.analyze_text(text, filename)\n",
    "                metadata = {'filename': filename, 'full_path': str(img_path),\n",
    "                          'ocr_confidence': ocr_result['ocr_confidence']}\n",
    "                if self.add_to_vectorstore(text, metadata): vector_stored += 1\n",
    "\n",
    "            # Store in DB\n",
    "            risk = analysis['risk_score'] if analysis else 0.0\n",
    "            incrim = analysis['contains_incriminating'] if analysis else False\n",
    "            self.conn.execute('''INSERT OR REPLACE INTO forensic_images\n",
    "                (filename, full_path, extracted_text, ocr_confidence, local_analysis,\n",
    "                 risk_score, contains_incriminating, vector_stored) VALUES (?,?,?,?,?,?,?,?)''',\n",
    "                (filename, str(img_path), text, ocr_result['ocr_confidence'],\n",
    "                 json.dumps(analysis) if analysis else None, risk, incrim, vector_stored > 0))\n",
    "\n",
    "            if text.strip():\n",
    "                if incrim: incriminating += 1; print(f\" üö® INCRIMINATING ({risk:.2f})\")\n",
    "                else: print(\" ‚úÖ TEXT\")\n",
    "            else: print(\" ‚ö™ NO TEXT\")\n",
    "\n",
    "            processed += 1\n",
    "            if i % 10 == 0: self.conn.commit()\n",
    "\n",
    "        self.conn.commit()\n",
    "        print(f\"\\nüè† COMPLETE: {processed} processed, {vector_stored} vectorized, {incriminating} flagged, {time.time()-start_time:.1f}s\")\n",
    "\n",
    "    def investigate(self, query: str) -> Dict[str, Any]:\n",
    "        print(f\"üè† INVESTIGATING: '{query}'\")\n",
    "        try:\n",
    "            docs = self.vectorstore.similarity_search(query, k=5)\n",
    "            if not docs: return {'findings': [], 'summary': 'No evidence found', 'total_flagged': 0}\n",
    "\n",
    "            evidence, files = \"\", set()\n",
    "            for i, doc in enumerate(docs, 1):\n",
    "                filename = doc.metadata.get('filename', f'unknown_{i}')\n",
    "                files.add(filename)\n",
    "                evidence += f\"Evidence {i} - {filename}: {doc.page_content}\\n---\\n\"\n",
    "\n",
    "            prompt = f'''Forensic investigation: \"{query}\"\n",
    "Evidence: {evidence}\n",
    "Respond with JSON:\n",
    "{{\"findings\": [{{\"image_number\": 1, \"filename\": \"file.jpg\", \"matches_query\": true,\n",
    "\"risk_level\": \"high\", \"evidence_found\": \"desc\", \"relevant_text\": \"text\", \"confidence\": 0.8}}],\n",
    "\"summary\": \"summary\", \"total_flagged\": 2, \"highest_risk_image\": \"file.jpg\"}}'''\n",
    "\n",
    "            response = str(self.llm.invoke(prompt)).strip()\n",
    "            response = response.replace('```json', '').replace('```', '').strip()\n",
    "            start, end = response.find('{'), response.rfind('}') + 1\n",
    "\n",
    "            if start >= 0 and end > start:\n",
    "                results = json.loads(response[start:end])\n",
    "            else:\n",
    "                results = self._fallback_investigation(query, files)\n",
    "\n",
    "            # Store investigation\n",
    "            flagged = [f.get('filename', '') for f in results.get('findings', []) if f.get('matches_query')]\n",
    "            self.conn.execute('''INSERT INTO local_investigations\n",
    "                (query, results_json, flagged_images, model_used) VALUES (?,?,?,?)''',\n",
    "                (query, json.dumps(results), json.dumps(flagged), f\"{self.config['LLM_PROVIDER']}-{self.config['LLM_MODEL']}\"))\n",
    "            self.conn.commit()\n",
    "\n",
    "            print(f\"‚úÖ Found {results.get('total_flagged', 0)} matches\")\n",
    "            return results\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error: {e}\")\n",
    "            return {'findings': [], 'summary': f'Error: {e}', 'total_flagged': 0}\n",
    "\n",
    "    def _fallback_investigation(self, query: str, files: set) -> Dict[str, Any]:\n",
    "        findings = [{'image_number': i, 'filename': f, 'matches_query': True, 'risk_level': 'medium',\n",
    "                    'evidence_found': f'Related to: {query}', 'relevant_text': f'Matches: {query}', 'confidence': 0.7}\n",
    "                   for i, f in enumerate(list(files)[:5], 1)]\n",
    "        return {'findings': findings, 'summary': f'Fallback analysis for: {query}',\n",
    "               'total_flagged': len(findings), 'highest_risk_image': list(files)[0] if files else None}\n",
    "\n",
    "    def get_flagged(self, min_risk=0.3):\n",
    "        return self.conn.execute('''SELECT filename, full_path, extracted_text, risk_score,\n",
    "            local_analysis, ocr_confidence FROM forensic_images\n",
    "            WHERE contains_incriminating = 1 AND risk_score >= ? ORDER BY risk_score DESC''', (min_risk,)).fetchall()\n",
    "\n",
    "    def export_results(self, results: Dict[str, Any], query: str) -> str:\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        query_safe = query.replace(' ', '_')[:30]\n",
    "        output_path = Path(self.config['RESULTS_OUTPUT_PATH']) / f\"investigation_{query_safe}_{timestamp}\"\n",
    "        output_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        flagged = [f.get('filename', '') for f in results.get('findings', []) if f.get('matches_query')]\n",
    "        copied = []\n",
    "        for i, filename in enumerate(flagged, 1):\n",
    "            result = self.conn.execute(\"SELECT full_path FROM forensic_images WHERE filename = ?\", (filename,)).fetchone()\n",
    "            if result and Path(result[0]).exists():\n",
    "                dest = output_path / f\"{i:03d}_{filename}\"\n",
    "                shutil.copy2(result[0], dest); copied.append(str(dest))\n",
    "\n",
    "        # Save reports\n",
    "        report = {'query': query, 'timestamp': timestamp, 'model': f\"{self.config['LLM_PROVIDER']}-{self.config['LLM_MODEL']}\",\n",
    "                 'results': results, 'flagged_images': flagged, 'copied_files': copied}\n",
    "\n",
    "        with open(output_path / \"report.json\", 'w') as f: json.dump(report, f, indent=2)\n",
    "        with open(output_path / \"summary.txt\", 'w') as f:\n",
    "            f.write(f\"LOCAL FORENSIC REPORT\\nQuery: {query}\\nDate: {timestamp}\\n\")\n",
    "            f.write(f\"Model: {self.config['LLM_PROVIDER']}-{self.config['LLM_MODEL']}\\n\")\n",
    "            f.write(f\"Flagged: {len(flagged)}\\nSummary: {results.get('summary', 'N/A')}\\n\")\n",
    "\n",
    "        print(f\"üìã Exported to: {output_path}\")\n",
    "        return str(output_path)\n",
    "\n",
    "    def close(self):\n",
    "        if hasattr(self, 'conn') and self.conn: self.conn.close()\n",
    "\n",
    "# Compact GUI\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def create_compact_gui():\n",
    "    # OCR Configuration - ADD THIS TO EXISTING INTERFACE\n",
    "    ocr_selector = widgets.Dropdown(\n",
    "        options=[\n",
    "            ('PaddleOCR - Best overall, 80+ languages', 'paddleocr'),\n",
    "            ('EasyOCR - Good for European languages', 'easyocr'),\n",
    "            ('Tesseract - Classic OCR for printed text', 'tesseract'),\n",
    "            ('TrOCR - AI-based OCR for handwriting', 'trocr')\n",
    "        ],\n",
    "        value='paddleocr',\n",
    "        description='OCR Engine:',\n",
    "        style={'description_width': 'initial'},\n",
    "        layout=widgets.Layout(width='500px')\n",
    "    )\n",
    "\n",
    "    # Existing widgets from your current interface\n",
    "    llm_provider = widgets.Dropdown(\n",
    "        options=[('Ollama', 'ollama'), ('Transformers', 'transformers')],\n",
    "        value='ollama',\n",
    "        description='LLM Provider:',\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "\n",
    "    llm_model = widgets.Text(\n",
    "        value='llama3.2:latest',\n",
    "        description='LLM Model:',\n",
    "        style={'description_width': 'initial'},\n",
    "        layout=widgets.Layout(width='300px')\n",
    "    )\n",
    "\n",
    "    gallery_path = widgets.Text(\n",
    "        value='../../../datasets/images/text_ocr',\n",
    "        description='Gallery Path:',\n",
    "        style={'description_width': 'initial'},\n",
    "        layout=widgets.Layout(width='400px')\n",
    "    )\n",
    "\n",
    "    query_input = widgets.Textarea(\n",
    "        value='Find weapons or violence mentions',\n",
    "        description='Investigation Query:',\n",
    "        style={'description_width': 'initial'},\n",
    "        layout=widgets.Layout(width='500px', height='60px')\n",
    "    )\n",
    "\n",
    "    confidence_slider = widgets.FloatSlider(\n",
    "        value=0.60,\n",
    "        min=0.1, max=0.9, step=0.05,\n",
    "        description='OCR Confidence:',\n",
    "        style={'description_width': 'initial'},\n",
    "        readout_format='.2f'\n",
    "    )\n",
    "\n",
    "    risk_slider = widgets.FloatSlider(\n",
    "        value=0.3,\n",
    "        min=0.1, max=1.0, step=0.1,\n",
    "        description='Risk Threshold:',\n",
    "        style={'description_width': 'initial'},\n",
    "        readout_format='.1f'\n",
    "    )\n",
    "\n",
    "    # Quick queries (same as your existing interface)\n",
    "    quick_queries = [\"Find weapons\", \"Look for drugs\", \"Financial crimes\", \"Personal info theft\", \"Threats\", \"Illegal coordination\"]\n",
    "    quick_btns = [widgets.Button(description=q, tooltip=q, layout=widgets.Layout(width='180px', margin='2px')) for q in quick_queries]\n",
    "\n",
    "    # Action buttons (same as your existing interface)\n",
    "    test_btn = widgets.Button(description='üîç Test Setup', button_style='info', layout=widgets.Layout(width='120px'))\n",
    "    process_btn = widgets.Button(description='üìÅ Process', button_style='primary', layout=widgets.Layout(width='120px'))\n",
    "    investigate_btn = widgets.Button(description='ü§ñ Investigate', button_style='success', layout=widgets.Layout(width='120px'))\n",
    "    flagged_btn = widgets.Button(description='üö® Flagged', button_style='warning', layout=widgets.Layout(width='120px'))\n",
    "    export_btn = widgets.Button(description='üìã Export', button_style='success', layout=widgets.Layout(width='120px'), disabled=True)\n",
    "    clear_btn = widgets.Button(description='üóëÔ∏è Clear', layout=widgets.Layout(width='120px'))\n",
    "\n",
    "    status_label = widgets.HTML(value=\"<b>Status:</b> Ready\")\n",
    "    progress_bar = widgets.IntProgress(value=0, min=0, max=100, layout=widgets.Layout(width='400px'))\n",
    "    output_area = widgets.Output()\n",
    "\n",
    "    # State\n",
    "    current_system = None\n",
    "    current_results = None\n",
    "\n",
    "    def update_status(msg, progress=None):\n",
    "        status_label.value = f\"<b>Status:</b> {msg}\"\n",
    "        if progress is not None: progress_bar.value = progress\n",
    "\n",
    "    def init_system():\n",
    "        nonlocal current_system\n",
    "        try:\n",
    "            config = CONFIG.copy()\n",
    "            config.update({\n",
    "                'OCR_MODEL': ocr_selector.value,  # NOW USES SELECTED OCR\n",
    "                'LLM_PROVIDER': llm_provider.value,\n",
    "                'LLM_MODEL': llm_model.value,\n",
    "                'SUSPECTS_GALLERY_PATH': gallery_path.value,\n",
    "                'OCR_CONFIDENCE_THRESHOLD': confidence_slider.value\n",
    "            })\n",
    "            current_system = CompactForensicSystem(config)\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Init error: {e}\")\n",
    "            return False\n",
    "\n",
    "    # Button handlers (same functionality, now with OCR support)\n",
    "    def on_quick_query(query):\n",
    "        def handler(b): query_input.value = query\n",
    "        return handler\n",
    "\n",
    "    for i, btn in enumerate(quick_btns):\n",
    "        btn.on_click(on_quick_query(quick_queries[i]))\n",
    "\n",
    "    def on_test(b):\n",
    "        with output_area:\n",
    "            clear_output(wait=True)\n",
    "            update_status(\"Testing setup...\", 20)\n",
    "            print(\"üîç TESTING LOCAL SETUP\")\n",
    "            print(\"=\"*40)\n",
    "\n",
    "            # Test OCR first\n",
    "            print(f\"üîç Selected OCR: {ocr_selector.value}\")\n",
    "            ocr_info = {\n",
    "                'paddleocr': 'Best overall, 80+ languages, handwriting',\n",
    "                'easyocr': 'Good for European languages, clean text',\n",
    "                'tesseract': 'Excellent for printed documents, stable',\n",
    "                'trocr': 'Perfect for handwritten notes, degraded images'\n",
    "            }\n",
    "            if ocr_selector.value in ocr_info:\n",
    "                print(f\"   Purpose: {ocr_info[ocr_selector.value]}\")\n",
    "\n",
    "            # Test OCR availability\n",
    "            try:\n",
    "                if ocr_selector.value == 'paddleocr':\n",
    "                    import paddleocr; print(\"‚úÖ PaddleOCR available\")\n",
    "                elif ocr_selector.value == 'easyocr':\n",
    "                    import easyocr; print(\"‚úÖ EasyOCR available\")\n",
    "                elif ocr_selector.value == 'tesseract':\n",
    "                    import pytesseract; print(\"‚úÖ Tesseract available\")\n",
    "                elif ocr_selector.value == 'trocr':\n",
    "                    import transformers; print(\"‚úÖ TrOCR available\")\n",
    "            except ImportError:\n",
    "                print(f\"‚ùå {ocr_selector.value} not installed\")\n",
    "\n",
    "            # Test other dependencies\n",
    "            deps = [('langchain', 'LangChain'), ('chromadb', 'ChromaDB'), ('sentence_transformers', 'Transformers')]\n",
    "            for dep, name in deps:\n",
    "                try: __import__(dep.replace('-', '_')); print(f\"‚úÖ {name}\")\n",
    "                except ImportError: print(f\"‚ùå {name} not found\")\n",
    "\n",
    "            # Test Ollama\n",
    "            if llm_provider.value == 'ollama':\n",
    "                update_status(\"Testing Ollama...\", 60)\n",
    "                try:\n",
    "                    import requests\n",
    "                    r = requests.get(\"http://localhost:11434/api/tags\", timeout=5)\n",
    "                    if r.status_code == 200:\n",
    "                        models = [m['name'] for m in r.json().get('models', [])]\n",
    "                        print(f\"‚úÖ Ollama: {models}\")\n",
    "                        if llm_model.value in models:\n",
    "                            print(f\"‚úÖ Model '{llm_model.value}' ready\")\n",
    "                        else:\n",
    "                            print(f\"‚ö†Ô∏è Model '{llm_model.value}' not found. Install: ollama pull {llm_model.value}\")\n",
    "                    else: print(\"‚ùå Ollama not responding\")\n",
    "                except: print(\"‚ùå Ollama connection failed. Start: ollama serve\")\n",
    "\n",
    "            update_status(\"Testing system init...\", 80)\n",
    "            if init_system():\n",
    "                print(\"‚úÖ System ready with selected OCR\");\n",
    "                update_status(\"Setup complete!\", 100)\n",
    "            else:\n",
    "                print(\"‚ùå System init failed\");\n",
    "                update_status(\"Setup failed\", 0)\n",
    "\n",
    "    def on_process(b):\n",
    "        with output_area:\n",
    "            clear_output(wait=True)\n",
    "            update_status(\"Processing gallery...\", 20)\n",
    "            if not init_system():\n",
    "                update_status(\"Init failed\", 0); return\n",
    "\n",
    "            print(f\"üè† PROCESSING | OCR: {ocr_selector.value} | LLM: {llm_provider.value}-{llm_model.value}\")\n",
    "            try:\n",
    "                current_system.process_gallery()\n",
    "                update_status(\"Processing complete!\", 100)\n",
    "                flagged = current_system.get_flagged(risk_slider.value)\n",
    "                if flagged: print(f\"\\nüö® FLAGGED: {len(flagged)} images above risk {risk_slider.value}\")\n",
    "                else: print(\"\\n‚úÖ No high-risk content detected\")\n",
    "            except Exception as e: update_status(\"Processing error\", 0); print(f\"‚ùå Error: {e}\")\n",
    "\n",
    "    def on_investigate(b):\n",
    "        nonlocal current_results\n",
    "        with output_area:\n",
    "            clear_output(wait=True)\n",
    "            if not current_system and not init_system(): print(\"‚ùå System not ready\"); return\n",
    "\n",
    "            query = query_input.value.strip()\n",
    "            if not query: print(\"‚ö†Ô∏è Enter investigation query\"); return\n",
    "\n",
    "            update_status(\"Investigating...\", 50)\n",
    "            print(f\"üè† INVESTIGATING: '{query}' | OCR: {ocr_selector.value} | LLM: {llm_model.value}\")\n",
    "            try:\n",
    "                current_results = current_system.investigate(query)\n",
    "                if current_results.get('total_flagged', 0) > 0:\n",
    "                    update_status(f\"Found {current_results['total_flagged']} matches\", 100)\n",
    "                    export_btn.disabled = False\n",
    "                    print(f\"üìä Summary: {current_results.get('summary', 'N/A')}\")\n",
    "                    print(\"üö® FLAGGED:\")\n",
    "                    for f in current_results.get('findings', []):\n",
    "                        if f.get('matches_query'):\n",
    "                            print(f\"  {f['risk_level'].upper()}: {f['filename']} - {f['evidence_found']}\")\n",
    "\n",
    "                    # Display images\n",
    "                    flagged_files = [f['filename'] for f in current_results.get('findings', []) if f.get('matches_query')]\n",
    "                    if flagged_files:\n",
    "                        print(f\"üñºÔ∏è Displaying {len(flagged_files)} flagged images...\")\n",
    "                        display_flagged_images(flagged_files[:6], current_system)\n",
    "                else:\n",
    "                    update_status(\"No matches\", 100); export_btn.disabled = True\n",
    "                    print(\"‚ùå No matches. Try different terms or lower risk threshold.\")\n",
    "            except Exception as e: update_status(\"Investigation error\", 0); print(f\"‚ùå Error: {e}\")\n",
    "\n",
    "    def on_flagged(b):\n",
    "        with output_area:\n",
    "            clear_output(wait=True)\n",
    "            if not current_system and not init_system(): print(\"‚ùå System not ready\"); return\n",
    "\n",
    "            update_status(\"Loading flagged images...\", 50)\n",
    "            try:\n",
    "                flagged = current_system.get_flagged(risk_slider.value)\n",
    "                if flagged:\n",
    "                    print(f\"üö® FLAGGED IMAGES (Risk ‚â• {risk_slider.value})\")\n",
    "                    for i, (filename, _, text, risk, analysis, conf) in enumerate(flagged, 1):\n",
    "                        level = \"CRITICAL\" if risk > 0.8 else \"HIGH\" if risk > 0.6 else \"MEDIUM\" if risk > 0.3 else \"LOW\"\n",
    "                        print(f\"{i}. {filename} | {level} ({risk:.3f}) | OCR: {conf:.3f}\")\n",
    "                        print(f\"   Text: {text[:100]}...\")\n",
    "                        if analysis:\n",
    "                            try:\n",
    "                                data = json.loads(analysis)\n",
    "                                cats = data.get('categories', [])\n",
    "                                if cats: print(f\"   Categories: {', '.join(cats)}\")\n",
    "                            except: pass\n",
    "                        print()\n",
    "\n",
    "                    files = [r[0] for r in flagged[:6]]\n",
    "                    print(f\"üñºÔ∏è Displaying {len(files)} flagged images...\")\n",
    "                    display_flagged_images(files, current_system)\n",
    "                    update_status(f\"Showing {len(flagged)} flagged images\", 100)\n",
    "                else:\n",
    "                    print(f\"‚úÖ No images flagged above risk {risk_slider.value}\")\n",
    "                    update_status(\"No flagged images\", 100)\n",
    "            except Exception as e: update_status(\"Error loading flagged\", 0); print(f\"‚ùå Error: {e}\")\n",
    "\n",
    "    def on_export(b):\n",
    "        with output_area:\n",
    "            if not current_results: print(\"‚ö†Ô∏è No results to export\"); return\n",
    "            try:\n",
    "                update_status(\"Exporting...\", 50)\n",
    "                path = current_system.export_results(current_results, query_input.value or \"investigation\")\n",
    "                update_status(\"Export complete!\", 100)\n",
    "                print(f\"‚úÖ Results exported to: {path}\")\n",
    "            except Exception as e: update_status(\"Export error\", 0); print(f\"‚ùå Error: {e}\")\n",
    "\n",
    "    def on_clear(b):\n",
    "        nonlocal current_results\n",
    "        current_results = None; export_btn.disabled = True\n",
    "        with output_area: clear_output(); update_status(\"Cleared\", 0); print(\"üóëÔ∏è Cleared\")\n",
    "\n",
    "    # Connect events\n",
    "    test_btn.on_click(on_test); process_btn.on_click(on_process); investigate_btn.on_click(on_investigate)\n",
    "    flagged_btn.on_click(on_flagged); export_btn.on_click(on_export); clear_btn.on_click(on_clear)\n",
    "\n",
    "    # Quick query grid\n",
    "    quick_grid = widgets.GridBox(quick_btns, layout=widgets.Layout(grid_template_columns='repeat(3, 1fr)', grid_gap='5px'))\n",
    "\n",
    "    # UPDATED LAYOUT: Add OCR selector at the top\n",
    "    controls = widgets.VBox([\n",
    "        widgets.HTML(\"<h3>üè† Compact Local Forensic System</h3>\"),\n",
    "\n",
    "        # ADD OCR SELECTOR AT THE TOP\n",
    "        widgets.HTML(\"<b>üîç OCR Engine Selection:</b>\"),\n",
    "        ocr_selector,\n",
    "        widgets.HTML(\"<br>\"),\n",
    "\n",
    "        # Existing LLM configuration\n",
    "        widgets.HBox([llm_provider, llm_model]),\n",
    "        gallery_path,\n",
    "        query_input,\n",
    "        widgets.HTML(\"<b>Quick Queries:</b>\"),\n",
    "        quick_grid,\n",
    "        widgets.HBox([confidence_slider, risk_slider]),\n",
    "        widgets.HBox([test_btn, process_btn, investigate_btn, flagged_btn, export_btn, clear_btn]),\n",
    "        status_label,\n",
    "        progress_bar,\n",
    "        widgets.HTML(\"<hr>\")\n",
    "    ])\n",
    "\n",
    "    return widgets.VBox([controls, output_area])\n",
    "\n",
    "    confidence_slider = widgets.FloatSlider(\n",
    "        value=CONFIG['OCR_CONFIDENCE_THRESHOLD'],\n",
    "        min=0.1, max=0.9, step=0.05,\n",
    "        description='OCR Confidence:',\n",
    "        style={'description_width': 'initial'},\n",
    "        readout_format='.2f'\n",
    "    )\n",
    "\n",
    "    risk_slider = widgets.FloatSlider(\n",
    "        value=0.3,\n",
    "        min=0.1, max=1.0, step=0.1,\n",
    "        description='Risk Threshold:',\n",
    "        style={'description_width': 'initial'},\n",
    "        readout_format='.1f'\n",
    "    )\n",
    "\n",
    "    # Quick queries\n",
    "    quick_queries = [\"Find weapons\", \"Look for drugs\", \"Financial crimes\", \"Personal info theft\", \"Threats\", \"Illegal coordination\"]\n",
    "    quick_btns = [widgets.Button(description=q[:20], tooltip=q, layout=widgets.Layout(width='180px', margin='2px')) for q in quick_queries]\n",
    "\n",
    "    # Action buttons\n",
    "    test_btn = widgets.Button(description='üîç Test Setup', button_style='info', layout=widgets.Layout(width='120px'))\n",
    "    process_btn = widgets.Button(description='üìÅ Process', button_style='primary', layout=widgets.Layout(width='120px'))\n",
    "    investigate_btn = widgets.Button(description='ü§ñ Investigate', button_style='success', layout=widgets.Layout(width='120px'))\n",
    "    flagged_btn = widgets.Button(description='üö® Flagged', button_style='warning', layout=widgets.Layout(width='120px'))\n",
    "    export_btn = widgets.Button(description='üìã Export', button_style='success', layout=widgets.Layout(width='120px'), disabled=True)\n",
    "    clear_btn = widgets.Button(description='üóëÔ∏è Clear', layout=widgets.Layout(width='120px'))\n",
    "\n",
    "    status_label = widgets.HTML(value=\"<b>Status:</b> Ready\")\n",
    "    progress_bar = widgets.IntProgress(value=0, min=0, max=100, layout=widgets.Layout(width='400px'))\n",
    "    output_area = widgets.Output()\n",
    "\n",
    "    # State\n",
    "    current_system = None\n",
    "    current_results = None\n",
    "\n",
    "    def update_status(msg, progress=None):\n",
    "        status_label.value = f\"<b>Status:</b> {msg}\"\n",
    "        if progress is not None: progress_bar.value = progress\n",
    "\n",
    "    def init_system():\n",
    "        nonlocal current_system\n",
    "        try:\n",
    "            config = CONFIG.copy()\n",
    "            config.update({\n",
    "                'OCR_MODEL': ocr_selector.value,\n",
    "                'LLM_PROVIDER': llm_provider.value,\n",
    "                'LLM_MODEL': llm_model.value,\n",
    "                'SUSPECTS_GALLERY_PATH': gallery_path.value,\n",
    "                'OCR_CONFIDENCE_THRESHOLD': confidence_slider.value\n",
    "            })\n",
    "            current_system = CompactForensicSystem(config)\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Init error: {e}\")\n",
    "            return False\n",
    "\n",
    "    # Button handlers\n",
    "    def on_quick_query(query):\n",
    "        def handler(b): query_input.value = query\n",
    "        return handler\n",
    "\n",
    "    for i, btn in enumerate(quick_btns): btn.on_click(on_quick_query(quick_queries[i]))\n",
    "\n",
    "    def on_test(b):\n",
    "        with output_area:\n",
    "            clear_output(wait=True)\n",
    "            update_status(\"Testing setup...\", 20)\n",
    "            print(\"üîç TESTING LOCAL SETUP\")\n",
    "            print(\"=\"*40)\n",
    "\n",
    "            # Test OCR first\n",
    "            print(f\"Testing OCR: {ocr_selector.value}\")\n",
    "            ocr_info = OCR_MODELS.get(ocr_selector.value, {})\n",
    "            print(f\"Purpose: {ocr_info.get('strengths', 'General OCR')}\")\n",
    "\n",
    "            try:\n",
    "                if ocr_selector.value == 'paddleocr':\n",
    "                    import paddleocr; print(\"‚úÖ PaddleOCR available\")\n",
    "                elif ocr_selector.value == 'easyocr':\n",
    "                    import easyocr; print(\"‚úÖ EasyOCR available\")\n",
    "                elif ocr_selector.value == 'tesseract':\n",
    "                    import pytesseract; print(\"‚úÖ Tesseract available\")\n",
    "                elif ocr_selector.value == 'trocr':\n",
    "                    import transformers; print(\"‚úÖ TrOCR (Transformers) available\")\n",
    "            except ImportError as e: print(f\"‚ùå {ocr_selector.value} not found: {e}\")\n",
    "\n",
    "            # Test other dependencies\n",
    "            deps = [('paddleocr', 'PaddleOCR'), ('langchain', 'LangChain'), ('chromadb', 'ChromaDB'), ('sentence_transformers', 'Transformers')]\n",
    "            for dep, name in deps:\n",
    "                try: __import__(dep.replace('-', '_')); print(f\"‚úÖ {name}\")\n",
    "                except ImportError: print(f\"‚ùå {name} not found\")\n",
    "\n",
    "            # Test Ollama\n",
    "            if llm_provider.value == 'ollama':\n",
    "                update_status(\"Testing Ollama...\", 60)\n",
    "                try:\n",
    "                    import requests\n",
    "                    r = requests.get(\"http://localhost:11434/api/tags\", timeout=5)\n",
    "                    if r.status_code == 200:\n",
    "                        models = [m['name'] for m in r.json().get('models', [])]\n",
    "                        print(f\"‚úÖ Ollama: {models}\")\n",
    "                        if llm_model.value in models: print(f\"‚úÖ Model '{llm_model.value}' ready\")\n",
    "                        else: print(f\"‚ö†Ô∏è Model '{llm_model.value}' not found. Install: ollama pull {llm_model.value}\")\n",
    "                    else: print(\"‚ùå Ollama not responding\")\n",
    "                except: print(\"‚ùå Ollama connection failed. Start: ollama serve\")\n",
    "\n",
    "            update_status(\"Testing system init...\", 80)\n",
    "            if init_system(): print(\"‚úÖ System ready\"); update_status(\"Setup complete!\", 100)\n",
    "            else: print(\"‚ùå System init failed\"); update_status(\"Setup failed\", 0)\n",
    "\n",
    "    def on_process(b):\n",
    "        with output_area:\n",
    "            clear_output(wait=True)\n",
    "            update_status(\"Processing gallery...\", 20)\n",
    "            if not init_system(): update_status(\"Init failed\", 0); return\n",
    "\n",
    "            print(f\"üè† PROCESSING | OCR: {ocr_selector.value} | LLM: {llm_provider.value}-{llm_model.value}\")\n",
    "            try:\n",
    "                current_system.process_gallery()\n",
    "                update_status(\"Processing complete!\", 100)\n",
    "                flagged = current_system.get_flagged(risk_slider.value)\n",
    "                if flagged: print(f\"\\nüö® FLAGGED: {len(flagged)} images above risk {risk_slider.value}\")\n",
    "                else: print(\"\\n‚úÖ No high-risk content detected\")\n",
    "            except Exception as e: update_status(\"Processing error\", 0); print(f\"‚ùå Error: {e}\")\n",
    "\n",
    "    def on_investigate(b):\n",
    "        nonlocal current_results\n",
    "        with output_area:\n",
    "            clear_output(wait=True)\n",
    "            if not current_system and not init_system(): print(\"‚ùå System not ready\"); return\n",
    "\n",
    "            query = query_input.value.strip()\n",
    "            if not query: print(\"‚ö†Ô∏è Enter investigation query\"); return\n",
    "\n",
    "            update_status(\"Investigating...\", 50)\n",
    "            print(f\"üè† INVESTIGATING: '{query}' | Model: {llm_model.value}\")\n",
    "            try:\n",
    "                current_results = current_system.investigate(query)\n",
    "                if current_results.get('total_flagged', 0) > 0:\n",
    "                    update_status(f\"Found {current_results['total_flagged']} matches\", 100)\n",
    "                    export_btn.disabled = False\n",
    "                    print(f\"üìä Summary: {current_results.get('summary', 'N/A')}\")\n",
    "                    print(\"üö® FLAGGED:\")\n",
    "                    for f in current_results.get('findings', []):\n",
    "                        if f.get('matches_query'):\n",
    "                            print(f\"  {f['risk_level'].upper()}: {f['filename']} - {f['evidence_found']}\")\n",
    "\n",
    "                    # Display images\n",
    "                    flagged_files = [f['filename'] for f in current_results.get('findings', []) if f.get('matches_query')]\n",
    "                    if flagged_files:\n",
    "                        print(f\"üñºÔ∏è Displaying {len(flagged_files)} flagged images...\")\n",
    "                        display_flagged_images(flagged_files[:6], current_system)\n",
    "                else:\n",
    "                    update_status(\"No matches\", 100); export_btn.disabled = True\n",
    "                    print(\"‚ùå No matches. Try different terms or lower risk threshold.\")\n",
    "            except Exception as e: update_status(\"Investigation error\", 0); print(f\"‚ùå Error: {e}\")\n",
    "\n",
    "    def on_flagged(b):\n",
    "        with output_area:\n",
    "            clear_output(wait=True)\n",
    "            if not current_system and not init_system(): print(\"‚ùå System not ready\"); return\n",
    "\n",
    "            update_status(\"Loading flagged images...\", 50)\n",
    "            try:\n",
    "                flagged = current_system.get_flagged(risk_slider.value)\n",
    "                if flagged:\n",
    "                    print(f\"üö® FLAGGED IMAGES (Risk ‚â• {risk_slider.value})\")\n",
    "                    for i, (filename, _, text, risk, analysis, conf) in enumerate(flagged, 1):\n",
    "                        level = \"CRITICAL\" if risk > 0.8 else \"HIGH\" if risk > 0.6 else \"MEDIUM\" if risk > 0.3 else \"LOW\"\n",
    "                        print(f\"{i}. {filename} | {level} ({risk:.3f}) | OCR: {conf:.3f}\")\n",
    "                        print(f\"   Text: {text[:100]}...\")\n",
    "                        if analysis:\n",
    "                            try:\n",
    "                                data = json.loads(analysis)\n",
    "                                cats = data.get('categories', [])\n",
    "                                if cats: print(f\"   Categories: {', '.join(cats)}\")\n",
    "                            except: pass\n",
    "                        print()\n",
    "\n",
    "                    files = [r[0] for r in flagged[:6]]\n",
    "                    display_flagged_images(files, current_system)\n",
    "                    update_status(f\"Showing {len(flagged)} flagged images\", 100)\n",
    "                else:\n",
    "                    print(f\"‚úÖ No images flagged above risk {risk_slider.value}\")\n",
    "                    update_status(\"No flagged images\", 100)\n",
    "            except Exception as e: update_status(\"Error loading flagged\", 0); print(f\"‚ùå Error: {e}\")\n",
    "\n",
    "    def on_export(b):\n",
    "        with output_area:\n",
    "            if not current_results: print(\"‚ö†Ô∏è No results to export\"); return\n",
    "            try:\n",
    "                update_status(\"Exporting...\", 50)\n",
    "                path = current_system.export_results(current_results, query_input.value or \"investigation\")\n",
    "                update_status(\"Export complete!\", 100)\n",
    "                print(f\"‚úÖ Results exported to: {path}\")\n",
    "            except Exception as e: update_status(\"Export error\", 0); print(f\"‚ùå Error: {e}\")\n",
    "\n",
    "    def on_clear(b):\n",
    "        nonlocal current_results\n",
    "        current_results = None; export_btn.disabled = True\n",
    "        with output_area: clear_output(); update_status(\"Cleared\", 0); print(\"üóëÔ∏è Cleared\")\n",
    "\n",
    "    # Connect events\n",
    "    test_btn.on_click(on_test); process_btn.on_click(on_process); investigate_btn.on_click(on_investigate)\n",
    "    flagged_btn.on_click(on_flagged); export_btn.on_click(on_export); clear_btn.on_click(on_clear)\n",
    "\n",
    "    # Layout\n",
    "    quick_grid = widgets.GridBox(quick_btns, layout=widgets.Layout(grid_template_columns='repeat(3, 1fr)', grid_gap='5px'))\n",
    "    controls = widgets.VBox([\n",
    "        widgets.HTML(\"<h3>üè† Compact Local Forensic System</h3>\"),\n",
    "        widgets.HBox([llm_provider, llm_model]), gallery_path, query_input,\n",
    "        widgets.HTML(\"<b>Quick Queries:</b>\"), quick_grid,\n",
    "        widgets.HBox([confidence_slider, risk_slider]),\n",
    "        widgets.HBox([test_btn, process_btn, investigate_btn, flagged_btn, export_btn, clear_btn]),\n",
    "        status_label, progress_bar, widgets.HTML(\"<hr>\")\n",
    "    ])\n",
    "\n",
    "    return widgets.VBox([controls, output_area])\n",
    "\n",
    "    for i, filename in enumerate(filenames[:num]):\n",
    "        ax = axes[i] if num > 1 else axes\n",
    "        try:\n",
    "            result = system.conn.execute('''SELECT full_path, extracted_text, risk_score, local_analysis\n",
    "                FROM forensic_images WHERE filename = ?''', (filename,)).fetchone()\n",
    "            if not result: ax.text(0.5, 0.5, f\"Not found\\n{filename}\", ha='center', va='center', transform=ax.transAxes); ax.axis('off'); continue\n",
    "\n",
    "            full_path, text, risk, analysis = result\n",
    "            try: img = plt.imread(full_path); ax.imshow(img)\n",
    "            except: ax.text(0.5, 0.5, f\"Load error\\n{filename}\", ha='center', va='center', transform=ax.transAxes); ax.axis('off'); continue\n",
    "\n",
    "            # Risk level and color\n",
    "            level, color = (\"CRITICAL\", \"red\") if risk > 0.8 else (\"HIGH\", \"orange\") if risk > 0.6 else (\"MEDIUM\", \"yellow\") if risk > 0.3 else (\"LOW\", \"green\")\n",
    "            ax.set_title(f\"{filename}\\n{level}: {risk:.2f}\", fontsize=10, color=color, fontweight='bold')\n",
    "\n",
    "            # Text overlay\n",
    "            text_preview = text[:80] if text else \"No text\"\n",
    "            ax.text(0.02, 0.98, f\"Text: {text_preview}...\", transform=ax.transAxes, fontsize=8,\n",
    "                   verticalalignment='top', bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=color, alpha=0.7))\n",
    "\n",
    "            # Categories\n",
    "            if analysis:\n",
    "                try:\n",
    "                    data = json.loads(analysis)\n",
    "                    cats = data.get('categories', [])\n",
    "                    if cats: ax.text(0.02, 0.02, f\"Cat: {', '.join(cats[:2])}\", transform=ax.transAxes, fontsize=7,\n",
    "                                   verticalalignment='bottom', bbox=dict(boxstyle=\"round,pad=0.2\", facecolor=\"lightblue\", alpha=0.8))\n",
    "                except: pass\n",
    "            ax.axis('off')\n",
    "        except Exception as e: ax.text(0.5, 0.5, f\"Error\\n{filename}\\n{str(e)[:30]}\", ha='center', va='center', transform=ax.transAxes); ax.axis('off')\n",
    "\n",
    "    for j in range(num, len(axes)): axes[j].axis('off')\n",
    "    plt.tight_layout(); plt.suptitle('üè† Local Forensic Results', fontsize=14, y=1.02); plt.show()\n",
    "\n",
    "# Quick functions\n",
    "def quick_setup():\n",
    "    print(\"üè† QUICK SETUP CHECK\")\n",
    "    deps = ['paddleocr', 'langchain', 'chromadb', 'sentence_transformers']\n",
    "    for dep in deps:\n",
    "        try: __import__(dep.replace('-', '_')); print(f\"‚úÖ {dep}\")\n",
    "        except ImportError: print(f\"‚ùå {dep} - pip install {dep}\")\n",
    "\n",
    "    try:\n",
    "        import requests\n",
    "        r = requests.get(\"http://localhost:11434/api/tags\", timeout=5)\n",
    "        if r.status_code == 200:\n",
    "            models = [m['name'] for m in r.json().get('models', [])]\n",
    "            print(f\"‚úÖ Ollama: {models}\")\n",
    "            if 'llama3.2:latest' in models: print(\"‚úÖ Recommended model ready\")\n",
    "            else: print(\"‚ö†Ô∏è Install: ollama pull llama3.2:latest\")\n",
    "        else: print(\"‚ùå Ollama not responding\")\n",
    "    except: print(\"‚ùå Ollama not available - Start: ollama serve\")\n",
    "\n",
    "def quick_investigate(query: str, gallery_path: str = '../../../datasets/images/text_ocr'):\n",
    "    print(f\"üè† Quick Investigation: '{query}' | üîí 100% Local\")\n",
    "    try:\n",
    "        config = CONFIG.copy(); config['SUSPECTS_GALLERY_PATH'] = gallery_path\n",
    "        system = CompactForensicSystem(config)\n",
    "\n",
    "        # Check if processed\n",
    "        count = system.conn.execute(\"SELECT COUNT(*) FROM forensic_images WHERE vector_stored = 1\").fetchone()[0]\n",
    "        if count == 0: print(\"üìÅ Processing gallery first...\"); system.process_gallery()\n",
    "\n",
    "        results = system.investigate(query)\n",
    "        if results.get('total_flagged', 0) > 0:\n",
    "            path = system.export_results(results, query)\n",
    "            print(f\"üìã Exported to: {path}\")\n",
    "        system.close(); return results\n",
    "    except Exception as e: print(f\"‚ùå Error: {e}\"); return None\n",
    "\n",
    "# Display interface with debugging\n",
    "print(\"üè† Creating Compact Local Forensic Interface...\")\n",
    "print(\"üîß Debug: OCR models available:\", list(OCR_MODELS.keys()))\n",
    "\n",
    "compact_interface = create_compact_gui()\n",
    "\n",
    "# Verify the interface was created properly\n",
    "print(\"‚úÖ GUI created successfully\")\n",
    "print(\"üîç OCR selector should be visible at the top\")\n",
    "\n",
    "display(compact_interface)\n",
    "\n",
    "print(f\"\\nüè† COMPACT LOCAL FORENSIC SYSTEM READY!\")\n",
    "print(\"=\"*50)\n",
    "print(\"üîí PRIVACY: 100% local, no API calls, offline capable\")\n",
    "print(\"ü§ñ COMPONENTS: Multi-OCR + Ollama/Transformers + ChromaDB + SQLite\")\n",
    "print(\"üìù OCR OPTIONS: PaddleOCR, EasyOCR, Tesseract, TrOCR\")\n",
    "print(\"üöÄ SETUP: ollama serve ‚Üí ollama pull llama3.2:latest\")\n",
    "print(\"üí° QUICK: quick_setup() | quick_investigate('find weapons')\")\n",
    "print(\"=\"*50)\n",
    "print(\"\\nüîç OCR SELECTION GUIDE:\")\n",
    "print(\"‚Ä¢ PaddleOCR: Best overall, Asian languages, handwriting\")\n",
    "print(\"‚Ä¢ EasyOCR: European languages, clean text\")\n",
    "print(\"‚Ä¢ Tesseract: Printed documents, very stable\")\n",
    "print(\"‚Ä¢ TrOCR: Handwritten notes, degraded images\")\n",
    "print(\"=\"*50)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üè† LOCAL FORENSIC SYSTEM | LLM: ollama-llama3.2:latest | üîí 100% Private\n",
      "‚úÖ paddleocr\n",
      "‚úÖ langchain\n",
      "‚úÖ chromadb\n",
      "‚úÖ sentence_transformers\n",
      "‚úÖ Ollama: ['deepseek-r1:1.5b', 'llama3.2:latest']\n",
      "üè† Creating Compact Local Forensic Interface...\n",
      "üîß Debug: OCR models available: ['paddleocr', 'easyocr', 'tesseract', 'trocr']\n",
      "‚úÖ GUI created successfully\n",
      "üîç OCR selector should be visible at the top\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VBox(children=(VBox(children=(HTML(value='<h3>üè† Compact Local Forensic System</h3>'), HTML(value='<b>üîç OCR Eng‚Ä¶"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e6dd0e06d0274a6697e2b6ef7f512798"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üè† COMPACT LOCAL FORENSIC SYSTEM READY!\n",
      "==================================================\n",
      "üîí PRIVACY: 100% local, no API calls, offline capable\n",
      "ü§ñ COMPONENTS: Multi-OCR + Ollama/Transformers + ChromaDB + SQLite\n",
      "üìù OCR OPTIONS: PaddleOCR, EasyOCR, Tesseract, TrOCR\n",
      "üöÄ SETUP: ollama serve ‚Üí ollama pull llama3.2:latest\n",
      "üí° QUICK: quick_setup() | quick_investigate('find weapons')\n",
      "==================================================\n",
      "\n",
      "üîç OCR SELECTION GUIDE:\n",
      "‚Ä¢ PaddleOCR: Best overall, Asian languages, handwriting\n",
      "‚Ä¢ EasyOCR: European languages, clean text\n",
      "‚Ä¢ Tesseract: Printed documents, very stable\n",
      "‚Ä¢ TrOCR: Handwritten notes, degraded images\n",
      "==================================================\n"
     ]
    }
   ],
   "execution_count": 4
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
