{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import os\n",
    "os.listdir('../../../datasets/images/text_ocr')"
   ],
   "id": "54cdfde4d1de3335"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Generic OCR Image Text Search System with GUI\n",
    "import os, json, sqlite3, shutil, warnings, time\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from typing import List, Dict, Any, Optional\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Disable analytics to prevent connection errors\n",
    "os.environ['DISABLE_TELEMETRY'] = '1'\n",
    "os.environ['PADDLEOCR_DISABLE_TELEMETRY'] = '1'\n",
    "os.environ['HUB_ANALYTICS'] = 'False'\n",
    "\n",
    "# Configuration with OCR options\n",
    "CONFIG = {\n",
    "    'OCR_MODEL': 'paddleocr',\n",
    "    'OCR_CONFIDENCE_THRESHOLD': 0.6,\n",
    "    'LLM_PROVIDER': 'ollama',\n",
    "    'LLM_MODEL': 'llama3.2:latest',\n",
    "    'LLM_BASE_URL': 'http://localhost:11434',\n",
    "    'LLM_TEMPERATURE': 0.1,\n",
    "    'LLM_MAX_TOKENS': 1000,\n",
    "    'EMBEDDING_PROVIDER': 'huggingface',\n",
    "    'EMBEDDING_MODEL': 'sentence-transformers/all-MiniLM-L6-v2',\n",
    "    'VECTOR_STORE_PATH': './image_vectorstore',\n",
    "    'CHUNK_SIZE': 500,\n",
    "    'CHUNK_OVERLAP': 50,\n",
    "    'IMAGE_GALLERY_PATH': '../../../datasets/images/text_ocr',\n",
    "    'DATABASE_PATH': './image_analysis_db',\n",
    "    'RESULTS_OUTPUT_PATH': '../../../datasets/images/forensic_results',\n",
    "    'BATCH_SIZE': 4,\n",
    "    'MAX_RESULTS_DISPLAY': 10,\n",
    "}\n",
    "\n",
    "# OCR model options for different text types\n",
    "OCR_MODELS = {\n",
    "    'paddleocr': {'name': 'PaddleOCR', 'desc': 'Best overall, 80+ languages, handwriting capable', 'strengths': 'Asian text, complex layouts'},\n",
    "    'easyocr': {'name': 'EasyOCR', 'desc': 'Good for European languages, simple setup', 'strengths': 'European text, clean images'},\n",
    "    'tesseract': {'name': 'Tesseract', 'desc': 'Classic OCR, best for clean printed text', 'strengths': 'Printed documents, stable'},\n",
    "    'trocr': {'name': 'TrOCR (Transformers)', 'desc': 'AI-based, excellent for handwriting', 'strengths': 'Handwritten notes, degraded images'}\n",
    "}\n",
    "\n",
    "print(f\"🔍 GENERIC OCR TEXT SEARCH | LLM: {CONFIG['LLM_PROVIDER']}-{CONFIG['LLM_MODEL']} | 🔒 100% Private\")\n",
    "\n",
    "# Quick dependency check\n",
    "def check_deps():\n",
    "    deps = ['paddleocr', 'langchain', 'chromadb', 'sentence_transformers']\n",
    "    for dep in deps:\n",
    "        try: __import__(dep.replace('-', '_')); print(f\"✅ {dep}\")\n",
    "        except ImportError: print(f\"❌ {dep} - Install: pip install {dep}\")\n",
    "\n",
    "def check_ollama():\n",
    "    try:\n",
    "        import requests\n",
    "        r = requests.get(f\"{CONFIG['LLM_BASE_URL']}/api/tags\", timeout=5)\n",
    "        if r.status_code == 200:\n",
    "            models = [m['name'] for m in r.json().get('models', [])]\n",
    "            print(f\"✅ Ollama: {models}\")\n",
    "            return CONFIG['LLM_MODEL'] in models\n",
    "        return False\n",
    "    except: print(\"❌ Ollama not running\"); return False\n",
    "\n",
    "check_deps()\n",
    "ollama_ready = check_ollama() if CONFIG['LLM_PROVIDER'] == 'ollama' else True\n",
    "\n",
    "# Safe OCR initialization\n",
    "def init_ocr_safe():\n",
    "    try:\n",
    "        from paddleocr import PaddleOCR\n",
    "        return PaddleOCR(\n",
    "            use_textline_orientation=True,\n",
    "            lang='en'\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"OCR initialization error: {e}\")\n",
    "        return None\n",
    "\n",
    "# Generic Image Text Search System\n",
    "class GenericOCRSearchSystem:\n",
    "    def __init__(self, config=None):\n",
    "        self.config = config or CONFIG.copy()\n",
    "        self._setup_dirs()\n",
    "        self._init_db()\n",
    "        self._init_ocr()\n",
    "        self._init_llm()\n",
    "\n",
    "    def _setup_dirs(self):\n",
    "        for k in ['IMAGE_GALLERY_PATH', 'DATABASE_PATH', 'RESULTS_OUTPUT_PATH', 'VECTOR_STORE_PATH']:\n",
    "            os.makedirs(self.config[k], exist_ok=True)\n",
    "\n",
    "    def _init_db(self):\n",
    "        db_path = os.path.join(self.config['DATABASE_PATH'], 'image_text.db')\n",
    "        self.conn = sqlite3.connect(db_path)\n",
    "        self.conn.execute('''CREATE TABLE IF NOT EXISTS image_texts (\n",
    "            id INTEGER PRIMARY KEY,\n",
    "            filename TEXT UNIQUE,\n",
    "            full_path TEXT,\n",
    "            extracted_text TEXT,\n",
    "            ocr_confidence REAL,\n",
    "            processed_date TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
    "            text_analysis TEXT,\n",
    "            relevance_score REAL,\n",
    "            vector_stored BOOLEAN DEFAULT 0\n",
    "        )''')\n",
    "        self.conn.execute('''CREATE TABLE IF NOT EXISTS text_searches (\n",
    "            id INTEGER PRIMARY KEY,\n",
    "            query TEXT,\n",
    "            search_date TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
    "            results_json TEXT,\n",
    "            matched_images TEXT,\n",
    "            model_used TEXT,\n",
    "            processing_time REAL\n",
    "        )''')\n",
    "        self.conn.commit()\n",
    "\n",
    "    def _init_ocr(self):\n",
    "        try:\n",
    "            ocr_model = self.config['OCR_MODEL']\n",
    "            if ocr_model == 'paddleocr':\n",
    "                from paddleocr import PaddleOCR\n",
    "                self.ocr = init_ocr_safe()\n",
    "            elif ocr_model == 'easyocr':\n",
    "                import easyocr\n",
    "                self.ocr = easyocr.Reader(['en'], gpu=False)\n",
    "            elif ocr_model == 'tesseract':\n",
    "                import pytesseract\n",
    "                self.ocr = pytesseract\n",
    "            elif ocr_model == 'trocr':\n",
    "                from transformers import TrOCRProcessor, VisionEncoderDecoderModel\n",
    "                self.ocr_processor = TrOCRProcessor.from_pretrained('microsoft/trocr-base-printed')\n",
    "                self.ocr_model = VisionEncoderDecoderModel.from_pretrained('microsoft/trocr-base-printed')\n",
    "                self.ocr = 'trocr'\n",
    "            print(f\"✅ {OCR_MODELS[ocr_model]['name']} ready\")\n",
    "        except Exception as e:\n",
    "            print(f\"❌ OCR error: {e}\");\n",
    "            self.ocr = None\n",
    "\n",
    "    def _init_llm(self):\n",
    "        try:\n",
    "            if self.config['LLM_PROVIDER'] == 'ollama':\n",
    "                from langchain_community.llms import Ollama\n",
    "                self.llm = Ollama(\n",
    "                    model=self.config['LLM_MODEL'],\n",
    "                    base_url=self.config['LLM_BASE_URL'],\n",
    "                    temperature=self.config['LLM_TEMPERATURE']\n",
    "                )\n",
    "            elif self.config['LLM_PROVIDER'] == 'transformers':\n",
    "                from langchain_community.llms import HuggingFacePipeline\n",
    "                from transformers import pipeline\n",
    "                pipe = pipeline(\"text-generation\", model=self.config['LLM_MODEL'],\n",
    "                              max_new_tokens=self.config['LLM_MAX_TOKENS'])\n",
    "                self.llm = HuggingFacePipeline(pipeline=pipe)\n",
    "\n",
    "            from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "            from langchain_community.vectorstores import Chroma\n",
    "            from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "            self.embeddings = HuggingFaceEmbeddings(\n",
    "                model_name=self.config['EMBEDDING_MODEL'],\n",
    "                model_kwargs={'device': 'cpu'}\n",
    "            )\n",
    "            self.vectorstore = Chroma(\n",
    "                persist_directory=self.config['VECTOR_STORE_PATH'],\n",
    "                embedding_function=self.embeddings\n",
    "            )\n",
    "            self.text_splitter = RecursiveCharacterTextSplitter(\n",
    "                chunk_size=self.config['CHUNK_SIZE'],\n",
    "                chunk_overlap=self.config['CHUNK_OVERLAP']\n",
    "            )\n",
    "            print(\"✅ LangChain ready\")\n",
    "        except Exception as e:\n",
    "            print(f\"❌ LLM error: {e}\")\n",
    "\n",
    "    def extract_text(self, img_path: str) -> Dict[str, Any]:\n",
    "        \"\"\"Extract text from image using selected OCR model\"\"\"\n",
    "        try:\n",
    "            img = Image.open(img_path).convert(\"RGB\")\n",
    "            result = {\n",
    "                'filename': os.path.basename(img_path),\n",
    "                'full_path': img_path,\n",
    "                'extracted_text': '',\n",
    "                'ocr_confidence': 0.0,\n",
    "                'error': None\n",
    "            }\n",
    "\n",
    "            if self.ocr:\n",
    "                ocr_model = self.config['OCR_MODEL']\n",
    "\n",
    "                if ocr_model == 'paddleocr':\n",
    "                    ocr_result = self.ocr.ocr(np.array(img), cls=True)\n",
    "                    if ocr_result and ocr_result[0]:\n",
    "                        texts, confs = [], []\n",
    "                        for line in ocr_result:\n",
    "                            for detection in line:\n",
    "                                bbox, (text, conf) = detection\n",
    "                                if conf >= self.config['OCR_CONFIDENCE_THRESHOLD']:\n",
    "                                    texts.append(text); confs.append(conf)\n",
    "                        result.update({\n",
    "                            'extracted_text': ' '.join(texts),\n",
    "                            'ocr_confidence': np.mean(confs) if confs else 0.0\n",
    "                        })\n",
    "\n",
    "                elif ocr_model == 'easyocr':\n",
    "                    ocr_result = self.ocr.readtext(np.array(img))\n",
    "                    texts, confs = [], []\n",
    "                    for detection in ocr_result:\n",
    "                        bbox, text, conf = detection\n",
    "                        if conf >= self.config['OCR_CONFIDENCE_THRESHOLD']:\n",
    "                            texts.append(text); confs.append(conf)\n",
    "                    result.update({\n",
    "                        'extracted_text': ' '.join(texts),\n",
    "                        'ocr_confidence': np.mean(confs) if confs else 0.0\n",
    "                    })\n",
    "\n",
    "                elif ocr_model == 'tesseract':\n",
    "                    import pytesseract\n",
    "                    text = pytesseract.image_to_string(img, config='--psm 6')\n",
    "                    if text.strip():\n",
    "                        result.update({\n",
    "                            'extracted_text': text.strip(),\n",
    "                            'ocr_confidence': 0.8\n",
    "                        })\n",
    "\n",
    "                elif ocr_model == 'trocr':\n",
    "                    pixel_values = self.ocr_processor(images=img, return_tensors=\"pt\").pixel_values\n",
    "                    generated_ids = self.ocr_model.generate(pixel_values)\n",
    "                    text = self.ocr_processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "                    if text.strip():\n",
    "                        result.update({\n",
    "                            'extracted_text': text.strip(),\n",
    "                            'ocr_confidence': 0.9\n",
    "                        })\n",
    "\n",
    "            return result\n",
    "        except Exception as e:\n",
    "            return {\n",
    "                'filename': os.path.basename(img_path),\n",
    "                'full_path': img_path,\n",
    "                'extracted_text': '',\n",
    "                'ocr_confidence': 0.0,\n",
    "                'error': str(e)\n",
    "            }\n",
    "\n",
    "    def analyze_text_relevance(self, text: str, filename: str, search_context: str = \"\") -> Dict[str, Any]:\n",
    "        \"\"\"Analyze text relevance for search queries\"\"\"\n",
    "        prompt = f'''Analyze the text content from image '{filename}':\n",
    "Text: {text}\n",
    "Context: {search_context if search_context else \"General text analysis\"}\n",
    "\n",
    "Respond with JSON only:\n",
    "{{\n",
    "    \"contains_relevant_text\": true/false,\n",
    "    \"relevance_score\": 0.0-1.0,\n",
    "    \"key_phrases\": [\"phrase1\", \"phrase2\"],\n",
    "    \"content_summary\": \"brief summary\",\n",
    "    \"text_categories\": [\"category1\", \"category2\"],\n",
    "    \"searchable_keywords\": [\"keyword1\", \"keyword2\"]\n",
    "}}'''\n",
    "\n",
    "        try:\n",
    "            response = str(self.llm.invoke(prompt)).strip()\n",
    "            response = response.replace('```json', '').replace('```', '').strip()\n",
    "            start, end = response.find('{'), response.rfind('}') + 1\n",
    "\n",
    "            if start >= 0 and end > start:\n",
    "                parsed = json.loads(response[start:end])\n",
    "                return {\n",
    "                    'contains_relevant_text': parsed.get('contains_relevant_text', False),\n",
    "                    'relevance_score': parsed.get('relevance_score', 0.0),\n",
    "                    'key_phrases': parsed.get('key_phrases', []),\n",
    "                    'content_summary': parsed.get('content_summary', ''),\n",
    "                    'text_categories': parsed.get('text_categories', []),\n",
    "                    'searchable_keywords': parsed.get('searchable_keywords', [])\n",
    "                }\n",
    "            else:\n",
    "                return self._fallback_analysis(text, filename)\n",
    "        except:\n",
    "            return self._fallback_analysis(text, filename)\n",
    "\n",
    "    def _fallback_analysis(self, text: str, filename: str) -> Dict[str, Any]:\n",
    "        \"\"\"Fallback analysis when LLM fails\"\"\"\n",
    "        words = text.lower().split()\n",
    "        return {\n",
    "            'contains_relevant_text': len(words) > 3,\n",
    "            'relevance_score': min(len(words) / 50.0, 1.0),\n",
    "            'key_phrases': words[:5],\n",
    "            'content_summary': f'Text with {len(words)} words',\n",
    "            'text_categories': ['text_document'],\n",
    "            'searchable_keywords': words[:10]\n",
    "        }\n",
    "\n",
    "    def add_to_vectorstore(self, text: str, metadata: Dict[str, Any]):\n",
    "        \"\"\"Add text to vector store for similarity search\"\"\"\n",
    "        try:\n",
    "            from langchain_core.documents import Document\n",
    "            chunks = self.text_splitter.split_text(text)\n",
    "            docs = [Document(page_content=chunk, metadata={**metadata, 'chunk_id': i})\n",
    "                   for i, chunk in enumerate(chunks)]\n",
    "            self.vectorstore.add_documents(docs)\n",
    "            self.vectorstore.persist()\n",
    "            return True\n",
    "        except:\n",
    "            return False\n",
    "\n",
    "    def process_images(self):\n",
    "        \"\"\"Process all images in the gallery to extract text\"\"\"\n",
    "        start_time = time.time()\n",
    "        gallery_path = Path(self.config['IMAGE_GALLERY_PATH'])\n",
    "        print(f\"🔍 PROCESSING: {gallery_path} | OCR: {self.config['OCR_MODEL']}\")\n",
    "\n",
    "        if not gallery_path.exists():\n",
    "            print(f\"❌ Path not found: {gallery_path}\");\n",
    "            return\n",
    "\n",
    "        exts = ['.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.webp']\n",
    "        files = [f for ext in exts\n",
    "                for f in list(gallery_path.glob(f\"**/*{ext}\")) +\n",
    "                         list(gallery_path.glob(f\"**/*{ext.upper()}\"))]\n",
    "        total, processed, vector_stored = len(files), 0, 0\n",
    "\n",
    "        print(f\"📸 Found {total} images\")\n",
    "        if total == 0:\n",
    "            print(\"⚠️ No images found!\");\n",
    "            return\n",
    "\n",
    "        for i, img_path in enumerate(files, 1):\n",
    "            filename = img_path.name\n",
    "            print(f\"[{i:3d}/{total}] ({i/total*100:5.1f}%) {filename[:40]}...\", end='')\n",
    "\n",
    "            # Skip if already processed\n",
    "            if self.conn.execute(\"SELECT id FROM image_texts WHERE filename = ?\", (filename,)).fetchone():\n",
    "                print(\" ⏭️ SKIP\");\n",
    "                continue\n",
    "\n",
    "            # Extract text\n",
    "            ocr_result = self.extract_text(img_path)\n",
    "            if ocr_result.get('error'):\n",
    "                print(\" ❌ ERROR\");\n",
    "                continue\n",
    "\n",
    "            text = ocr_result['extracted_text']\n",
    "            analysis = None\n",
    "\n",
    "            if text.strip():\n",
    "                analysis = self.analyze_text_relevance(text, filename)\n",
    "                metadata = {\n",
    "                    'filename': filename,\n",
    "                    'full_path': str(img_path),\n",
    "                    'ocr_confidence': ocr_result['ocr_confidence']\n",
    "                }\n",
    "                if self.add_to_vectorstore(text, metadata):\n",
    "                    vector_stored += 1\n",
    "\n",
    "            # Store in database\n",
    "            relevance = analysis['relevance_score'] if analysis else 0.0\n",
    "            self.conn.execute('''INSERT OR REPLACE INTO image_texts\n",
    "                (filename, full_path, extracted_text, ocr_confidence, text_analysis,\n",
    "                 relevance_score, vector_stored) VALUES (?,?,?,?,?,?,?)''',\n",
    "                (filename, str(img_path), text, ocr_result['ocr_confidence'],\n",
    "                 json.dumps(analysis) if analysis else None, relevance, vector_stored > 0))\n",
    "\n",
    "            if text.strip():\n",
    "                print(f\" ✅ TEXT ({len(text.split())} words)\")\n",
    "            else:\n",
    "                print(\" ⚪ NO TEXT\")\n",
    "\n",
    "            processed += 1\n",
    "            if i % 10 == 0:\n",
    "                self.conn.commit()\n",
    "\n",
    "        self.conn.commit()\n",
    "        print(f\"\\n🔍 COMPLETE: {processed} processed, {vector_stored} vectorized, {time.time()-start_time:.1f}s\")\n",
    "\n",
    "    def search_text(self, query: str) -> Dict[str, Any]:\n",
    "        \"\"\"Search for text across all processed images\"\"\"\n",
    "        print(f\"🔍 SEARCHING: '{query}'\")\n",
    "        try:\n",
    "            # Use vector similarity search\n",
    "            docs = self.vectorstore.similarity_search(query, k=10)\n",
    "            if not docs:\n",
    "                return {\n",
    "                    'matches': [],\n",
    "                    'summary': 'No matches found',\n",
    "                    'total_matches': 0\n",
    "                }\n",
    "\n",
    "            # Group results by image\n",
    "            image_matches = {}\n",
    "            for doc in docs:\n",
    "                filename = doc.metadata.get('filename', 'unknown')\n",
    "                if filename not in image_matches:\n",
    "                    image_matches[filename] = {\n",
    "                        'filename': filename,\n",
    "                        'full_path': doc.metadata.get('full_path', ''),\n",
    "                        'text_chunks': [],\n",
    "                        'relevance_score': 0.0\n",
    "                    }\n",
    "                image_matches[filename]['text_chunks'].append(doc.page_content)\n",
    "\n",
    "            # Get additional info from database\n",
    "            matches = []\n",
    "            for filename, data in image_matches.items():\n",
    "                db_result = self.conn.execute('''SELECT extracted_text, ocr_confidence, text_analysis\n",
    "                    FROM image_texts WHERE filename = ?''', (filename,)).fetchone()\n",
    "\n",
    "                if db_result:\n",
    "                    full_text, confidence, analysis = db_result\n",
    "\n",
    "                    # Calculate relevance based on query match\n",
    "                    relevance = self._calculate_relevance(query, full_text)\n",
    "\n",
    "                    matches.append({\n",
    "                        'filename': filename,\n",
    "                        'full_path': data['full_path'],\n",
    "                        'extracted_text': full_text,\n",
    "                        'ocr_confidence': confidence,\n",
    "                        'relevance_score': relevance,\n",
    "                        'matching_chunks': data['text_chunks'][:3],  # Top 3 chunks\n",
    "                        'analysis': json.loads(analysis) if analysis else None\n",
    "                    })\n",
    "\n",
    "            # Sort by relevance\n",
    "            matches.sort(key=lambda x: x['relevance_score'], reverse=True)\n",
    "\n",
    "            results = {\n",
    "                'matches': matches,\n",
    "                'summary': f\"Found {len(matches)} images with matching text\",\n",
    "                'total_matches': len(matches),\n",
    "                'query': query\n",
    "            }\n",
    "\n",
    "            # Store search in database\n",
    "            self.conn.execute('''INSERT INTO text_searches\n",
    "                (query, results_json, matched_images, model_used) VALUES (?,?,?,?)''',\n",
    "                (query, json.dumps(results),\n",
    "                 json.dumps([m['filename'] for m in matches]),\n",
    "                 f\"{self.config['LLM_PROVIDER']}-{self.config['LLM_MODEL']}\"))\n",
    "            self.conn.commit()\n",
    "\n",
    "            print(f\"✅ Found {len(matches)} matches\")\n",
    "            return results\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error: {e}\")\n",
    "            return {\n",
    "                'matches': [],\n",
    "                'summary': f'Search error: {e}',\n",
    "                'total_matches': 0\n",
    "            }\n",
    "\n",
    "    def _calculate_relevance(self, query: str, text: str) -> float:\n",
    "        \"\"\"Calculate relevance score between query and text\"\"\"\n",
    "        query_words = set(query.lower().split())\n",
    "        text_words = set(text.lower().split())\n",
    "\n",
    "        if not query_words or not text_words:\n",
    "            return 0.0\n",
    "\n",
    "        # Simple word overlap scoring\n",
    "        overlap = len(query_words.intersection(text_words))\n",
    "        return min(overlap / len(query_words), 1.0)\n",
    "\n",
    "    def get_all_texts(self, min_confidence=0.5):\n",
    "        \"\"\"Get all extracted texts above confidence threshold\"\"\"\n",
    "        return self.conn.execute('''SELECT filename, full_path, extracted_text,\n",
    "            ocr_confidence, text_analysis FROM image_texts\n",
    "            WHERE ocr_confidence >= ? ORDER BY ocr_confidence DESC''',\n",
    "            (min_confidence,)).fetchall()\n",
    "\n",
    "    def export_results(self, results: Dict[str, Any], query: str) -> str:\n",
    "        \"\"\"Export search results to files\"\"\"\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        query_safe = query.replace(' ', '_')[:30]\n",
    "        output_path = Path(self.config['RESULTS_OUTPUT_PATH']) / f\"search_{query_safe}_{timestamp}\"\n",
    "        output_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        # Copy matching images\n",
    "        copied = []\n",
    "        for i, match in enumerate(results.get('matches', []), 1):\n",
    "            if Path(match['full_path']).exists():\n",
    "                dest = output_path / f\"{i:03d}_{match['filename']}\"\n",
    "                shutil.copy2(match['full_path'], dest)\n",
    "                copied.append(str(dest))\n",
    "\n",
    "        # Save reports\n",
    "        report = {\n",
    "            'query': query,\n",
    "            'timestamp': timestamp,\n",
    "            'ocr_model': self.config['OCR_MODEL'],\n",
    "            'llm_model': f\"{self.config['LLM_PROVIDER']}-{self.config['LLM_MODEL']}\",\n",
    "            'results': results,\n",
    "            'copied_files': copied\n",
    "        }\n",
    "\n",
    "        with open(output_path / \"search_report.json\", 'w') as f:\n",
    "            json.dump(report, f, indent=2)\n",
    "\n",
    "        with open(output_path / \"summary.txt\", 'w') as f:\n",
    "            f.write(f\"IMAGE TEXT SEARCH REPORT\\n\")\n",
    "            f.write(f\"Query: {query}\\n\")\n",
    "            f.write(f\"Date: {timestamp}\\n\")\n",
    "            f.write(f\"OCR: {self.config['OCR_MODEL']}\\n\")\n",
    "            f.write(f\"LLM: {self.config['LLM_PROVIDER']}-{self.config['LLM_MODEL']}\\n\")\n",
    "            f.write(f\"Matches: {len(results.get('matches', []))}\\n\")\n",
    "            f.write(f\"Summary: {results.get('summary', 'N/A')}\\n\\n\")\n",
    "\n",
    "            for i, match in enumerate(results.get('matches', []), 1):\n",
    "                f.write(f\"{i}. {match['filename']} (Confidence: {match['ocr_confidence']:.3f})\\n\")\n",
    "                f.write(f\"   Text: {match['extracted_text'][:200]}...\\n\\n\")\n",
    "\n",
    "        print(f\"📋 Results exported to: {output_path}\")\n",
    "        return str(output_path)\n",
    "\n",
    "    def close(self):\n",
    "        \"\"\"Close database connection\"\"\"\n",
    "        if hasattr(self, 'conn') and self.conn:\n",
    "            self.conn.close()\n",
    "\n",
    "# GUI Interface\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def create_search_gui():\n",
    "    \"\"\"Create interactive GUI for the OCR search system\"\"\"\n",
    "\n",
    "    # Configuration widgets\n",
    "    ocr_selector = widgets.Dropdown(\n",
    "        options=[\n",
    "            ('PaddleOCR - Best overall, 80+ languages', 'paddleocr'),\n",
    "            ('EasyOCR - Good for European languages', 'easyocr'),\n",
    "            ('Tesseract - Classic OCR for printed text', 'tesseract'),\n",
    "            ('TrOCR - AI-based OCR for handwriting', 'trocr')\n",
    "        ],\n",
    "        value='paddleocr',\n",
    "        description='OCR Engine:',\n",
    "        style={'description_width': 'initial'},\n",
    "        layout=widgets.Layout(width='500px')\n",
    "    )\n",
    "\n",
    "    llm_provider = widgets.Dropdown(\n",
    "        options=[('Ollama', 'ollama'), ('Transformers', 'transformers')],\n",
    "        value='ollama',\n",
    "        description='LLM Provider:',\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "\n",
    "    llm_model = widgets.Text(\n",
    "        value='llama3.2:latest',\n",
    "        description='LLM Model:',\n",
    "        style={'description_width': 'initial'},\n",
    "        layout=widgets.Layout(width='300px')\n",
    "    )\n",
    "\n",
    "    gallery_path = widgets.Text(\n",
    "        value='../../../datasets/images/text_ocr',\n",
    "        description='Image Folder:',\n",
    "        style={'description_width': 'initial'},\n",
    "        layout=widgets.Layout(width='400px')\n",
    "    )\n",
    "\n",
    "    search_input = widgets.Textarea(\n",
    "        value='Enter text to search for in images...',\n",
    "        description='Search Query:',\n",
    "        style={'description_width': 'initial'},\n",
    "        layout=widgets.Layout(width='500px', height='60px')\n",
    "    )\n",
    "\n",
    "    confidence_slider = widgets.FloatSlider(\n",
    "        value=0.60,\n",
    "        min=0.1, max=0.9, step=0.05,\n",
    "        description='OCR Confidence:',\n",
    "        style={'description_width': 'initial'},\n",
    "        readout_format='.2f'\n",
    "    )\n",
    "\n",
    "    # Quick search examples\n",
    "    quick_searches = [\n",
    "        \"phone numbers\", \"email addresses\", \"addresses\",\n",
    "        \"names\", \"dates\", \"prices\"\n",
    "    ]\n",
    "    quick_btns = [widgets.Button(\n",
    "        description=q,\n",
    "        tooltip=f\"Search for {q}\",\n",
    "        layout=widgets.Layout(width='150px', margin='2px')\n",
    "    ) for q in quick_searches]\n",
    "\n",
    "    # Action buttons\n",
    "    test_btn = widgets.Button(description='🔍 Test Setup', button_style='info', layout=widgets.Layout(width='120px'))\n",
    "    process_btn = widgets.Button(description='📁 Process Images', button_style='primary', layout=widgets.Layout(width='140px'))\n",
    "    search_btn = widgets.Button(description='🔍 Search Text', button_style='success', layout=widgets.Layout(width='120px'))\n",
    "    show_all_btn = widgets.Button(description='📝 Show All Texts', button_style='warning', layout=widgets.Layout(width='140px'))\n",
    "    export_btn = widgets.Button(description='📋 Export Results', button_style='success', layout=widgets.Layout(width='140px'), disabled=True)\n",
    "    clear_btn = widgets.Button(description='🗑️ Clear', layout=widgets.Layout(width='120px'))\n",
    "\n",
    "    status_label = widgets.HTML(value=\"<b>Status:</b> Ready\")\n",
    "    progress_bar = widgets.IntProgress(value=0, min=0, max=100, layout=widgets.Layout(width='400px'))\n",
    "    output_area = widgets.Output()\n",
    "\n",
    "    # State variables\n",
    "    current_system = None\n",
    "    current_results = None\n",
    "\n",
    "    def update_status(msg, progress=None):\n",
    "        status_label.value = f\"<b>Status:</b> {msg}\"\n",
    "        if progress is not None:\n",
    "            progress_bar.value = progress\n",
    "\n",
    "    def init_system():\n",
    "        nonlocal current_system\n",
    "        try:\n",
    "            config = CONFIG.copy()\n",
    "            config.update({\n",
    "                'OCR_MODEL': ocr_selector.value,\n",
    "                'LLM_PROVIDER': llm_provider.value,\n",
    "                'LLM_MODEL': llm_model.value,\n",
    "                'IMAGE_GALLERY_PATH': gallery_path.value,\n",
    "                'OCR_CONFIDENCE_THRESHOLD': confidence_slider.value\n",
    "            })\n",
    "            current_system = GenericOCRSearchSystem(config)\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"❌ System initialization error: {e}\")\n",
    "            return False\n",
    "\n",
    "    # Button event handlers\n",
    "    def on_quick_search(search_text):\n",
    "        def handler(b):\n",
    "            search_input.value = search_text\n",
    "        return handler\n",
    "\n",
    "    for i, btn in enumerate(quick_btns):\n",
    "        btn.on_click(on_quick_search(quick_searches[i]))\n",
    "\n",
    "    def on_test(b):\n",
    "        with output_area:\n",
    "            clear_output(wait=True)\n",
    "            update_status(\"Testing setup...\", 20)\n",
    "            print(\"🔍 TESTING OCR TEXT SEARCH SETUP\")\n",
    "            print(\"=\"*50)\n",
    "\n",
    "            # Test OCR\n",
    "            print(f\"Selected OCR: {ocr_selector.value}\")\n",
    "            ocr_info = OCR_MODELS.get(ocr_selector.value, {})\n",
    "            print(f\"Purpose: {ocr_info.get('strengths', 'General OCR')}\")\n",
    "\n",
    "            try:\n",
    "                if ocr_selector.value == 'paddleocr':\n",
    "                    import paddleocr; print(\"✅ PaddleOCR available\")\n",
    "                elif ocr_selector.value == 'easyocr':\n",
    "                    import easyocr; print(\"✅ EasyOCR available\")\n",
    "                elif ocr_selector.value == 'tesseract':\n",
    "                    import pytesseract; print(\"✅ Tesseract available\")\n",
    "                elif ocr_selector.value == 'trocr':\n",
    "                    import transformers; print(\"✅ TrOCR available\")\n",
    "            except ImportError as e:\n",
    "                print(f\"❌ {ocr_selector.value} not found: {e}\")\n",
    "\n",
    "            # Test dependencies\n",
    "            deps = [('langchain', 'LangChain'), ('chromadb', 'ChromaDB'), ('sentence_transformers', 'Transformers')]\n",
    "            for dep, name in deps:\n",
    "                try:\n",
    "                    __import__(dep.replace('-', '_'));\n",
    "                    print(f\"✅ {name}\")\n",
    "                except ImportError:\n",
    "                    print(f\"❌ {name} not found\")\n",
    "\n",
    "            # Test Ollama if selected\n",
    "            if llm_provider.value == 'ollama':\n",
    "                update_status(\"Testing Ollama...\", 60)\n",
    "                try:\n",
    "                    import requests\n",
    "                    r = requests.get(\"http://localhost:11434/api/tags\", timeout=5)\n",
    "                    if r.status_code == 200:\n",
    "                        models = [m['name'] for m in r.json().get('models', [])]\n",
    "                        print(f\"✅ Ollama models: {models}\")\n",
    "                        if llm_model.value in models:\n",
    "                            print(f\"✅ Model '{llm_model.value}' ready\")\n",
    "                        else:\n",
    "                            print(f\"⚠️ Model '{llm_model.value}' not found. Install: ollama pull {llm_model.value}\")\n",
    "                    else:\n",
    "                        print(\"❌ Ollama not responding\")\n",
    "                except:\n",
    "                    print(\"❌ Ollama connection failed. Start: ollama serve\")\n",
    "\n",
    "            # Test image folder\n",
    "            if Path(gallery_path.value).exists():\n",
    "                img_count = len([f for f in Path(gallery_path.value).glob('**/*')\n",
    "                               if f.suffix.lower() in ['.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.webp']])\n",
    "                print(f\"✅ Image folder: {img_count} images found\")\n",
    "            else:\n",
    "                print(f\"⚠️ Image folder not found: {gallery_path.value}\")\n",
    "\n",
    "            update_status(\"Testing system initialization...\", 80)\n",
    "            if init_system():\n",
    "                print(\"✅ System ready for text search\")\n",
    "                update_status(\"Setup complete!\", 100)\n",
    "            else:\n",
    "                print(\"❌ System initialization failed\")\n",
    "                update_status(\"Setup failed\", 0)\n",
    "\n",
    "    def on_process(b):\n",
    "        with output_area:\n",
    "            clear_output(wait=True)\n",
    "            update_status(\"Processing images...\", 20)\n",
    "            if not init_system():\n",
    "                update_status(\"Initialization failed\", 0)\n",
    "                return\n",
    "\n",
    "            print(f\"🔍 PROCESSING IMAGES | OCR: {ocr_selector.value} | LLM: {llm_provider.value}-{llm_model.value}\")\n",
    "            try:\n",
    "                current_system.process_images()\n",
    "                update_status(\"Processing complete!\", 100)\n",
    "\n",
    "                # Show summary\n",
    "                total_texts = current_system.conn.execute(\"SELECT COUNT(*) FROM image_texts WHERE extracted_text != ''\").fetchone()[0]\n",
    "                total_images = current_system.conn.execute(\"SELECT COUNT(*) FROM image_texts\").fetchone()[0]\n",
    "                print(f\"\\n📊 SUMMARY: {total_texts}/{total_images} images contain extractable text\")\n",
    "\n",
    "            except Exception as e:\n",
    "                update_status(\"Processing error\", 0)\n",
    "                print(f\"❌ Error: {e}\")\n",
    "\n",
    "    def on_search(b):\n",
    "        nonlocal current_results\n",
    "        with output_area:\n",
    "            clear_output(wait=True)\n",
    "            if not current_system and not init_system():\n",
    "                print(\"❌ System not ready\")\n",
    "                return\n",
    "\n",
    "            query = search_input.value.strip()\n",
    "            if not query or query == \"Enter text to search for in images...\":\n",
    "                print(\"⚠️ Please enter a search query\")\n",
    "                return\n",
    "\n",
    "            update_status(\"Searching...\", 50)\n",
    "            print(f\"🔍 SEARCHING: '{query}' | OCR: {ocr_selector.value}\")\n",
    "\n",
    "            try:\n",
    "                current_results = current_system.search_text(query)\n",
    "                matches = current_results.get('matches', [])\n",
    "\n",
    "                if matches:\n",
    "                    update_status(f\"Found {len(matches)} matches\", 100)\n",
    "                    export_btn.disabled = False\n",
    "\n",
    "                    print(f\"📊 {current_results.get('summary', 'No summary')}\")\n",
    "                    print(\"\\n🔍 SEARCH RESULTS:\")\n",
    "                    print(\"-\" * 60)\n",
    "\n",
    "                    for i, match in enumerate(matches[:10], 1):  # Show top 10\n",
    "                        print(f\"{i}. {match['filename']}\")\n",
    "                        print(f\"   Confidence: {match['ocr_confidence']:.3f} | Relevance: {match['relevance_score']:.3f}\")\n",
    "                        print(f\"   Text: {match['extracted_text'][:150]}...\")\n",
    "                        if match.get('matching_chunks'):\n",
    "                            print(f\"   Matching: {match['matching_chunks'][0][:100]}...\")\n",
    "                        print()\n",
    "\n",
    "                    # Display matching images\n",
    "                    if matches:\n",
    "                        print(f\"🖼️ Displaying {min(6, len(matches))} matching images...\")\n",
    "                        display_search_results([m['filename'] for m in matches[:6]], current_system)\n",
    "\n",
    "                else:\n",
    "                    update_status(\"No matches found\", 100)\n",
    "                    export_btn.disabled = True\n",
    "                    print(\"❌ No matches found. Try different search terms or check if images are processed.\")\n",
    "\n",
    "            except Exception as e:\n",
    "                update_status(\"Search error\", 0)\n",
    "                print(f\"❌ Search error: {e}\")\n",
    "\n",
    "    def on_show_all(b):\n",
    "        with output_area:\n",
    "            clear_output(wait=True)\n",
    "            if not current_system and not init_system():\n",
    "                print(\"❌ System not ready\")\n",
    "                return\n",
    "\n",
    "            update_status(\"Loading all texts...\", 50)\n",
    "            try:\n",
    "                all_texts = current_system.get_all_texts(confidence_slider.value)\n",
    "                if all_texts:\n",
    "                    print(f\"📝 ALL EXTRACTED TEXTS (Confidence ≥ {confidence_slider.value})\")\n",
    "                    print(\"=\" * 70)\n",
    "\n",
    "                    for i, (filename, path, text, conf, analysis) in enumerate(all_texts, 1):\n",
    "                        print(f\"{i}. {filename} | Confidence: {conf:.3f}\")\n",
    "                        print(f\"   Text: {text[:200]}...\")\n",
    "\n",
    "                        if analysis:\n",
    "                            try:\n",
    "                                data = json.loads(analysis)\n",
    "                                keywords = data.get('searchable_keywords', [])\n",
    "                                if keywords:\n",
    "                                    print(f\"   Keywords: {', '.join(keywords[:8])}\")\n",
    "                            except:\n",
    "                                pass\n",
    "                        print()\n",
    "\n",
    "                        if i >= 20:  # Limit display\n",
    "                            print(f\"... and {len(all_texts) - 20} more images\")\n",
    "                            break\n",
    "\n",
    "                    update_status(f\"Showing {len(all_texts)} texts\", 100)\n",
    "                else:\n",
    "                    print(f\"📝 No texts found with confidence ≥ {confidence_slider.value}\")\n",
    "                    print(\"Try lowering the confidence threshold or process more images.\")\n",
    "                    update_status(\"No texts found\", 100)\n",
    "\n",
    "            except Exception as e:\n",
    "                update_status(\"Error loading texts\", 0)\n",
    "                print(f\"❌ Error: {e}\")\n",
    "\n",
    "    def on_export(b):\n",
    "        with output_area:\n",
    "            if not current_results:\n",
    "                print(\"⚠️ No search results to export\")\n",
    "                return\n",
    "            try:\n",
    "                update_status(\"Exporting results...\", 50)\n",
    "                path = current_system.export_results(current_results, search_input.value or \"search\")\n",
    "                update_status(\"Export complete!\", 100)\n",
    "                print(f\"✅ Search results exported to: {path}\")\n",
    "            except Exception as e:\n",
    "                update_status(\"Export error\", 0)\n",
    "                print(f\"❌ Export error: {e}\")\n",
    "\n",
    "    def on_clear(b):\n",
    "        nonlocal current_results\n",
    "        current_results = None\n",
    "        export_btn.disabled = True\n",
    "        with output_area:\n",
    "            clear_output()\n",
    "            update_status(\"Cleared\", 0)\n",
    "            print(\"🗑️ Output cleared\")\n",
    "\n",
    "    # Connect button events\n",
    "    test_btn.on_click(on_test)\n",
    "    process_btn.on_click(on_process)\n",
    "    search_btn.on_click(on_search)\n",
    "    show_all_btn.on_click(on_show_all)\n",
    "    export_btn.on_click(on_export)\n",
    "    clear_btn.on_click(on_clear)\n",
    "\n",
    "    # Layout components\n",
    "    quick_grid = widgets.GridBox(\n",
    "        quick_btns,\n",
    "        layout=widgets.Layout(grid_template_columns='repeat(3, 1fr)', grid_gap='5px')\n",
    "    )\n",
    "\n",
    "    controls = widgets.VBox([\n",
    "        widgets.HTML(\"<h3>🔍 Generic OCR Image Text Search System</h3>\"),\n",
    "        widgets.HTML(\"<p><i>Extract and search text from any images in your folder</i></p>\"),\n",
    "\n",
    "        widgets.HTML(\"<b>🔧 Configuration:</b>\"),\n",
    "        ocr_selector,\n",
    "        widgets.HBox([llm_provider, llm_model]),\n",
    "        gallery_path,\n",
    "        widgets.HBox([confidence_slider]),\n",
    "\n",
    "        widgets.HTML(\"<br><b>🔍 Search:</b>\"),\n",
    "        search_input,\n",
    "        widgets.HTML(\"<b>Quick Search Examples:</b>\"),\n",
    "        quick_grid,\n",
    "\n",
    "        widgets.HTML(\"<br><b>🎛️ Actions:</b>\"),\n",
    "        widgets.HBox([test_btn, process_btn, search_btn]),\n",
    "        widgets.HBox([show_all_btn, export_btn, clear_btn]),\n",
    "\n",
    "        status_label,\n",
    "        progress_bar,\n",
    "        widgets.HTML(\"<hr>\")\n",
    "    ])\n",
    "\n",
    "    return widgets.VBox([controls, output_area])\n",
    "\n",
    "def display_search_results(filenames: List[str], system: GenericOCRSearchSystem, max_images=6):\n",
    "    \"\"\"Display search result images with their extracted text\"\"\"\n",
    "    if not filenames:\n",
    "        return\n",
    "\n",
    "    num = min(len(filenames), max_images)\n",
    "    cols = 3 if num > 4 else 2 if num > 1 else 1\n",
    "    rows = (num + cols - 1) // cols\n",
    "\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(15, 5*rows))\n",
    "    if num == 1:\n",
    "        axes = [axes]\n",
    "    elif rows == 1:\n",
    "        axes = axes if num > 1 else [axes]\n",
    "    else:\n",
    "        axes = axes.flatten()\n",
    "\n",
    "    for i, filename in enumerate(filenames[:num]):\n",
    "        ax = axes[i] if num > 1 else axes[0]\n",
    "        try:\n",
    "            # Get image info from database\n",
    "            result = system.conn.execute('''SELECT full_path, extracted_text, ocr_confidence, text_analysis\n",
    "                FROM image_texts WHERE filename = ?''', (filename,)).fetchone()\n",
    "\n",
    "            if not result:\n",
    "                ax.text(0.5, 0.5, f\"Not found\\n{filename}\", ha='center', va='center', transform=ax.transAxes)\n",
    "                ax.axis('off')\n",
    "                continue\n",
    "\n",
    "            full_path, text, confidence, analysis = result\n",
    "\n",
    "            try:\n",
    "                img = plt.imread(full_path)\n",
    "                ax.imshow(img)\n",
    "            except:\n",
    "                ax.text(0.5, 0.5, f\"Image load error\\n{filename}\", ha='center', va='center', transform=ax.transAxes)\n",
    "                ax.axis('off')\n",
    "                continue\n",
    "\n",
    "            # Title with confidence\n",
    "            conf_color = \"green\" if confidence > 0.8 else \"orange\" if confidence > 0.6 else \"red\"\n",
    "            ax.set_title(f\"{filename}\\nConfidence: {confidence:.2f}\", fontsize=10, color=conf_color, fontweight='bold')\n",
    "\n",
    "            # Text overlay\n",
    "            text_preview = text[:100] if text else \"No text detected\"\n",
    "            ax.text(0.02, 0.98, f\"Text: {text_preview}...\", transform=ax.transAxes, fontsize=8,\n",
    "                   verticalalignment='top', bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"lightblue\", alpha=0.8))\n",
    "\n",
    "            # Show keywords if available\n",
    "            if analysis:\n",
    "                try:\n",
    "                    data = json.loads(analysis)\n",
    "                    keywords = data.get('searchable_keywords', [])\n",
    "                    if keywords:\n",
    "                        ax.text(0.02, 0.02, f\"Keywords: {', '.join(keywords[:4])}\", transform=ax.transAxes, fontsize=7,\n",
    "                               verticalalignment='bottom', bbox=dict(boxstyle=\"round,pad=0.2\", facecolor=\"lightyellow\", alpha=0.8))\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "            ax.axis('off')\n",
    "\n",
    "        except Exception as e:\n",
    "            ax.text(0.5, 0.5, f\"Error\\n{filename}\\n{str(e)[:30]}\", ha='center', va='center', transform=ax.transAxes)\n",
    "            ax.axis('off')\n",
    "\n",
    "    # Hide unused subplots\n",
    "    for j in range(num, len(axes)):\n",
    "        axes[j].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.suptitle('🔍 Search Results', fontsize=14, y=1.02)\n",
    "    plt.show()\n",
    "\n",
    "# Quick utility functions\n",
    "def quick_setup():\n",
    "    \"\"\"Quick dependency and setup check\"\"\"\n",
    "    print(\"🔍 QUICK SETUP CHECK FOR OCR TEXT SEARCH\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    # Check Python packages\n",
    "    deps = ['paddleocr', 'langchain', 'chromadb', 'sentence_transformers', 'PIL', 'numpy']\n",
    "    for dep in deps:\n",
    "        try:\n",
    "            __import__(dep.replace('-', '_'))\n",
    "            print(f\"✅ {dep}\")\n",
    "        except ImportError:\n",
    "            print(f\"❌ {dep} - Install: pip install {dep}\")\n",
    "\n",
    "    # Check Ollama\n",
    "    try:\n",
    "        import requests\n",
    "        r = requests.get(\"http://localhost:11434/api/tags\", timeout=5)\n",
    "        if r.status_code == 200:\n",
    "            models = [m['name'] for m in r.json().get('models', [])]\n",
    "            print(f\"✅ Ollama: {models}\")\n",
    "            if 'llama3.2:latest' in models:\n",
    "                print(\"✅ Recommended model ready\")\n",
    "            else:\n",
    "                print(\"⚠️ Install recommended model: ollama pull llama3.2:latest\")\n",
    "        else:\n",
    "            print(\"❌ Ollama not responding\")\n",
    "    except:\n",
    "        print(\"❌ Ollama not available - Start: ollama serve\")\n",
    "\n",
    "def quick_search(query: str, image_folder: str = '../../../datasets/images/text_ocr'):\n",
    "    \"\"\"Quick text search in images\"\"\"\n",
    "    print(f\"🔍 Quick Search: '{query}' in {image_folder}\")\n",
    "    print(\"🔒 100% Local Processing\")\n",
    "\n",
    "    try:\n",
    "        config = CONFIG.copy()\n",
    "        config['IMAGE_GALLERY_PATH'] = image_folder\n",
    "        system = GenericOCRSearchSystem(config)\n",
    "\n",
    "        # Check if images are processed\n",
    "        count = system.conn.execute(\"SELECT COUNT(*) FROM image_texts WHERE vector_stored = 1\").fetchone()[0]\n",
    "        if count == 0:\n",
    "            print(\"📁 Processing images first...\")\n",
    "            system.process_images()\n",
    "\n",
    "        # Search\n",
    "        results = system.search_text(query)\n",
    "        matches = results.get('matches', [])\n",
    "\n",
    "        if matches:\n",
    "            print(f\"\\n✅ Found {len(matches)} matches:\")\n",
    "            for i, match in enumerate(matches[:5], 1):\n",
    "                print(f\"{i}. {match['filename']} (Confidence: {match['ocr_confidence']:.2f})\")\n",
    "                print(f\"   Text: {match['extracted_text'][:150]}...\")\n",
    "                print()\n",
    "\n",
    "            # Export results\n",
    "            path = system.export_results(results, query)\n",
    "            print(f\"📋 Results exported to: {path}\")\n",
    "        else:\n",
    "            print(\"❌ No matches found\")\n",
    "\n",
    "        system.close()\n",
    "        return results\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error: {e}\")\n",
    "        return None\n",
    "\n",
    "# Create and display the interface\n",
    "print(\"🔍 Creating Generic OCR Text Search Interface...\")\n",
    "print(\"🔧 Features: Multi-OCR support, semantic search, text extraction\")\n",
    "\n",
    "search_interface = create_search_gui()\n",
    "display(search_interface)\n",
    "\n",
    "print(f\"\\n🔍 GENERIC OCR TEXT SEARCH SYSTEM READY!\")\n",
    "print(\"=\" * 60)\n",
    "print(\"🔒 PRIVACY: 100% local processing, no external API calls\")\n",
    "print(\"🤖 COMPONENTS: Multi-OCR + Ollama/Transformers + ChromaDB + SQLite\")\n",
    "print(\"📝 OCR OPTIONS: PaddleOCR, EasyOCR, Tesseract, TrOCR\")\n",
    "print(\"🚀 SETUP: ollama serve → ollama pull llama3.2:latest\")\n",
    "print(\"💡 QUICK: quick_setup() | quick_search('phone number', './my_images')\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\n🔍 USAGE GUIDE:\")\n",
    "print(\"1. Select OCR engine based on your image types\")\n",
    "print(\"2. Set your image folder path\")\n",
    "print(\"3. Click 'Process Images' to extract all text\")\n",
    "print(\"4. Enter search query and click 'Search Text'\")\n",
    "print(\"5. Export results with matching images\")\n",
    "print(\"=\" * 60)"
   ],
   "id": "c12ae15ce197cee4"
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
