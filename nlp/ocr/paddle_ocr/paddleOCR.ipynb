{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Worked with Python_3.9",
   "id": "1170857b95ac103b"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-10T00:05:45.093901Z",
     "start_time": "2025-07-10T00:05:14.024068Z"
    }
   },
   "source": [
    "# Cell 1: Configuration and Setup\n",
    "import os\n",
    "import shutil\n",
    "import sqlite3\n",
    "import json\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from typing import List, Dict, Any\n",
    "import time\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "# Configuration Settings\n",
    "CONFIG = {\n",
    "    # OCR Model Selection\n",
    "    'OCR_MODEL': 'paddleocr',  # 'paddleocr', 'easyocr', 'tesseract'\n",
    "    'OCR_LANGUAGES': ['en'],   # Languages for OCR\n",
    "\n",
    "    # Search and Embeddings\n",
    "    'EMBEDDING_MODEL': 'sentence-transformers/all-MiniLM-L6-v2',\n",
    "    'DEVICE': 'auto',  # 'auto', 'cpu', 'cuda'\n",
    "\n",
    "    # Paths\n",
    "    'SUSPECTS_GALLERY_PATH': '../../datasets/images/text_ocr',     # Input folder with suspect images\n",
    "    'DATABASE_PATH': 'forensic_analysis_db',       # Database folder\n",
    "    'RESULTS_OUTPUT_PATH': '../../datasets/images/forensic_results',     # Output folder for matched images\n",
    "\n",
    "    # OCR Processing parameters\n",
    "    'OCR_CONFIDENCE_THRESHOLD': 0.6,  # Minimum OCR confidence\n",
    "    'TEXT_MIN_LENGTH': 3,              # Minimum text length to consider\n",
    "    'BATCH_SIZE': 4,                   # Batch size for processing\n",
    "\n",
    "    # Search parameters\n",
    "    'SIMILARITY_THRESHOLD': 0.3,       # Semantic similarity threshold\n",
    "    'MAX_RESULTS_DISPLAY': 10,         # Maximum results to display\n",
    "    'TOP_K_RESULTS': 20,               # Top K results for queries\n",
    "\n",
    "    # Processing settings\n",
    "    'SAVE_OCR_METADATA': True,         # Save detailed OCR metadata\n",
    "    'FIGURE_SIZE': (15, 10),           # Size of result visualization\n",
    "}\n",
    "\n",
    "# Available OCR models\n",
    "AVAILABLE_OCR_MODELS = {\n",
    "    'paddleocr': {\n",
    "        'name': 'PaddleOCR',\n",
    "        'description': 'High accuracy, supports 80+ languages',\n",
    "        'performance': 'Best overall performance',\n",
    "        'install_cmd': 'pip install paddlepaddle paddleocr'\n",
    "    },\n",
    "    'easyocr': {\n",
    "        'name': 'EasyOCR',\n",
    "        'description': 'Simple to use, good accuracy',\n",
    "        'performance': 'Good performance, easy setup',\n",
    "        'install_cmd': 'pip install easyocr'\n",
    "    },\n",
    "    'tesseract': {\n",
    "        'name': 'Tesseract',\n",
    "        'description': 'Classic OCR, widely supported',\n",
    "        'performance': 'Baseline performance',\n",
    "        'install_cmd': 'pip install pytesseract'\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"‚úÖ Configuration loaded successfully\")\n",
    "print(f\"üìÅ Suspects gallery: {CONFIG['SUSPECTS_GALLERY_PATH']}\")\n",
    "print(f\"üìÅ Database path: {CONFIG['DATABASE_PATH']}\")\n",
    "print(f\"üìÅ Results output: {CONFIG['RESULTS_OUTPUT_PATH']}\")\n",
    "print(f\"üîç OCR model: {CONFIG['OCR_MODEL']}\")\n",
    "print(\"üìù Forensic OCR + Search System Ready\")\n",
    "\n",
    "# Cell 2: Install and Import Dependencies\n",
    "def install_dependencies():\n",
    "    \"\"\"Install required packages based on selected OCR model\"\"\"\n",
    "    import subprocess\n",
    "    import sys\n",
    "\n",
    "    try:\n",
    "        # Check core dependencies\n",
    "        import numpy\n",
    "        import PIL\n",
    "        import cv2\n",
    "        print(\"‚úÖ Core dependencies available\")\n",
    "    except ImportError as e:\n",
    "        print(f\"‚ö†Ô∏è Installing core dependencies...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"numpy\", \"Pillow\", \"opencv-python\"])\n",
    "\n",
    "    # Install OCR model\n",
    "    ocr_model = CONFIG['OCR_MODEL']\n",
    "    try:\n",
    "        if ocr_model == 'paddleocr':\n",
    "            import paddleocr\n",
    "            print(\"‚úÖ PaddleOCR already available\")\n",
    "        elif ocr_model == 'easyocr':\n",
    "            import easyocr\n",
    "            print(\"‚úÖ EasyOCR already available\")\n",
    "        elif ocr_model == 'tesseract':\n",
    "            import pytesseract\n",
    "            print(\"‚úÖ Tesseract already available\")\n",
    "    except ImportError:\n",
    "        print(f\"‚ö†Ô∏è Installing {ocr_model}...\")\n",
    "        install_cmd = AVAILABLE_OCR_MODELS[ocr_model]['install_cmd']\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\"] + install_cmd.split()[2:])\n",
    "\n",
    "    # Install search dependencies\n",
    "    try:\n",
    "        import chromadb\n",
    "        import sentence_transformers\n",
    "        print(\"‚úÖ Search dependencies available\")\n",
    "    except ImportError:\n",
    "        print(\"‚ö†Ô∏è Installing search dependencies...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"chromadb\", \"sentence-transformers\"])\n",
    "\n",
    "# Run installation\n",
    "install_dependencies()\n",
    "\n",
    "# Import required libraries\n",
    "try:\n",
    "    import chromadb\n",
    "    from sentence_transformers import SentenceTransformer\n",
    "\n",
    "    # Import OCR model\n",
    "    if CONFIG['OCR_MODEL'] == 'paddleocr':\n",
    "        from paddleocr import PaddleOCR\n",
    "    elif CONFIG['OCR_MODEL'] == 'easyocr':\n",
    "        import easyocr\n",
    "    elif CONFIG['OCR_MODEL'] == 'tesseract':\n",
    "        import pytesseract\n",
    "\n",
    "    print(\"‚úÖ All dependencies imported successfully\")\n",
    "\n",
    "    # Check device compatibility\n",
    "    import torch\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"üöÄ CUDA available: {torch.cuda.get_device_name(0)}\")\n",
    "        default_device = \"cuda\"\n",
    "    else:\n",
    "        print(\"üñ•Ô∏è Using CPU mode\")\n",
    "        default_device = \"cpu\"\n",
    "\n",
    "    if CONFIG['DEVICE'] == 'auto':\n",
    "        CONFIG['DEVICE'] = default_device\n",
    "        print(f\"üìç Auto-detected device: {CONFIG['DEVICE']}\")\n",
    "\n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå Import error: {e}\")\n",
    "    print(\"üîß Please run the installation cell and restart kernel\")\n",
    "\n",
    "# Cell 3: Initialize OCR and Search Models\n",
    "class ForensicOCRSearchSystem:\n",
    "    \"\"\"Comprehensive forensic OCR and search system\"\"\"\n",
    "\n",
    "    def __init__(self, config=None):\n",
    "        \"\"\"Initialize the forensic analysis system\"\"\"\n",
    "        self.config = config or CONFIG\n",
    "        self.setup_directories()\n",
    "        self.init_ocr_model()\n",
    "        self.init_search_components()\n",
    "        self.init_database()\n",
    "\n",
    "    def setup_directories(self):\n",
    "        \"\"\"Create necessary directories\"\"\"\n",
    "        for path_key in ['SUSPECTS_GALLERY_PATH', 'DATABASE_PATH', 'RESULTS_OUTPUT_PATH']:\n",
    "            path = self.config[path_key]\n",
    "            os.makedirs(path, exist_ok=True)\n",
    "            print(f\"üìÅ Directory ready: {path}\")\n",
    "\n",
    "    def init_ocr_model(self):\n",
    "        \"\"\"Initialize OCR model based on configuration\"\"\"\n",
    "        ocr_model = self.config['OCR_MODEL']\n",
    "        languages = self.config['OCR_LANGUAGES']\n",
    "\n",
    "        print(f\"üì• Loading OCR model: {ocr_model}\")\n",
    "\n",
    "        try:\n",
    "            if ocr_model == 'paddleocr':\n",
    "                self.ocr = PaddleOCR(\n",
    "                    use_textline_orientation=True,\n",
    "                    lang=languages[0] if languages else 'en',\n",
    "                    # use_gpu=True if self.config['DEVICE'] == 'cuda' else False\n",
    "                )\n",
    "                print(\"‚úÖ PaddleOCR initialized\")\n",
    "\n",
    "            elif ocr_model == 'easyocr':\n",
    "                self.ocr = easyocr.Reader(\n",
    "                    languages,\n",
    "                    gpu=True if self.config['DEVICE'] == 'cuda' else False\n",
    "                )\n",
    "                print(\"‚úÖ EasyOCR initialized\")\n",
    "\n",
    "            elif ocr_model == 'tesseract':\n",
    "                # Tesseract doesn't need initialization, just check availability\n",
    "                try:\n",
    "                    import pytesseract\n",
    "                    self.ocr = pytesseract\n",
    "                    print(\"‚úÖ Tesseract initialized\")\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ùå Tesseract error: {e}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå OCR initialization error: {e}\")\n",
    "            self.ocr = None\n",
    "\n",
    "    def init_search_components(self):\n",
    "        \"\"\"Initialize search and embedding components\"\"\"\n",
    "        try:\n",
    "            print(f\"üì• Loading embedding model: {self.config['EMBEDDING_MODEL']}\")\n",
    "            self.embedding_model = SentenceTransformer(self.config['EMBEDDING_MODEL'])\n",
    "\n",
    "            print(\"üì• Initializing vector database...\")\n",
    "            self.chroma_client = chromadb.PersistentClient(path=self.config['DATABASE_PATH'])\n",
    "            self.collection = self.chroma_client.get_or_create_collection(\n",
    "                name=\"forensic_text_search\",\n",
    "                metadata={\"hnsw:space\": \"cosine\"}\n",
    "            )\n",
    "            print(\"‚úÖ Search components initialized\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Search initialization error: {e}\")\n",
    "            self.embedding_model = None\n",
    "            self.chroma_client = None\n",
    "            self.collection = None\n",
    "\n",
    "    def init_database(self):\n",
    "        \"\"\"Initialize SQLite database for metadata\"\"\"\n",
    "        try:\n",
    "            db_path = os.path.join(self.config['DATABASE_PATH'], 'forensic_metadata.db')\n",
    "            self.conn = sqlite3.connect(db_path)\n",
    "\n",
    "            # Create tables\n",
    "            self.conn.execute('''\n",
    "                CREATE TABLE IF NOT EXISTS forensic_images (\n",
    "                    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "                    filename TEXT UNIQUE NOT NULL,\n",
    "                    full_path TEXT NOT NULL,\n",
    "                    extracted_text TEXT,\n",
    "                    ocr_confidence REAL,\n",
    "                    text_blocks_count INTEGER,\n",
    "                    processed_date TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
    "                    file_size INTEGER,\n",
    "                    image_dimensions TEXT,\n",
    "                    ocr_metadata TEXT\n",
    "                )\n",
    "            ''')\n",
    "\n",
    "            self.conn.execute('''\n",
    "                CREATE TABLE IF NOT EXISTS search_queries (\n",
    "                    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "                    query_text TEXT NOT NULL,\n",
    "                    query_date TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
    "                    results_count INTEGER,\n",
    "                    processing_time REAL\n",
    "                )\n",
    "            ''')\n",
    "\n",
    "            self.conn.commit()\n",
    "            print(\"‚úÖ Database initialized\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Database initialization error: {e}\")\n",
    "            self.conn = None\n",
    "\n",
    "    def extract_text_from_image(self, image_path: str) -> Dict[str, Any]:\n",
    "        \"\"\"Extract text from image using configured OCR model\"\"\"\n",
    "        try:\n",
    "            image_path = str(image_path)\n",
    "            filename = os.path.basename(image_path)\n",
    "\n",
    "            # Load image\n",
    "            image = Image.open(image_path).convert(\"RGB\")\n",
    "            image_array = np.array(image)\n",
    "\n",
    "            result = {\n",
    "                'filename': filename,\n",
    "                'full_path': image_path,\n",
    "                'extracted_text': '',\n",
    "                'ocr_confidence': 0.0,\n",
    "                'text_blocks': [],\n",
    "                'text_blocks_count': 0,\n",
    "                'error': None\n",
    "            }\n",
    "\n",
    "            # Process with selected OCR model\n",
    "            if self.config['OCR_MODEL'] == 'paddleocr' and self.ocr:\n",
    "                ocr_result = self.ocr.ocr(image_array, cls=True)\n",
    "\n",
    "                if ocr_result and ocr_result[0]:\n",
    "                    text_blocks = []\n",
    "                    all_text = []\n",
    "                    confidences = []\n",
    "\n",
    "                    for line in ocr_result:\n",
    "                        for detection in line:\n",
    "                            bbox, (text, confidence) = detection\n",
    "\n",
    "                            if confidence >= self.config['OCR_CONFIDENCE_THRESHOLD']:\n",
    "                                text_blocks.append({\n",
    "                                    'text': text,\n",
    "                                    'confidence': confidence,\n",
    "                                    'bbox': bbox\n",
    "                                })\n",
    "                                all_text.append(text)\n",
    "                                confidences.append(confidence)\n",
    "\n",
    "                    result.update({\n",
    "                        'extracted_text': ' '.join(all_text),\n",
    "                        'ocr_confidence': np.mean(confidences) if confidences else 0.0,\n",
    "                        'text_blocks': text_blocks,\n",
    "                        'text_blocks_count': len(text_blocks)\n",
    "                    })\n",
    "\n",
    "            elif self.config['OCR_MODEL'] == 'easyocr' and self.ocr:\n",
    "                ocr_result = self.ocr.readtext(image_array)\n",
    "\n",
    "                text_blocks = []\n",
    "                all_text = []\n",
    "                confidences = []\n",
    "\n",
    "                for detection in ocr_result:\n",
    "                    bbox, text, confidence = detection\n",
    "\n",
    "                    if confidence >= self.config['OCR_CONFIDENCE_THRESHOLD']:\n",
    "                        text_blocks.append({\n",
    "                            'text': text,\n",
    "                            'confidence': confidence,\n",
    "                            'bbox': bbox\n",
    "                        })\n",
    "                        all_text.append(text)\n",
    "                        confidences.append(confidence)\n",
    "\n",
    "                result.update({\n",
    "                    'extracted_text': ' '.join(all_text),\n",
    "                    'ocr_confidence': np.mean(confidences) if confidences else 0.0,\n",
    "                    'text_blocks': text_blocks,\n",
    "                    'text_blocks_count': len(text_blocks)\n",
    "                })\n",
    "\n",
    "            elif self.config['OCR_MODEL'] == 'tesseract' and self.ocr:\n",
    "                # Simple Tesseract extraction\n",
    "                text = self.ocr.image_to_string(image, config='--psm 6')\n",
    "                confidence = 0.8  # Tesseract doesn't provide confidence easily\n",
    "\n",
    "                if text.strip():\n",
    "                    result.update({\n",
    "                        'extracted_text': text.strip(),\n",
    "                        'ocr_confidence': confidence,\n",
    "                        'text_blocks': [{'text': text.strip(), 'confidence': confidence}],\n",
    "                        'text_blocks_count': 1\n",
    "                    })\n",
    "\n",
    "            return result\n",
    "\n",
    "        except Exception as e:\n",
    "            return {\n",
    "                'filename': os.path.basename(image_path),\n",
    "                'full_path': image_path,\n",
    "                'extracted_text': '',\n",
    "                'ocr_confidence': 0.0,\n",
    "                'text_blocks': [],\n",
    "                'text_blocks_count': 0,\n",
    "                'error': str(e)\n",
    "            }\n",
    "\n",
    "    def process_image_gallery(self, image_extensions=['.jpg', '.jpeg', '.png', '.bmp', '.tiff']):\n",
    "        \"\"\"Process all images in the suspect gallery\"\"\"\n",
    "        start_time = time.time()\n",
    "        gallery_path = Path(self.config['SUSPECTS_GALLERY_PATH'])\n",
    "\n",
    "        print(f\"üîç Processing images from: {gallery_path}\")\n",
    "        print(f\"üîç OCR Model: {self.config['OCR_MODEL']}\")\n",
    "        print(f\"‚è∞ Start time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "\n",
    "        if not gallery_path.exists():\n",
    "            print(f\"‚ùå Gallery path {gallery_path} does not exist!\")\n",
    "            return\n",
    "\n",
    "        # Get all image files\n",
    "        image_files = []\n",
    "        for ext in image_extensions:\n",
    "            image_files.extend(gallery_path.glob(f\"**/*{ext}\"))\n",
    "            image_files.extend(gallery_path.glob(f\"**/*{ext.upper()}\"))\n",
    "\n",
    "        total_files = len(image_files)\n",
    "        print(f\"üì∏ Found {total_files} images to process\")\n",
    "\n",
    "        if total_files == 0:\n",
    "            print(\"‚ö†Ô∏è No images found!\")\n",
    "            return\n",
    "\n",
    "        processed_count = 0\n",
    "        text_found_count = 0\n",
    "\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"üîç PROCESSING IMAGES\")\n",
    "        print(\"=\"*60)\n",
    "\n",
    "        for i, image_path in enumerate(image_files, 1):\n",
    "            filename = image_path.name\n",
    "\n",
    "            # Progress indicator\n",
    "            progress = (i / total_files) * 100\n",
    "            print(f\"[{i:3d}/{total_files}] ({progress:5.1f}%) Processing: {filename[:40]}...\", end='')\n",
    "\n",
    "            # Check if already processed\n",
    "            cursor = self.conn.execute(\"SELECT filename FROM forensic_images WHERE filename = ?\", (filename,))\n",
    "            if cursor.fetchone():\n",
    "                print(\" ‚è≠Ô∏è SKIP (already processed)\")\n",
    "                continue\n",
    "\n",
    "            # Extract text\n",
    "            ocr_result = self.extract_text_from_image(image_path)\n",
    "\n",
    "            if ocr_result.get('error'):\n",
    "                print(f\" ‚ùå ERROR: {ocr_result['error'][:30]}\")\n",
    "                continue\n",
    "\n",
    "            # Store in database\n",
    "            file_size = image_path.stat().st_size if image_path.exists() else 0\n",
    "            image_dims = f\"{ocr_result.get('width', 0)}x{ocr_result.get('height', 0)}\"\n",
    "\n",
    "            self.conn.execute('''\n",
    "                INSERT OR REPLACE INTO forensic_images\n",
    "                (filename, full_path, extracted_text, ocr_confidence, text_blocks_count,\n",
    "                 file_size, image_dimensions, ocr_metadata)\n",
    "                VALUES (?, ?, ?, ?, ?, ?, ?, ?)\n",
    "            ''', (\n",
    "                filename,\n",
    "                str(image_path),\n",
    "                ocr_result['extracted_text'],\n",
    "                ocr_result['ocr_confidence'],\n",
    "                ocr_result['text_blocks_count'],\n",
    "                file_size,\n",
    "                image_dims,\n",
    "                json.dumps(ocr_result['text_blocks']) if self.config['SAVE_OCR_METADATA'] else None\n",
    "            ))\n",
    "\n",
    "            # Add to vector database if text found\n",
    "            if ocr_result['extracted_text'].strip():\n",
    "                try:\n",
    "                    doc_id = f\"img_{processed_count}_{filename}\"\n",
    "                    self.collection.add(\n",
    "                        documents=[ocr_result['extracted_text']],\n",
    "                        metadatas=[{\n",
    "                            'filename': filename,\n",
    "                            'full_path': str(image_path),\n",
    "                            'ocr_confidence': ocr_result['ocr_confidence'],\n",
    "                            'text_blocks_count': ocr_result['text_blocks_count']\n",
    "                        }],\n",
    "                        ids=[doc_id]\n",
    "                    )\n",
    "                    text_found_count += 1\n",
    "                    print(f\" ‚úÖ TEXT ({ocr_result['text_blocks_count']} blocks, conf: {ocr_result['ocr_confidence']:.2f})\")\n",
    "                except Exception as e:\n",
    "                    print(f\" ‚ö†Ô∏è DB ERROR: {str(e)[:20]}\")\n",
    "            else:\n",
    "                print(\" ‚ö™ NO TEXT\")\n",
    "\n",
    "            processed_count += 1\n",
    "\n",
    "            # Commit every 10 images\n",
    "            if i % 10 == 0:\n",
    "                self.conn.commit()\n",
    "\n",
    "        # Final commit\n",
    "        self.conn.commit()\n",
    "\n",
    "        # Calculate timing\n",
    "        end_time = time.time()\n",
    "        duration = end_time - start_time\n",
    "\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"üìä PROCESSING SUMMARY\")\n",
    "        print(\"=\"*60)\n",
    "        print(f\"üì∏ Total images: {total_files}\")\n",
    "        print(f\"‚úÖ Successfully processed: {processed_count}\")\n",
    "        print(f\"üìù Images with text: {text_found_count}\")\n",
    "        print(f\"‚ö™ Images without text: {processed_count - text_found_count}\")\n",
    "        print(f\"‚è±Ô∏è Total time: {duration:.1f}s ({duration/total_files:.2f}s per image)\")\n",
    "        print(f\"üìä Text detection rate: {(text_found_count/processed_count*100):.1f}%\" if processed_count > 0 else \"\")\n",
    "        print(\"=\"*60)\n",
    "\n",
    "    def search_by_text_query(self, query: str, max_results: int = None) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Search images by semantic text similarity\"\"\"\n",
    "        if max_results is None:\n",
    "            max_results = self.config['TOP_K_RESULTS']\n",
    "\n",
    "        if not self.collection or not self.embedding_model:\n",
    "            print(\"‚ùå Search components not available\")\n",
    "            return []\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        try:\n",
    "            # Perform semantic search\n",
    "            results = self.collection.query(\n",
    "                query_texts=[query],\n",
    "                n_results=max_results\n",
    "            )\n",
    "\n",
    "            # Format results\n",
    "            matches = []\n",
    "            if results['documents'] and results['documents'][0]:\n",
    "                for i, doc in enumerate(results['documents'][0]):\n",
    "                    metadata = results['metadatas'][0][i]\n",
    "                    distance = results['distances'][0][i] if 'distances' in results else 0\n",
    "                    similarity = 1 - distance\n",
    "\n",
    "                    # Filter by similarity threshold\n",
    "                    if similarity >= self.config['SIMILARITY_THRESHOLD']:\n",
    "                        matches.append({\n",
    "                            'filename': metadata['filename'],\n",
    "                            'full_path': metadata['full_path'],\n",
    "                            'extracted_text': doc,\n",
    "                            'similarity_score': similarity,\n",
    "                            'ocr_confidence': metadata.get('ocr_confidence', 0),\n",
    "                            'text_blocks_count': metadata.get('text_blocks_count', 0),\n",
    "                            'text_preview': doc[:200] + \"...\" if len(doc) > 200 else doc\n",
    "                        })\n",
    "\n",
    "            # Log query\n",
    "            processing_time = time.time() - start_time\n",
    "            self.conn.execute('''\n",
    "                INSERT INTO search_queries (query_text, results_count, processing_time)\n",
    "                VALUES (?, ?, ?)\n",
    "            ''', (query, len(matches), processing_time))\n",
    "            self.conn.commit()\n",
    "\n",
    "            return matches\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Search error: {e}\")\n",
    "            return []\n",
    "\n",
    "    def search_by_keywords(self, keywords: List[str], exact_match: bool = False) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Search images by specific keywords using SQL\"\"\"\n",
    "        matches = []\n",
    "\n",
    "        try:\n",
    "            for keyword in keywords:\n",
    "                if exact_match:\n",
    "                    sql_query = \"\"\"\n",
    "                        SELECT filename, full_path, extracted_text, ocr_confidence, text_blocks_count\n",
    "                        FROM forensic_images\n",
    "                        WHERE extracted_text LIKE ? AND extracted_text != ''\n",
    "                    \"\"\"\n",
    "                    params = (f\"%{keyword}%\",)\n",
    "                else:\n",
    "                    sql_query = \"\"\"\n",
    "                        SELECT filename, full_path, extracted_text, ocr_confidence, text_blocks_count\n",
    "                        FROM forensic_images\n",
    "                        WHERE LOWER(extracted_text) LIKE LOWER(?) AND extracted_text != ''\n",
    "                    \"\"\"\n",
    "                    params = (f\"%{keyword}%\",)\n",
    "\n",
    "                cursor = self.conn.execute(sql_query, params)\n",
    "                results = cursor.fetchall()\n",
    "\n",
    "                for row in results:\n",
    "                    match = {\n",
    "                        'filename': row[0],\n",
    "                        'full_path': row[1],\n",
    "                        'extracted_text': row[2],\n",
    "                        'ocr_confidence': row[3],\n",
    "                        'text_blocks_count': row[4],\n",
    "                        'matched_keyword': keyword,\n",
    "                        'search_type': 'keyword',\n",
    "                        'text_preview': row[2][:200] + \"...\" if len(row[2]) > 200 else row[2]\n",
    "                    }\n",
    "\n",
    "                    # Avoid duplicates\n",
    "                    if not any(m['filename'] == match['filename'] for m in matches):\n",
    "                        matches.append(match)\n",
    "\n",
    "            return matches\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Keyword search error: {e}\")\n",
    "            return []\n",
    "\n",
    "    def forensic_query_analysis(self, query: str, include_keywords: bool = True) -> Dict[str, Any]:\n",
    "        \"\"\"Comprehensive forensic analysis for a query\"\"\"\n",
    "        print(f\"üîç Forensic Analysis: '{query}'\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Semantic search\n",
    "        print(\"üìù Performing semantic search...\")\n",
    "        semantic_results = self.search_by_text_query(query)\n",
    "\n",
    "        # Keyword search\n",
    "        keyword_results = []\n",
    "        if include_keywords:\n",
    "            print(\"üîç Performing keyword search...\")\n",
    "            query_words = query.lower().split()\n",
    "            keyword_results = self.search_by_keywords(query_words)\n",
    "\n",
    "        # Combine and deduplicate results\n",
    "        all_results = semantic_results.copy()\n",
    "        for kw_result in keyword_results:\n",
    "            if not any(r['filename'] == kw_result['filename'] for r in all_results):\n",
    "                kw_result['search_type'] = 'keyword'\n",
    "                all_results.append(kw_result)\n",
    "\n",
    "        # Sort by relevance (similarity score or confidence)\n",
    "        all_results.sort(\n",
    "            key=lambda x: x.get('similarity_score', x.get('ocr_confidence', 0)),\n",
    "            reverse=True\n",
    "        )\n",
    "\n",
    "        processing_time = time.time() - start_time\n",
    "\n",
    "        analysis = {\n",
    "            'query': query,\n",
    "            'semantic_matches': len(semantic_results),\n",
    "            'keyword_matches': len(keyword_results),\n",
    "            'total_unique_matches': len(all_results),\n",
    "            'processing_time': processing_time,\n",
    "            'results': all_results[:self.config['MAX_RESULTS_DISPLAY']],\n",
    "            'timestamp': datetime.now().isoformat()\n",
    "        }\n",
    "\n",
    "        print(f\"‚úÖ Analysis complete:\")\n",
    "        print(f\"   üìä Semantic matches: {len(semantic_results)}\")\n",
    "        print(f\"   üîç Keyword matches: {len(keyword_results)}\")\n",
    "        print(f\"   üìù Total unique: {len(all_results)}\")\n",
    "        print(f\"   ‚è±Ô∏è Time: {processing_time:.2f}s\")\n",
    "\n",
    "        return analysis\n",
    "\n",
    "    def get_statistics(self) -> Dict[str, Any]:\n",
    "        \"\"\"Get comprehensive database statistics\"\"\"\n",
    "        try:\n",
    "            stats = {}\n",
    "\n",
    "            # Image statistics\n",
    "            cursor = self.conn.execute(\"SELECT COUNT(*) FROM forensic_images\")\n",
    "            stats['total_images'] = cursor.fetchone()[0]\n",
    "\n",
    "            cursor = self.conn.execute(\"SELECT COUNT(*) FROM forensic_images WHERE extracted_text != ''\")\n",
    "            stats['images_with_text'] = cursor.fetchone()[0]\n",
    "\n",
    "            cursor = self.conn.execute(\"SELECT AVG(ocr_confidence) FROM forensic_images WHERE extracted_text != ''\")\n",
    "            result = cursor.fetchone()[0]\n",
    "            stats['avg_ocr_confidence'] = round(result, 3) if result else 0\n",
    "\n",
    "            cursor = self.conn.execute(\"SELECT SUM(text_blocks_count) FROM forensic_images\")\n",
    "            result = cursor.fetchone()[0]\n",
    "            stats['total_text_blocks'] = result if result else 0\n",
    "\n",
    "            # Query statistics\n",
    "            cursor = self.conn.execute(\"SELECT COUNT(*) FROM search_queries\")\n",
    "            stats['total_queries'] = cursor.fetchone()[0]\n",
    "\n",
    "            cursor = self.conn.execute(\"SELECT AVG(processing_time) FROM search_queries\")\n",
    "            result = cursor.fetchone()[0]\n",
    "            stats['avg_query_time'] = round(result, 3) if result else 0\n",
    "\n",
    "            # File size statistics\n",
    "            cursor = self.conn.execute(\"SELECT SUM(file_size), AVG(file_size) FROM forensic_images\")\n",
    "            total_size, avg_size = cursor.fetchone()\n",
    "            stats['total_file_size_mb'] = round(total_size / (1024*1024), 2) if total_size else 0\n",
    "            stats['avg_file_size_kb'] = round(avg_size / 1024, 2) if avg_size else 0\n",
    "\n",
    "            return stats\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Statistics error: {e}\")\n",
    "            return {}\n",
    "\n",
    "    def export_results(self, results: List[Dict], output_folder: str, copy_images: bool = True) -> str:\n",
    "        \"\"\"Export search results to folder with metadata\"\"\"\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        output_path = Path(output_folder) / f\"forensic_search_{timestamp}\"\n",
    "        output_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        copied_files = []\n",
    "        metadata = {\n",
    "            'export_timestamp': timestamp,\n",
    "            'total_results': len(results),\n",
    "            'export_path': str(output_path),\n",
    "            'results': []\n",
    "        }\n",
    "\n",
    "        for i, result in enumerate(results, 1):\n",
    "            try:\n",
    "                result_meta = {\n",
    "                    'index': i,\n",
    "                    'filename': result['filename'],\n",
    "                    'original_path': result['full_path'],\n",
    "                    'extracted_text': result['extracted_text'],\n",
    "                    'text_preview': result.get('text_preview', ''),\n",
    "                    'ocr_confidence': result.get('ocr_confidence', 0),\n",
    "                    'similarity_score': result.get('similarity_score', 0),\n",
    "                    'search_type': result.get('search_type', 'semantic')\n",
    "                }\n",
    "\n",
    "                if copy_images:\n",
    "                    # Copy image file\n",
    "                    source_path = Path(result['full_path'])\n",
    "                    if source_path.exists():\n",
    "                        # Create descriptive filename\n",
    "                        conf_or_sim = result.get('similarity_score', result.get('ocr_confidence', 0))\n",
    "                        new_filename = f\"{i:03d}_{source_path.stem}_score{conf_or_sim:.2f}{source_path.suffix}\"\n",
    "                        dest_path = output_path / new_filename\n",
    "\n",
    "                        shutil.copy2(source_path, dest_path)\n",
    "                        copied_files.append(str(dest_path))\n",
    "                        result_meta['exported_filename'] = new_filename\n",
    "                        result_meta['exported_path'] = str(dest_path)\n",
    "\n",
    "                metadata['results'].append(result_meta)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Error exporting {result['filename']}: {e}\")\n",
    "\n",
    "        # Save metadata JSON\n",
    "        metadata_file = output_path / \"search_metadata.json\"\n",
    "        with open(metadata_file, 'w', encoding='utf-8') as f:\n",
    "            json.dump(metadata, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "        # Save text summary\n",
    "        summary_file = output_path / \"search_summary.txt\"\n",
    "        with open(summary_file, 'w', encoding='utf-8') as f:\n",
    "            f.write(f\"Forensic Search Results\\n\")\n",
    "            f.write(f\"=\"*50 + \"\\n\")\n",
    "            f.write(f\"Export Date: {timestamp}\\n\")\n",
    "            f.write(f\"Total Results: {len(results)}\\n\")\n",
    "            f.write(f\"Files Copied: {len(copied_files)}\\n\\n\")\n",
    "\n",
    "            for i, result in enumerate(results, 1):\n",
    "                f.write(f\"{i}. {result['filename']}\\n\")\n",
    "                f.write(f\"   Text: {result.get('text_preview', '')}\\n\")\n",
    "                f.write(f\"   Score: {result.get('similarity_score', result.get('ocr_confidence', 0)):.3f}\\n\\n\")\n",
    "\n",
    "        print(f\"üìÅ Exported {len(results)} results to: {output_path}\")\n",
    "        print(f\"üìã Images copied: {len(copied_files)}\")\n",
    "        print(f\"üìÑ Metadata saved: {metadata_file}\")\n",
    "\n",
    "        return str(output_path)\n",
    "\n",
    "    def close(self):\n",
    "        \"\"\"Close database connections and cleanup\"\"\"\n",
    "        if hasattr(self, 'conn') and self.conn:\n",
    "            self.conn.close()\n",
    "            print(\"üìä Database connections closed\")\n",
    "\n",
    "# Cell 4: Batch Processing and Forensic Analysis Functions\n",
    "def run_comprehensive_forensic_analysis(system, custom_queries=None):\n",
    "    \"\"\"Run comprehensive forensic analysis with predefined and custom queries\"\"\"\n",
    "\n",
    "    # Default forensic text queries\n",
    "    default_queries = [\n",
    "        \"bank account number\",\n",
    "        \"credit card\",\n",
    "        \"social security number\",\n",
    "        \"phone number\",\n",
    "        \"email address\",\n",
    "        \"password\",\n",
    "        \"address location\",\n",
    "        \"threat violence\",\n",
    "        \"weapon gun knife\",\n",
    "        \"drugs illegal substances\",\n",
    "        \"money cash payment\",\n",
    "        \"meeting appointment\",\n",
    "        \"suspicious activity\",\n",
    "        \"personal identification\",\n",
    "        \"financial transaction\"\n",
    "    ]\n",
    "\n",
    "    # Combine with custom queries\n",
    "    queries = default_queries + (custom_queries or [])\n",
    "\n",
    "    print(f\"üöÄ Starting comprehensive forensic analysis\")\n",
    "    print(f\"üìã Total queries: {len(queries)} ({len(default_queries)} default + {len(custom_queries or [])} custom)\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    all_results = {}\n",
    "    high_priority_findings = []\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    for i, query in enumerate(queries, 1):\n",
    "        print(f\"\\n[{i:2d}/{len(queries)}] Analyzing: '{query}'\")\n",
    "\n",
    "        # Perform analysis\n",
    "        analysis = system.forensic_query_analysis(query, include_keywords=True)\n",
    "        all_results[query] = analysis\n",
    "\n",
    "        # Identify high-priority findings\n",
    "        for result in analysis['results'][:3]:  # Top 3 per query\n",
    "            score = result.get('similarity_score', result.get('ocr_confidence', 0))\n",
    "            if score > 0.5:  # High confidence threshold\n",
    "                high_priority_findings.append({\n",
    "                    'query': query,\n",
    "                    'filename': result['filename'],\n",
    "                    'score': score,\n",
    "                    'text_preview': result['text_preview'],\n",
    "                    'search_type': result.get('search_type', 'semantic')\n",
    "                })\n",
    "\n",
    "        # Brief status\n",
    "        matches = analysis['total_unique_matches']\n",
    "        status = \"üî¥\" if matches > 5 else \"üü°\" if matches > 0 else \"‚ö™\"\n",
    "        print(f\"   {status} {matches} matches found\")\n",
    "\n",
    "    total_time = time.time() - start_time\n",
    "\n",
    "    # Generate summary report\n",
    "    print(f\"\\n\" + \"=\"*60)\n",
    "    print(\"üìä COMPREHENSIVE ANALYSIS SUMMARY\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    total_matches = sum(r['total_unique_matches'] for r in all_results.values())\n",
    "    queries_with_results = sum(1 for r in all_results.values() if r['total_unique_matches'] > 0)\n",
    "\n",
    "    print(f\"üéØ Queries processed: {len(queries)}\")\n",
    "    print(f\"‚úÖ Queries with results: {queries_with_results}\")\n",
    "    print(f\"üìä Total matches found: {total_matches}\")\n",
    "    print(f\"üî¥ High priority findings: {len(high_priority_findings)}\")\n",
    "    print(f\"‚è±Ô∏è Total analysis time: {total_time:.1f}s\")\n",
    "    print(f\"üìà Average per query: {total_time/len(queries):.1f}s\")\n",
    "\n",
    "    # Show top findings by query\n",
    "    print(f\"\\nüìã TOP FINDINGS BY QUERY:\")\n",
    "    for query, analysis in all_results.items():\n",
    "        matches = analysis['total_unique_matches']\n",
    "        if matches > 0:\n",
    "            status = \"üî¥\" if matches > 5 else \"üü°\"\n",
    "            print(f\"{status} '{query}': {matches} matches\")\n",
    "\n",
    "    # Show high priority findings\n",
    "    if high_priority_findings:\n",
    "        print(f\"\\nüö® HIGH PRIORITY EVIDENCE:\")\n",
    "        high_priority_findings.sort(key=lambda x: x['score'], reverse=True)\n",
    "        for finding in high_priority_findings[:10]:  # Top 10\n",
    "            print(f\"üî¥ {finding['filename']} (Query: '{finding['query']}')\")\n",
    "            print(f\"   Score: {finding['score']:.3f} | Type: {finding['search_type']}\")\n",
    "            print(f\"   Text: {finding['text_preview'][:80]}...\")\n",
    "            print()\n",
    "\n",
    "    return {\n",
    "        'all_results': all_results,\n",
    "        'high_priority_findings': high_priority_findings,\n",
    "        'summary': {\n",
    "            'total_queries': len(queries),\n",
    "            'queries_with_results': queries_with_results,\n",
    "            'total_matches': total_matches,\n",
    "            'high_priority_count': len(high_priority_findings),\n",
    "            'processing_time': total_time\n",
    "        }\n",
    "    }\n",
    "\n",
    "def batch_export_all_results(system, analysis_results, output_base_path):\n",
    "    \"\"\"Export all analysis results in organized folders\"\"\"\n",
    "\n",
    "    print(\"üìÅ Exporting all forensic analysis results...\")\n",
    "\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    base_export_path = Path(output_base_path) / f\"forensic_analysis_{timestamp}\"\n",
    "    base_export_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Export high priority findings\n",
    "    high_priority = analysis_results['high_priority_findings']\n",
    "    if high_priority:\n",
    "        print(f\"üî¥ Exporting {len(high_priority)} high priority findings...\")\n",
    "        hp_results = []\n",
    "        for finding in high_priority:\n",
    "            # Convert finding to result format\n",
    "            result = {\n",
    "                'filename': finding['filename'],\n",
    "                'full_path': '',  # Will be filled from database\n",
    "                'extracted_text': '',\n",
    "                'text_preview': finding['text_preview'],\n",
    "                'similarity_score': finding['score'],\n",
    "                'search_type': finding['search_type']\n",
    "            }\n",
    "\n",
    "            # Get full details from database\n",
    "            cursor = system.conn.execute(\n",
    "                \"SELECT full_path, extracted_text FROM forensic_images WHERE filename = ?\",\n",
    "                (finding['filename'],)\n",
    "            )\n",
    "            row = cursor.fetchone()\n",
    "            if row:\n",
    "                result['full_path'] = row[0]\n",
    "                result['extracted_text'] = row[1]\n",
    "                hp_results.append(result)\n",
    "\n",
    "        if hp_results:\n",
    "            hp_folder = system.export_results(hp_results, base_export_path / \"high_priority\", copy_images=True)\n",
    "\n",
    "    # Export results by query category\n",
    "    categories = {\n",
    "        'financial': ['bank account', 'credit card', 'money', 'payment', 'transaction'],\n",
    "        'personal_info': ['phone number', 'email', 'address', 'social security', 'identification'],\n",
    "        'security': ['password', 'threat', 'weapon', 'suspicious'],\n",
    "        'illegal': ['drugs', 'illegal']\n",
    "    }\n",
    "\n",
    "    for category, keywords in categories.items():\n",
    "        category_results = []\n",
    "        for query, analysis in analysis_results['all_results'].items():\n",
    "            if any(keyword in query.lower() for keyword in keywords):\n",
    "                category_results.extend(analysis['results'])\n",
    "\n",
    "        if category_results:\n",
    "            # Remove duplicates\n",
    "            unique_results = []\n",
    "            seen_files = set()\n",
    "            for result in category_results:\n",
    "                if result['filename'] not in seen_files:\n",
    "                    unique_results.append(result)\n",
    "                    seen_files.add(result['filename'])\n",
    "\n",
    "            if unique_results:\n",
    "                print(f\"üìÇ Exporting {len(unique_results)} {category} findings...\")\n",
    "                system.export_results(unique_results, base_export_path / category, copy_images=True)\n",
    "\n",
    "    # Create master summary\n",
    "    summary_file = base_export_path / \"analysis_summary.json\"\n",
    "    with open(summary_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump({\n",
    "            'export_timestamp': timestamp,\n",
    "            'summary': analysis_results['summary'],\n",
    "            'high_priority_count': len(high_priority),\n",
    "            'categories_exported': list(categories.keys()),\n",
    "            'export_path': str(base_export_path)\n",
    "        }, f, indent=2)\n",
    "\n",
    "    print(f\"‚úÖ All results exported to: {base_export_path}\")\n",
    "    return str(base_export_path)\n",
    "\n",
    "# Cell 5: Interactive Interface Functions\n",
    "def create_forensic_interface(system):\n",
    "    \"\"\"Create interactive interface for forensic analysts\"\"\"\n",
    "\n",
    "    def display_statistics():\n",
    "        \"\"\"Display system statistics\"\"\"\n",
    "        stats = system.get_statistics()\n",
    "        print(\"\\nüìä FORENSIC SYSTEM STATISTICS\")\n",
    "        print(\"=\"*40)\n",
    "        print(f\"üì∏ Total images processed: {stats.get('total_images', 0)}\")\n",
    "        print(f\"üìù Images with text: {stats.get('images_with_text', 0)}\")\n",
    "        print(f\"üìä Text detection rate: {(stats.get('images_with_text', 0) / max(stats.get('total_images', 1), 1) * 100):.1f}%\")\n",
    "        print(f\"üéØ Average OCR confidence: {stats.get('avg_ocr_confidence', 0):.3f}\")\n",
    "        print(f\"üìã Total text blocks found: {stats.get('total_text_blocks', 0)}\")\n",
    "        print(f\"üîç Total queries executed: {stats.get('total_queries', 0)}\")\n",
    "        print(f\"‚è±Ô∏è Average query time: {stats.get('avg_query_time', 0):.3f}s\")\n",
    "        print(f\"üíæ Total data size: {stats.get('total_file_size_mb', 0)} MB\")\n",
    "        print(f\"üìè Average file size: {stats.get('avg_file_size_kb', 0)} KB\")\n",
    "        print(\"=\"*40)\n",
    "\n",
    "    def interactive_search():\n",
    "        \"\"\"Interactive search interface\"\"\"\n",
    "        print(\"\\nüîç INTERACTIVE FORENSIC SEARCH\")\n",
    "        print(\"=\"*40)\n",
    "        print(\"Enter 'help' for commands, 'quit' to exit\")\n",
    "\n",
    "        while True:\n",
    "            try:\n",
    "                user_input = input(\"\\nüîç Query> \").strip()\n",
    "\n",
    "                if user_input.lower() in ['quit', 'exit', 'q']:\n",
    "                    break\n",
    "                elif user_input.lower() == 'help':\n",
    "                    print(\"\\nüìã Available commands:\")\n",
    "                    print(\"  search <query>     - Semantic text search\")\n",
    "                    print(\"  keyword <words>    - Keyword search\")\n",
    "                    print(\"  stats             - Show system statistics\")\n",
    "                    print(\"  recent            - Show recent queries\")\n",
    "                    print(\"  export <query>    - Export last search results\")\n",
    "                    print(\"  help              - Show this help\")\n",
    "                    print(\"  quit              - Exit interface\")\n",
    "                    continue\n",
    "                elif user_input.lower() == 'stats':\n",
    "                    display_statistics()\n",
    "                    continue\n",
    "                elif user_input.lower() == 'recent':\n",
    "                    cursor = system.conn.execute(\n",
    "                        \"SELECT query_text, results_count, query_date FROM search_queries ORDER BY query_date DESC LIMIT 10\"\n",
    "                    )\n",
    "                    recent = cursor.fetchall()\n",
    "                    print(\"\\nüïê Recent queries:\")\n",
    "                    for query, count, date in recent:\n",
    "                        print(f\"  {date}: '{query}' ({count} results)\")\n",
    "                    continue\n",
    "                elif not user_input:\n",
    "                    continue\n",
    "\n",
    "                # Parse command\n",
    "                parts = user_input.split(' ', 1)\n",
    "                command = parts[0].lower()\n",
    "                query = parts[1] if len(parts) > 1 else \"\"\n",
    "\n",
    "                if command == 'search' and query:\n",
    "                    print(f\"\\nüîç Searching: '{query}'\")\n",
    "                    results = system.search_by_text_query(query)\n",
    "\n",
    "                    if results:\n",
    "                        print(f\"‚úÖ Found {len(results)} matches:\")\n",
    "                        for i, result in enumerate(results[:5], 1):  # Show top 5\n",
    "                            score = result.get('similarity_score', 0)\n",
    "                            print(f\"{i}. {result['filename']} (score: {score:.3f})\")\n",
    "                            print(f\"   {result['text_preview']}\")\n",
    "                            print()\n",
    "                    else:\n",
    "                        print(\"‚ö™ No matches found\")\n",
    "\n",
    "                elif command == 'keyword' and query:\n",
    "                    keywords = query.split()\n",
    "                    print(f\"\\nüîç Keyword search: {keywords}\")\n",
    "                    results = system.search_by_keywords(keywords)\n",
    "\n",
    "                    if results:\n",
    "                        print(f\"‚úÖ Found {len(results)} matches:\")\n",
    "                        for i, result in enumerate(results[:5], 1):\n",
    "                            keyword = result.get('matched_keyword', '')\n",
    "                            print(f\"{i}. {result['filename']} (keyword: '{keyword}')\")\n",
    "                            print(f\"   {result['text_preview']}\")\n",
    "                            print()\n",
    "                    else:\n",
    "                        print(\"‚ö™ No matches found\")\n",
    "\n",
    "                elif command == 'export' and query:\n",
    "                    # Search and export\n",
    "                    results = system.search_by_text_query(query)\n",
    "                    if results:\n",
    "                        output_path = system.export_results(results, system.config['RESULTS_OUTPUT_PATH'])\n",
    "                        print(f\"üìÅ Results exported to: {output_path}\")\n",
    "                    else:\n",
    "                        print(\"‚ö™ No results to export\")\n",
    "\n",
    "                else:\n",
    "                    print(\"‚ùå Unknown command. Type 'help' for available commands.\")\n",
    "\n",
    "            except KeyboardInterrupt:\n",
    "                print(\"\\nüëã Goodbye!\")\n",
    "                break\n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Error: {e}\")\n",
    "\n",
    "    return interactive_search, display_statistics\n",
    "\n",
    "# Cell 6: Main Execution and Examples\n",
    "def main_forensic_analysis():\n",
    "    \"\"\"Main function to run the complete forensic analysis system\"\"\"\n",
    "\n",
    "    print(\"üöÄ INITIALIZING FORENSIC OCR + SEARCH SYSTEM\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    # Initialize system\n",
    "    system = ForensicOCRSearchSystem(CONFIG)\n",
    "\n",
    "    # Check if system is ready\n",
    "    if not system.ocr:\n",
    "        print(\"‚ùå OCR model not loaded. Please check installation.\")\n",
    "        return None\n",
    "\n",
    "    if not system.collection:\n",
    "        print(\"‚ùå Search components not loaded. Please check installation.\")\n",
    "        return None\n",
    "\n",
    "    print(\"‚úÖ System initialized successfully!\")\n",
    "\n",
    "    # Process images if needed\n",
    "    stats = system.get_statistics()\n",
    "    if stats.get('total_images', 0) == 0:\n",
    "        print(\"\\nüì∏ No processed images found. Processing gallery...\")\n",
    "        system.process_image_gallery()\n",
    "    else:\n",
    "        print(f\"\\nüìä Found {stats['total_images']} processed images, {stats['images_with_text']} with text\")\n",
    "\n",
    "    return system\n",
    "\n",
    "# Example usage functions\n",
    "def run_quick_demo(system):\n",
    "    \"\"\"Run a quick demonstration of the system\"\"\"\n",
    "    if not system:\n",
    "        print(\"‚ùå System not available\")\n",
    "        return\n",
    "\n",
    "    print(\"\\nüéØ QUICK DEMONSTRATION\")\n",
    "    print(\"=\"*30)\n",
    "\n",
    "    # Example queries\n",
    "    demo_queries = [\n",
    "        \"phone number\",\n",
    "        \"bank account\",\n",
    "        \"password\",\n",
    "        \"address\"\n",
    "    ]\n",
    "\n",
    "    for query in demo_queries:\n",
    "        print(f\"\\nüîç Demo query: '{query}'\")\n",
    "        results = system.search_by_text_query(query, max_results=3)\n",
    "\n",
    "        if results:\n",
    "            print(f\"‚úÖ Found {len(results)} matches\")\n",
    "            for result in results[:2]:  # Show top 2\n",
    "                print(f\"  üìÑ {result['filename']} (score: {result['similarity_score']:.3f})\")\n",
    "        else:\n",
    "            print(\"‚ö™ No matches\")\n",
    "\n",
    "def list_available_ocr_models():\n",
    "    \"\"\"Display available OCR models\"\"\"\n",
    "    print(\"\\nüîç AVAILABLE OCR MODELS\")\n",
    "    print(\"=\"*30)\n",
    "    for key, info in AVAILABLE_OCR_MODELS.items():\n",
    "        status = \"‚úÖ\" if key == CONFIG['OCR_MODEL'] else \"‚ö™\"\n",
    "        print(f\"{status} {info['name']} ({key})\")\n",
    "        print(f\"   üìä {info['performance']}\")\n",
    "        print(f\"   üìù {info['description']}\")\n",
    "        print(f\"   üíª Install: {info['install_cmd']}\")\n",
    "        print()\n",
    "\n",
    "# Display available models\n",
    "list_available_ocr_models()\n",
    "\n",
    "# Initialize system\n",
    "print(\"\\nüöÄ STARTING FORENSIC SYSTEM...\")\n",
    "forensic_system = main_forensic_analysis()\n",
    "\n",
    "if forensic_system:\n",
    "    # Create interactive interface\n",
    "    interactive_search, display_stats = create_forensic_interface(forensic_system)\n",
    "\n",
    "    print(f\"\\n‚úÖ FORENSIC OCR + SEARCH SYSTEM READY!\")\n",
    "    print(\"=\"*50)\n",
    "    print(\"üìã AVAILABLE FUNCTIONS:\")\n",
    "    print(\"  ‚Ä¢ forensic_system.process_image_gallery() - Process new images\")\n",
    "    print(\"  ‚Ä¢ forensic_system.search_by_text_query(query) - Semantic search\")\n",
    "    print(\"  ‚Ä¢ forensic_system.search_by_keywords([keywords]) - Keyword search\")\n",
    "    print(\"  ‚Ä¢ forensic_system.forensic_query_analysis(query) - Full analysis\")\n",
    "    print(\"  ‚Ä¢ run_comprehensive_forensic_analysis(forensic_system) - Batch analysis\")\n",
    "    print(\"  ‚Ä¢ interactive_search() - Interactive search interface\")\n",
    "    print(\"  ‚Ä¢ display_stats() - Show system statistics\")\n",
    "    print(\"  ‚Ä¢ run_quick_demo(forensic_system) - Quick demonstration\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "    # Show initial statistics\n",
    "    display_stats()\n",
    "\n",
    "    # Run quick demo\n",
    "    run_quick_demo(forensic_system)\n",
    "\n",
    "    print(f\"\\nüí° TIP: Use interactive_search() for hands-on searching!\")\n",
    "    print(f\"üí° TIP: Run run_comprehensive_forensic_analysis(forensic_system) for full analysis!\")\n",
    "\n",
    "else:\n",
    "    print(\"‚ùå Failed to initialize forensic system\")\n",
    "\n",
    "# Cell 7: Usage Instructions and Documentation\n",
    "print(\"\"\"\n",
    "üéØ FORENSIC OCR + SEARCH SYSTEM - COMPLETE GUIDE\n",
    "===============================================\n",
    "\n",
    "üÜï SYSTEM FEATURES:\n",
    "‚Ä¢ üîç Advanced OCR with PaddleOCR/EasyOCR/Tesseract\n",
    "‚Ä¢ üìù Semantic text search using embeddings\n",
    "‚Ä¢ üîç Keyword-based search with SQL\n",
    "‚Ä¢ üìä Comprehensive forensic analysis\n",
    "‚Ä¢ üìÅ Automated result export with metadata\n",
    "‚Ä¢ üíæ SQLite database for persistence\n",
    "‚Ä¢ üéØ Interactive search interface\n",
    "\n",
    "üìã SETUP CHECKLIST:\n",
    "1. ‚úÖ Place suspect images in './suspect_images' folder\n",
    "2. ‚úÖ Run all cells in order (1-7)\n",
    "3. ‚úÖ System automatically processes images with OCR\n",
    "4. ‚úÖ Vector database created for semantic search\n",
    "5. ‚úÖ Ready for forensic analysis\n",
    "\n",
    "üîß OCR MODEL OPTIONS:\n",
    "‚Ä¢ PaddleOCR: Best accuracy, 80+ languages, GPU support\n",
    "‚Ä¢ EasyOCR: Good balance, easy setup, 80+ languages\n",
    "‚Ä¢ Tesseract: Classic, reliable, widely supported\n",
    "\n",
    "üîç SEARCH CAPABILITIES:\n",
    "‚Ä¢ Semantic Search: \"bank account information\" finds related concepts\n",
    "‚Ä¢ Keyword Search: Exact/partial word matching in extracted text\n",
    "‚Ä¢ Combined Analysis: Both semantic + keyword for comprehensive results\n",
    "‚Ä¢ Batch Processing: Multiple queries for systematic investigation\n",
    "\n",
    "üéõÔ∏è KEY FUNCTIONS:\n",
    "forensic_system.search_by_text_query(\"bank account\")\n",
    "forensic_system.search_by_keywords([\"phone\", \"number\"])\n",
    "forensic_system.forensic_query_analysis(\"suspicious activity\")\n",
    "run_comprehensive_forensic_analysis(forensic_system)\n",
    "\n",
    "üìä ANALYSIS FEATURES:\n",
    "‚Ä¢ High-priority evidence detection (score > 0.5)\n",
    "‚Ä¢ Automatic categorization (financial, personal, security, illegal)\n",
    "‚Ä¢ Export results with images and metadata\n",
    "‚Ä¢ Query performance tracking\n",
    "‚Ä¢ Statistical reporting\n",
    "\n",
    "üîç FORENSIC QUERY EXAMPLES:\n",
    "‚Ä¢ \"bank account number\" - Financial information\n",
    "‚Ä¢ \"phone number\" - Contact information\n",
    "‚Ä¢ \"threat violence\" - Security concerns\n",
    "‚Ä¢ \"password\" - Security credentials\n",
    "‚Ä¢ \"suspicious activity\" - General investigation\n",
    "‚Ä¢ \"weapon gun knife\" - Dangerous items\n",
    "‚Ä¢ \"drugs illegal substances\" - Illegal content\n",
    "\n",
    "üìÅ OUTPUT STRUCTURE:\n",
    "forensic_results/\n",
    "‚îú‚îÄ‚îÄ forensic_analysis_20240614_143022/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ high_priority/          # Critical findings\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ financial/              # Financial evidence\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ personal_info/          # Personal information\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ security/               # Security-related\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ illegal/                # Illegal content\n",
    "‚îî‚îÄ‚îÄ search_metadata.json       # Analysis metadata\n",
    "\n",
    "‚öôÔ∏è CONFIGURATION OPTIONS:\n",
    "‚Ä¢ OCR_CONFIDENCE_THRESHOLD: Minimum OCR confidence (0.6)\n",
    "‚Ä¢ SIMILARITY_THRESHOLD: Semantic search threshold (0.3)\n",
    "‚Ä¢ TEXT_MIN_LENGTH: Minimum text length to process (3)\n",
    "‚Ä¢ MAX_RESULTS_DISPLAY: Results shown per query (10)\n",
    "‚Ä¢ BATCH_SIZE: Processing batch size (4)\n",
    "\n",
    "üö® FORENSIC BEST PRACTICES:\n",
    "‚Ä¢ Start with comprehensive batch analysis\n",
    "‚Ä¢ Review high-priority findings first\n",
    "‚Ä¢ Cross-reference semantic + keyword results\n",
    "‚Ä¢ Export evidence with metadata for reports\n",
    "‚Ä¢ Document analysis parameters for court\n",
    "‚Ä¢ Use interactive search for targeted investigation\n",
    "\n",
    "üìà PERFORMANCE OPTIMIZATION:\n",
    "‚Ä¢ PaddleOCR + GPU: Best performance for large datasets\n",
    "‚Ä¢ Adjust confidence thresholds based on image quality\n",
    "‚Ä¢ Use batch processing for efficiency\n",
    "‚Ä¢ Monitor similarity scores for relevance tuning\n",
    "‚Ä¢ Regular database maintenance for speed\n",
    "\n",
    "üîç TROUBLESHOOTING:\n",
    "‚Ä¢ \"No text found\" ‚Üí Check OCR confidence threshold\n",
    "‚Ä¢ \"No search results\" ‚Üí Lower similarity threshold\n",
    "‚Ä¢ \"Slow processing\" ‚Üí Reduce batch size or use CPU\n",
    "‚Ä¢ \"Memory issues\" ‚Üí Process smaller batches\n",
    "‚Ä¢ \"Poor OCR accuracy\" ‚Üí Try different OCR model\n",
    "\n",
    "üìä EXPECTED PERFORMANCE:\n",
    "‚Ä¢ OCR Processing: 2-5 seconds per image (CPU)\n",
    "‚Ä¢ Semantic Search: 0.1-0.5 seconds per query\n",
    "‚Ä¢ Text Detection Rate: 60-90% depending on image quality\n",
    "‚Ä¢ Search Accuracy: High for clear, well-extracted text\n",
    "\n",
    "üéØ INVESTIGATION WORKFLOW:\n",
    "1. Process all suspect images with OCR\n",
    "2. Run comprehensive forensic analysis\n",
    "3. Review high-priority findings\n",
    "4. Conduct targeted searches based on case needs\n",
    "5. Export evidence with metadata\n",
    "6. Generate reports for legal proceedings\n",
    "\n",
    "üí° ADVANCED FEATURES:\n",
    "‚Ä¢ Custom query development for specific cases\n",
    "‚Ä¢ Integration with existing forensic workflows\n",
    "‚Ä¢ Batch export for evidence management\n",
    "‚Ä¢ Statistical analysis for case patterns\n",
    "‚Ä¢ Interactive search for real-time investigation\n",
    "\"\"\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Configuration loaded successfully\n",
      "üìÅ Suspects gallery: ../../datasets/images/text_ocr\n",
      "üìÅ Database path: forensic_analysis_db\n",
      "üìÅ Results output: ../../datasets/images/forensic_results\n",
      "üîç OCR model: paddleocr\n",
      "üìù Forensic OCR + Search System Ready\n",
      "‚úÖ Core dependencies available\n",
      "‚úÖ PaddleOCR already available\n",
      "‚úÖ Search dependencies available\n",
      "‚úÖ All dependencies imported successfully\n",
      "üñ•Ô∏è Using CPU mode\n",
      "üìç Auto-detected device: cpu\n",
      "\n",
      "üîç AVAILABLE OCR MODELS\n",
      "==============================\n",
      "‚úÖ PaddleOCR (paddleocr)\n",
      "   üìä Best overall performance\n",
      "   üìù High accuracy, supports 80+ languages\n",
      "   üíª Install: pip install paddlepaddle paddleocr\n",
      "\n",
      "‚ö™ EasyOCR (easyocr)\n",
      "   üìä Good performance, easy setup\n",
      "   üìù Simple to use, good accuracy\n",
      "   üíª Install: pip install easyocr\n",
      "\n",
      "‚ö™ Tesseract (tesseract)\n",
      "   üìä Baseline performance\n",
      "   üìù Classic OCR, widely supported\n",
      "   üíª Install: pip install pytesseract\n",
      "\n",
      "\n",
      "üöÄ STARTING FORENSIC SYSTEM...\n",
      "üöÄ INITIALIZING FORENSIC OCR + SEARCH SYSTEM\n",
      "============================================================\n",
      "üìÅ Directory ready: ../../datasets/images/text_ocr\n",
      "üìÅ Directory ready: forensic_analysis_db\n",
      "üìÅ Directory ready: ../../datasets/images/forensic_results\n",
      "üì• Loading OCR model: paddleocr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Interpreter\\Python\\Projects\\ai_cyberforensics_ocr\\.venv\\lib\\site-packages\\paddle\\utils\\cpp_extension\\extension_utils.py:715: UserWarning: No ccache found. Please be aware that recompiling all source files may be required. You can download and install ccache from: https://github.com/ccache/ccache/blob/master/doc/INSTALL.md\n",
      "  warnings.warn(warning_message)\n",
      "\u001B[32mCreating model: ('PP-LCNet_x1_0_doc_ori', None)\u001B[0m\n",
      "\u001B[32mUsing official model (PP-LCNet_x1_0_doc_ori), the model files will be automatically downloaded and saved in C:\\Users\\scott\\.paddlex\\official_models.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Fetching 6 files:   0%|          | 0/6 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8d0ae62d5daf412c982c9acf4415c6fa"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mCreating model: ('UVDoc', None)\u001B[0m\n",
      "\u001B[33mThe model(UVDoc) is not supported to run in MKLDNN mode! Using `paddle` instead!\u001B[0m\n",
      "\u001B[32mUsing official model (UVDoc), the model files will be automatically downloaded and saved in C:\\Users\\scott\\.paddlex\\official_models.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Fetching 6 files:   0%|          | 0/6 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "44482d6f65d24f138663a2f642375703"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mCreating model: ('PP-LCNet_x1_0_textline_ori', None)\u001B[0m\n",
      "\u001B[32mUsing official model (PP-LCNet_x1_0_textline_ori), the model files will be automatically downloaded and saved in C:\\Users\\scott\\.paddlex\\official_models.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Fetching 8 files:   0%|          | 0/8 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "00c81ed383b3459aa4b3cbaf0d4f86a2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mCreating model: ('PP-OCRv5_server_det', None)\u001B[0m\n",
      "\u001B[32mUsing official model (PP-OCRv5_server_det), the model files will be automatically downloaded and saved in C:\\Users\\scott\\.paddlex\\official_models.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Fetching 6 files:   0%|          | 0/6 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1df6ba0fa5dc46428f35b4868d1d6d3e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mCreating model: ('PP-OCRv5_server_rec', None)\u001B[0m\n",
      "\u001B[32mUsing official model (PP-OCRv5_server_rec), the model files will be automatically downloaded and saved in C:\\Users\\scott\\.paddlex\\official_models.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Fetching 6 files:   0%|          | 0/6 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "949299be723b4b0993416f0a750ad423"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ PaddleOCR initialized\n",
      "üì• Loading embedding model: sentence-transformers/all-MiniLM-L6-v2\n",
      "üì• Initializing vector database...\n",
      "‚úÖ Search components initialized\n",
      "‚úÖ Database initialized\n",
      "‚úÖ System initialized successfully!\n",
      "\n",
      "üì∏ No processed images found. Processing gallery...\n",
      "üîç Processing images from: ..\\..\\datasets\\images\\text_ocr\n",
      "üîç OCR Model: paddleocr\n",
      "‚è∞ Start time: 2025-07-09 20:05:41\n",
      "üì∏ Found 200 images to process\n",
      "\n",
      "============================================================\n",
      "üîç PROCESSING IMAGES\n",
      "============================================================\n",
      "[  1/200] (  0.5%) Processing: Text_ocr_000.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[  2/200] (  1.0%) Processing: Text_ocr_001.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[  3/200] (  1.5%) Processing: Text_ocr_002.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[  4/200] (  2.0%) Processing: Text_ocr_003.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[  5/200] (  2.5%) Processing: Text_ocr_004.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[  6/200] (  3.0%) Processing: Text_ocr_005.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[  7/200] (  3.5%) Processing: Text_ocr_006.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[  8/200] (  4.0%) Processing: Text_ocr_007.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[  9/200] (  4.5%) Processing: Text_ocr_008.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[ 10/200] (  5.0%) Processing: Text_ocr_009.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[ 11/200] (  5.5%) Processing: Text_ocr_010.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[ 12/200] (  6.0%) Processing: Text_ocr_011.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[ 13/200] (  6.5%) Processing: Text_ocr_012.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[ 14/200] (  7.0%) Processing: Text_ocr_013.jpg..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\scott\\AppData\\Local\\Temp\\ipykernel_9260\\1044633368.py:286: DeprecationWarning: Please use `predict` instead.\n",
      "  ocr_result = self.ocr.ocr(image_array, cls=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ‚ùå ERROR: predict() got an unexpected ke\n",
      "[ 15/200] (  7.5%) Processing: Text_ocr_014.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[ 16/200] (  8.0%) Processing: Text_ocr_015.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[ 17/200] (  8.5%) Processing: Text_ocr_016.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[ 18/200] (  9.0%) Processing: Text_ocr_017.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[ 19/200] (  9.5%) Processing: Text_ocr_018.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[ 20/200] ( 10.0%) Processing: Text_ocr_019.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[ 21/200] ( 10.5%) Processing: Text_ocr_020.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[ 22/200] ( 11.0%) Processing: Text_ocr_021.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[ 23/200] ( 11.5%) Processing: Text_ocr_022.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[ 24/200] ( 12.0%) Processing: Text_ocr_023.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[ 25/200] ( 12.5%) Processing: Text_ocr_024.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[ 26/200] ( 13.0%) Processing: Text_ocr_025.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[ 27/200] ( 13.5%) Processing: Text_ocr_026.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[ 28/200] ( 14.0%) Processing: Text_ocr_027.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[ 29/200] ( 14.5%) Processing: Text_ocr_028.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[ 30/200] ( 15.0%) Processing: Text_ocr_029.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[ 31/200] ( 15.5%) Processing: Text_ocr_030.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[ 32/200] ( 16.0%) Processing: Text_ocr_031.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[ 33/200] ( 16.5%) Processing: Text_ocr_032.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[ 34/200] ( 17.0%) Processing: Text_ocr_033.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[ 35/200] ( 17.5%) Processing: Text_ocr_034.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[ 36/200] ( 18.0%) Processing: Text_ocr_035.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[ 37/200] ( 18.5%) Processing: Text_ocr_036.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[ 38/200] ( 19.0%) Processing: Text_ocr_037.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[ 39/200] ( 19.5%) Processing: Text_ocr_038.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[ 40/200] ( 20.0%) Processing: Text_ocr_039.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[ 41/200] ( 20.5%) Processing: Text_ocr_040.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[ 42/200] ( 21.0%) Processing: Text_ocr_041.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[ 43/200] ( 21.5%) Processing: Text_ocr_042.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[ 44/200] ( 22.0%) Processing: Text_ocr_043.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[ 45/200] ( 22.5%) Processing: Text_ocr_044.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[ 46/200] ( 23.0%) Processing: Text_ocr_045.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[ 47/200] ( 23.5%) Processing: Text_ocr_046.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[ 48/200] ( 24.0%) Processing: Text_ocr_047.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[ 49/200] ( 24.5%) Processing: Text_ocr_048.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[ 50/200] ( 25.0%) Processing: Text_ocr_049.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[ 51/200] ( 25.5%) Processing: Text_ocr_050.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[ 52/200] ( 26.0%) Processing: Text_ocr_051.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[ 53/200] ( 26.5%) Processing: Text_ocr_052.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[ 54/200] ( 27.0%) Processing: Text_ocr_053.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[ 55/200] ( 27.5%) Processing: Text_ocr_054.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[ 56/200] ( 28.0%) Processing: Text_ocr_055.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[ 57/200] ( 28.5%) Processing: Text_ocr_056.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[ 58/200] ( 29.0%) Processing: Text_ocr_057.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[ 59/200] ( 29.5%) Processing: Text_ocr_058.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[ 60/200] ( 30.0%) Processing: Text_ocr_059.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[ 61/200] ( 30.5%) Processing: Text_ocr_060.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[ 62/200] ( 31.0%) Processing: Text_ocr_061.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[ 63/200] ( 31.5%) Processing: Text_ocr_062.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[ 64/200] ( 32.0%) Processing: Text_ocr_063.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[ 65/200] ( 32.5%) Processing: Text_ocr_064.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[ 66/200] ( 33.0%) Processing: Text_ocr_065.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[ 67/200] ( 33.5%) Processing: Text_ocr_066.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[ 68/200] ( 34.0%) Processing: Text_ocr_067.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[ 69/200] ( 34.5%) Processing: Text_ocr_068.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[ 70/200] ( 35.0%) Processing: Text_ocr_069.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[ 71/200] ( 35.5%) Processing: Text_ocr_070.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[ 72/200] ( 36.0%) Processing: Text_ocr_071.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[ 73/200] ( 36.5%) Processing: Text_ocr_072.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[ 74/200] ( 37.0%) Processing: Text_ocr_073.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[ 75/200] ( 37.5%) Processing: Text_ocr_074.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[ 76/200] ( 38.0%) Processing: Text_ocr_075.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[ 77/200] ( 38.5%) Processing: Text_ocr_076.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[ 78/200] ( 39.0%) Processing: Text_ocr_077.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[ 79/200] ( 39.5%) Processing: Text_ocr_078.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[ 80/200] ( 40.0%) Processing: Text_ocr_079.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[ 81/200] ( 40.5%) Processing: Text_ocr_080.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[ 82/200] ( 41.0%) Processing: Text_ocr_081.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[ 83/200] ( 41.5%) Processing: Text_ocr_082.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[ 84/200] ( 42.0%) Processing: Text_ocr_083.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[ 85/200] ( 42.5%) Processing: Text_ocr_084.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[ 86/200] ( 43.0%) Processing: Text_ocr_085.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[ 87/200] ( 43.5%) Processing: Text_ocr_086.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[ 88/200] ( 44.0%) Processing: Text_ocr_087.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[ 89/200] ( 44.5%) Processing: Text_ocr_088.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[ 90/200] ( 45.0%) Processing: Text_ocr_089.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[ 91/200] ( 45.5%) Processing: Text_ocr_090.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[ 92/200] ( 46.0%) Processing: Text_ocr_091.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[ 93/200] ( 46.5%) Processing: Text_ocr_092.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[ 94/200] ( 47.0%) Processing: Text_ocr_093.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[ 95/200] ( 47.5%) Processing: Text_ocr_094.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[ 96/200] ( 48.0%) Processing: Text_ocr_095.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[ 97/200] ( 48.5%) Processing: Text_ocr_096.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[ 98/200] ( 49.0%) Processing: Text_ocr_097.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[ 99/200] ( 49.5%) Processing: Text_ocr_098.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[100/200] ( 50.0%) Processing: Text_ocr_099.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[101/200] ( 50.5%) Processing: Text_ocr_000.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[102/200] ( 51.0%) Processing: Text_ocr_001.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[103/200] ( 51.5%) Processing: Text_ocr_002.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[104/200] ( 52.0%) Processing: Text_ocr_003.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[105/200] ( 52.5%) Processing: Text_ocr_004.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[106/200] ( 53.0%) Processing: Text_ocr_005.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[107/200] ( 53.5%) Processing: Text_ocr_006.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[108/200] ( 54.0%) Processing: Text_ocr_007.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[109/200] ( 54.5%) Processing: Text_ocr_008.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[110/200] ( 55.0%) Processing: Text_ocr_009.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[111/200] ( 55.5%) Processing: Text_ocr_010.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[112/200] ( 56.0%) Processing: Text_ocr_011.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[113/200] ( 56.5%) Processing: Text_ocr_012.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[114/200] ( 57.0%) Processing: Text_ocr_013.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[115/200] ( 57.5%) Processing: Text_ocr_014.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[116/200] ( 58.0%) Processing: Text_ocr_015.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[117/200] ( 58.5%) Processing: Text_ocr_016.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[118/200] ( 59.0%) Processing: Text_ocr_017.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[119/200] ( 59.5%) Processing: Text_ocr_018.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[120/200] ( 60.0%) Processing: Text_ocr_019.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[121/200] ( 60.5%) Processing: Text_ocr_020.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[122/200] ( 61.0%) Processing: Text_ocr_021.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[123/200] ( 61.5%) Processing: Text_ocr_022.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[124/200] ( 62.0%) Processing: Text_ocr_023.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[125/200] ( 62.5%) Processing: Text_ocr_024.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[126/200] ( 63.0%) Processing: Text_ocr_025.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[127/200] ( 63.5%) Processing: Text_ocr_026.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[128/200] ( 64.0%) Processing: Text_ocr_027.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[129/200] ( 64.5%) Processing: Text_ocr_028.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[130/200] ( 65.0%) Processing: Text_ocr_029.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[131/200] ( 65.5%) Processing: Text_ocr_030.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[132/200] ( 66.0%) Processing: Text_ocr_031.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[133/200] ( 66.5%) Processing: Text_ocr_032.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[134/200] ( 67.0%) Processing: Text_ocr_033.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[135/200] ( 67.5%) Processing: Text_ocr_034.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[136/200] ( 68.0%) Processing: Text_ocr_035.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[137/200] ( 68.5%) Processing: Text_ocr_036.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[138/200] ( 69.0%) Processing: Text_ocr_037.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[139/200] ( 69.5%) Processing: Text_ocr_038.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[140/200] ( 70.0%) Processing: Text_ocr_039.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[141/200] ( 70.5%) Processing: Text_ocr_040.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[142/200] ( 71.0%) Processing: Text_ocr_041.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[143/200] ( 71.5%) Processing: Text_ocr_042.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[144/200] ( 72.0%) Processing: Text_ocr_043.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[145/200] ( 72.5%) Processing: Text_ocr_044.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[146/200] ( 73.0%) Processing: Text_ocr_045.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[147/200] ( 73.5%) Processing: Text_ocr_046.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[148/200] ( 74.0%) Processing: Text_ocr_047.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[149/200] ( 74.5%) Processing: Text_ocr_048.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[150/200] ( 75.0%) Processing: Text_ocr_049.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[151/200] ( 75.5%) Processing: Text_ocr_050.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[152/200] ( 76.0%) Processing: Text_ocr_051.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[153/200] ( 76.5%) Processing: Text_ocr_052.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[154/200] ( 77.0%) Processing: Text_ocr_053.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[155/200] ( 77.5%) Processing: Text_ocr_054.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[156/200] ( 78.0%) Processing: Text_ocr_055.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[157/200] ( 78.5%) Processing: Text_ocr_056.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[158/200] ( 79.0%) Processing: Text_ocr_057.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[159/200] ( 79.5%) Processing: Text_ocr_058.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[160/200] ( 80.0%) Processing: Text_ocr_059.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[161/200] ( 80.5%) Processing: Text_ocr_060.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[162/200] ( 81.0%) Processing: Text_ocr_061.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[163/200] ( 81.5%) Processing: Text_ocr_062.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[164/200] ( 82.0%) Processing: Text_ocr_063.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[165/200] ( 82.5%) Processing: Text_ocr_064.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[166/200] ( 83.0%) Processing: Text_ocr_065.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[167/200] ( 83.5%) Processing: Text_ocr_066.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[168/200] ( 84.0%) Processing: Text_ocr_067.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[169/200] ( 84.5%) Processing: Text_ocr_068.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[170/200] ( 85.0%) Processing: Text_ocr_069.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[171/200] ( 85.5%) Processing: Text_ocr_070.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[172/200] ( 86.0%) Processing: Text_ocr_071.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[173/200] ( 86.5%) Processing: Text_ocr_072.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[174/200] ( 87.0%) Processing: Text_ocr_073.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[175/200] ( 87.5%) Processing: Text_ocr_074.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[176/200] ( 88.0%) Processing: Text_ocr_075.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[177/200] ( 88.5%) Processing: Text_ocr_076.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[178/200] ( 89.0%) Processing: Text_ocr_077.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[179/200] ( 89.5%) Processing: Text_ocr_078.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[180/200] ( 90.0%) Processing: Text_ocr_079.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[181/200] ( 90.5%) Processing: Text_ocr_080.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[182/200] ( 91.0%) Processing: Text_ocr_081.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[183/200] ( 91.5%) Processing: Text_ocr_082.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[184/200] ( 92.0%) Processing: Text_ocr_083.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[185/200] ( 92.5%) Processing: Text_ocr_084.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[186/200] ( 93.0%) Processing: Text_ocr_085.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[187/200] ( 93.5%) Processing: Text_ocr_086.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[188/200] ( 94.0%) Processing: Text_ocr_087.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[189/200] ( 94.5%) Processing: Text_ocr_088.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[190/200] ( 95.0%) Processing: Text_ocr_089.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[191/200] ( 95.5%) Processing: Text_ocr_090.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[192/200] ( 96.0%) Processing: Text_ocr_091.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[193/200] ( 96.5%) Processing: Text_ocr_092.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[194/200] ( 97.0%) Processing: Text_ocr_093.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[195/200] ( 97.5%) Processing: Text_ocr_094.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[196/200] ( 98.0%) Processing: Text_ocr_095.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[197/200] ( 98.5%) Processing: Text_ocr_096.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[198/200] ( 99.0%) Processing: Text_ocr_097.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[199/200] ( 99.5%) Processing: Text_ocr_098.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "[200/200] (100.0%) Processing: Text_ocr_099.jpg... ‚ùå ERROR: predict() got an unexpected ke\n",
      "\n",
      "============================================================\n",
      "üìä PROCESSING SUMMARY\n",
      "============================================================\n",
      "üì∏ Total images: 200\n",
      "‚úÖ Successfully processed: 0\n",
      "üìù Images with text: 0\n",
      "‚ö™ Images without text: 0\n",
      "‚è±Ô∏è Total time: 2.6s (0.01s per image)\n",
      "\n",
      "============================================================\n",
      "\n",
      "‚úÖ FORENSIC OCR + SEARCH SYSTEM READY!\n",
      "==================================================\n",
      "üìã AVAILABLE FUNCTIONS:\n",
      "  ‚Ä¢ forensic_system.process_image_gallery() - Process new images\n",
      "  ‚Ä¢ forensic_system.search_by_text_query(query) - Semantic search\n",
      "  ‚Ä¢ forensic_system.search_by_keywords([keywords]) - Keyword search\n",
      "  ‚Ä¢ forensic_system.forensic_query_analysis(query) - Full analysis\n",
      "  ‚Ä¢ run_comprehensive_forensic_analysis(forensic_system) - Batch analysis\n",
      "  ‚Ä¢ interactive_search() - Interactive search interface\n",
      "  ‚Ä¢ display_stats() - Show system statistics\n",
      "  ‚Ä¢ run_quick_demo(forensic_system) - Quick demonstration\n",
      "==================================================\n",
      "\n",
      "üìä FORENSIC SYSTEM STATISTICS\n",
      "========================================\n",
      "üì∏ Total images processed: 0\n",
      "üìù Images with text: 0\n",
      "üìä Text detection rate: 0.0%\n",
      "üéØ Average OCR confidence: 0.000\n",
      "üìã Total text blocks found: 0\n",
      "üîç Total queries executed: 8\n",
      "‚è±Ô∏è Average query time: 1.107s\n",
      "üíæ Total data size: 0 MB\n",
      "üìè Average file size: 0 KB\n",
      "========================================\n",
      "\n",
      "üéØ QUICK DEMONSTRATION\n",
      "==============================\n",
      "\n",
      "üîç Demo query: 'phone number'\n",
      "‚ö™ No matches\n",
      "\n",
      "üîç Demo query: 'bank account'\n",
      "‚ö™ No matches\n",
      "\n",
      "üîç Demo query: 'password'\n",
      "‚ö™ No matches\n",
      "\n",
      "üîç Demo query: 'address'\n",
      "‚ö™ No matches\n",
      "\n",
      "üí° TIP: Use interactive_search() for hands-on searching!\n",
      "üí° TIP: Run run_comprehensive_forensic_analysis(forensic_system) for full analysis!\n",
      "\n",
      "üéØ FORENSIC OCR + SEARCH SYSTEM - COMPLETE GUIDE\n",
      "===============================================\n",
      "\n",
      "üÜï SYSTEM FEATURES:\n",
      "‚Ä¢ üîç Advanced OCR with PaddleOCR/EasyOCR/Tesseract\n",
      "‚Ä¢ üìù Semantic text search using embeddings\n",
      "‚Ä¢ üîç Keyword-based search with SQL\n",
      "‚Ä¢ üìä Comprehensive forensic analysis\n",
      "‚Ä¢ üìÅ Automated result export with metadata\n",
      "‚Ä¢ üíæ SQLite database for persistence\n",
      "‚Ä¢ üéØ Interactive search interface\n",
      "\n",
      "üìã SETUP CHECKLIST:\n",
      "1. ‚úÖ Place suspect images in './suspect_images' folder\n",
      "2. ‚úÖ Run all cells in order (1-7)\n",
      "3. ‚úÖ System automatically processes images with OCR\n",
      "4. ‚úÖ Vector database created for semantic search\n",
      "5. ‚úÖ Ready for forensic analysis\n",
      "\n",
      "üîß OCR MODEL OPTIONS:\n",
      "‚Ä¢ PaddleOCR: Best accuracy, 80+ languages, GPU support\n",
      "‚Ä¢ EasyOCR: Good balance, easy setup, 80+ languages\n",
      "‚Ä¢ Tesseract: Classic, reliable, widely supported\n",
      "\n",
      "üîç SEARCH CAPABILITIES:\n",
      "‚Ä¢ Semantic Search: \"bank account information\" finds related concepts\n",
      "‚Ä¢ Keyword Search: Exact/partial word matching in extracted text\n",
      "‚Ä¢ Combined Analysis: Both semantic + keyword for comprehensive results\n",
      "‚Ä¢ Batch Processing: Multiple queries for systematic investigation\n",
      "\n",
      "üéõÔ∏è KEY FUNCTIONS:\n",
      "forensic_system.search_by_text_query(\"bank account\")\n",
      "forensic_system.search_by_keywords([\"phone\", \"number\"])\n",
      "forensic_system.forensic_query_analysis(\"suspicious activity\")\n",
      "run_comprehensive_forensic_analysis(forensic_system)\n",
      "\n",
      "üìä ANALYSIS FEATURES:\n",
      "‚Ä¢ High-priority evidence detection (score > 0.5)\n",
      "‚Ä¢ Automatic categorization (financial, personal, security, illegal)\n",
      "‚Ä¢ Export results with images and metadata\n",
      "‚Ä¢ Query performance tracking\n",
      "‚Ä¢ Statistical reporting\n",
      "\n",
      "üîç FORENSIC QUERY EXAMPLES:\n",
      "‚Ä¢ \"bank account number\" - Financial information\n",
      "‚Ä¢ \"phone number\" - Contact information\n",
      "‚Ä¢ \"threat violence\" - Security concerns\n",
      "‚Ä¢ \"password\" - Security credentials\n",
      "‚Ä¢ \"suspicious activity\" - General investigation\n",
      "‚Ä¢ \"weapon gun knife\" - Dangerous items\n",
      "‚Ä¢ \"drugs illegal substances\" - Illegal content\n",
      "\n",
      "üìÅ OUTPUT STRUCTURE:\n",
      "forensic_results/\n",
      "‚îú‚îÄ‚îÄ forensic_analysis_20240614_143022/\n",
      "‚îÇ   ‚îú‚îÄ‚îÄ high_priority/          # Critical findings\n",
      "‚îÇ   ‚îú‚îÄ‚îÄ financial/              # Financial evidence\n",
      "‚îÇ   ‚îú‚îÄ‚îÄ personal_info/          # Personal information\n",
      "‚îÇ   ‚îú‚îÄ‚îÄ security/               # Security-related\n",
      "‚îÇ   ‚îî‚îÄ‚îÄ illegal/                # Illegal content\n",
      "‚îî‚îÄ‚îÄ search_metadata.json       # Analysis metadata\n",
      "\n",
      "‚öôÔ∏è CONFIGURATION OPTIONS:\n",
      "‚Ä¢ OCR_CONFIDENCE_THRESHOLD: Minimum OCR confidence (0.6)\n",
      "‚Ä¢ SIMILARITY_THRESHOLD: Semantic search threshold (0.3)\n",
      "‚Ä¢ TEXT_MIN_LENGTH: Minimum text length to process (3)\n",
      "‚Ä¢ MAX_RESULTS_DISPLAY: Results shown per query (10)\n",
      "‚Ä¢ BATCH_SIZE: Processing batch size (4)\n",
      "\n",
      "üö® FORENSIC BEST PRACTICES:\n",
      "‚Ä¢ Start with comprehensive batch analysis\n",
      "‚Ä¢ Review high-priority findings first\n",
      "‚Ä¢ Cross-reference semantic + keyword results\n",
      "‚Ä¢ Export evidence with metadata for reports\n",
      "‚Ä¢ Document analysis parameters for court\n",
      "‚Ä¢ Use interactive search for targeted investigation\n",
      "\n",
      "üìà PERFORMANCE OPTIMIZATION:\n",
      "‚Ä¢ PaddleOCR + GPU: Best performance for large datasets\n",
      "‚Ä¢ Adjust confidence thresholds based on image quality\n",
      "‚Ä¢ Use batch processing for efficiency\n",
      "‚Ä¢ Monitor similarity scores for relevance tuning\n",
      "‚Ä¢ Regular database maintenance for speed\n",
      "\n",
      "üîç TROUBLESHOOTING:\n",
      "‚Ä¢ \"No text found\" ‚Üí Check OCR confidence threshold\n",
      "‚Ä¢ \"No search results\" ‚Üí Lower similarity threshold\n",
      "‚Ä¢ \"Slow processing\" ‚Üí Reduce batch size or use CPU\n",
      "‚Ä¢ \"Memory issues\" ‚Üí Process smaller batches\n",
      "‚Ä¢ \"Poor OCR accuracy\" ‚Üí Try different OCR model\n",
      "\n",
      "üìä EXPECTED PERFORMANCE:\n",
      "‚Ä¢ OCR Processing: 2-5 seconds per image (CPU)\n",
      "‚Ä¢ Semantic Search: 0.1-0.5 seconds per query\n",
      "‚Ä¢ Text Detection Rate: 60-90% depending on image quality\n",
      "‚Ä¢ Search Accuracy: High for clear, well-extracted text\n",
      "\n",
      "üéØ INVESTIGATION WORKFLOW:\n",
      "1. Process all suspect images with OCR\n",
      "2. Run comprehensive forensic analysis\n",
      "3. Review high-priority findings\n",
      "4. Conduct targeted searches based on case needs\n",
      "5. Export evidence with metadata\n",
      "6. Generate reports for legal proceedings\n",
      "\n",
      "üí° ADVANCED FEATURES:\n",
      "‚Ä¢ Custom query development for specific cases\n",
      "‚Ä¢ Integration with existing forensic workflows\n",
      "‚Ä¢ Batch export for evidence management\n",
      "‚Ä¢ Statistical analysis for case patterns\n",
      "‚Ä¢ Interactive search for real-time investigation\n",
      "\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-25T15:22:57.878751Z",
     "start_time": "2025-07-25T15:22:57.839688Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Quick Fix: Add OCR Selector to Existing Interface\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "print(\"üîß QUICK FIX: Adding OCR selector to existing interface\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Create the missing OCR selector\n",
    "ocr_selector_fix = widgets.Dropdown(\n",
    "    options=[\n",
    "        ('PaddleOCR - Best overall, 80+ languages', 'paddleocr'),\n",
    "        ('EasyOCR - Good for European languages', 'easyocr'),\n",
    "        ('Tesseract - Classic OCR for printed text', 'tesseract'),\n",
    "        ('TrOCR - AI-based OCR for handwriting', 'trocr')\n",
    "    ],\n",
    "    value='paddleocr',\n",
    "    description='OCR Engine:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='500px')\n",
    ")\n",
    "\n",
    "# Create enhanced interface section for OCR\n",
    "ocr_section = widgets.VBox([\n",
    "    widgets.HTML(\"<div style='background-color: #e8f4fd; padding: 15px; border-radius: 5px; margin: 10px 0;'>\"),\n",
    "    widgets.HTML(\"<h4 style='margin: 0; color: #0066cc;'>üîç OCR Engine Configuration</h4>\"),\n",
    "    widgets.HTML(\"<p style='margin: 5px 0; font-size: 14px;'>Select the OCR engine for text extraction:</p>\"),\n",
    "    ocr_selector_fix,\n",
    "    widgets.HTML(\"<p style='margin: 5px 0; font-size: 12px; color: #666;'>üí° Different engines work better for different types of evidence</p>\"),\n",
    "    widgets.HTML(\"</div>\")\n",
    "])\n",
    "\n",
    "print(\"üì± Displaying OCR configuration section:\")\n",
    "display(ocr_section)\n",
    "\n",
    "# Add functionality to show OCR info\n",
    "def show_ocr_info(change):\n",
    "    info_map = {\n",
    "        'paddleocr': {\n",
    "            'name': 'PaddleOCR',\n",
    "            'best_for': 'Asian languages, handwriting, complex layouts',\n",
    "            'use_cases': 'Phone screenshots, multilingual documents, handwritten notes'\n",
    "        },\n",
    "        'easyocr': {\n",
    "            'name': 'EasyOCR',\n",
    "            'best_for': 'European languages, clean text',\n",
    "            'use_cases': 'Printed documents, simple layouts, European text'\n",
    "        },\n",
    "        'tesseract': {\n",
    "            'name': 'Tesseract',\n",
    "            'best_for': 'Clean printed text, stability',\n",
    "            'use_cases': 'Bank statements, invoices, typed documents'\n",
    "        },\n",
    "        'trocr': {\n",
    "            'name': 'TrOCR (Transformers)',\n",
    "            'best_for': 'Handwritten text, degraded images',\n",
    "            'use_cases': 'Handwritten notes, old documents, poor quality scans'\n",
    "        }\n",
    "    }\n",
    "\n",
    "    if change['new'] in info_map:\n",
    "        info = info_map[change['new']]\n",
    "        print(f\"\\nüîÑ Selected: {info['name']}\")\n",
    "        print(f\"üéØ Best for: {info['best_for']}\")\n",
    "        print(f\"üìã Use cases: {info['use_cases']}\")\n",
    "\n",
    "ocr_selector_fix.observe(show_ocr_info, names='value')\n",
    "\n",
    "# Instructions for integrating with existing system\n",
    "print(\"\\nüîó INTEGRATION INSTRUCTIONS:\")\n",
    "print(\"=\"*30)\n",
    "print(\"To use this OCR selector with your existing forensic system:\")\n",
    "print()\n",
    "print(\"1. The OCR selector is now available as 'ocr_selector_fix'\")\n",
    "print(\"2. Get current selection: ocr_selector_fix.value\")\n",
    "print(\"3. Use in your system config:\")\n",
    "print(\"   config['OCR_MODEL'] = ocr_selector_fix.value\")\n",
    "print()\n",
    "print(\"4. Update your forensic system initialization:\")\n",
    "print(\"   system = CompactForensicSystem(config)\")\n",
    "\n",
    "# Make the selector available globally\n",
    "globals()['main_ocr_selector'] = ocr_selector_fix\n",
    "\n",
    "print(f\"\\n‚úÖ OCR selector ready! Current selection: {ocr_selector_fix.value}\")\n",
    "print(\"üîß This should work alongside your existing interface\")\n",
    "\n",
    "# Test the selector\n",
    "print(\"\\nüß™ Testing OCR selector functionality...\")\n",
    "print(f\"üìã Available options: {[opt[1] for opt in ocr_selector_fix.options]}\")\n",
    "print(f\"üìã Current value: {ocr_selector_fix.value}\")\n",
    "print(f\"üìã Widget type: {type(ocr_selector_fix)}\")\n",
    "\n",
    "print(\"\\nüí° Try selecting different OCR engines above to see their descriptions!\")"
   ],
   "id": "9832501882fb7f77",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß QUICK FIX: Adding OCR selector to existing interface\n",
      "==================================================\n",
      "üì± Displaying OCR configuration section:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VBox(children=(HTML(value=\"<div style='background-color: #e8f4fd; padding: 15px; border-radius: 5px; margin: 1‚Ä¶"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "18b2b362d3cf4410ab20a1eb05d4730e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîó INTEGRATION INSTRUCTIONS:\n",
      "==============================\n",
      "To use this OCR selector with your existing forensic system:\n",
      "\n",
      "1. The OCR selector is now available as 'ocr_selector_fix'\n",
      "2. Get current selection: ocr_selector_fix.value\n",
      "3. Use in your system config:\n",
      "   config['OCR_MODEL'] = ocr_selector_fix.value\n",
      "\n",
      "4. Update your forensic system initialization:\n",
      "   system = CompactForensicSystem(config)\n",
      "\n",
      "‚úÖ OCR selector ready! Current selection: paddleocr\n",
      "üîß This should work alongside your existing interface\n",
      "\n",
      "üß™ Testing OCR selector functionality...\n",
      "üìã Available options: ['paddleocr', 'easyocr', 'tesseract', 'trocr']\n",
      "üìã Current value: paddleocr\n",
      "üìã Widget type: <class 'ipywidgets.widgets.widget_selection.Dropdown'>\n",
      "\n",
      "üí° Try selecting different OCR engines above to see their descriptions!\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-25T15:27:33.071655Z",
     "start_time": "2025-07-25T15:27:30.837282Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Compact Local Forensic OCR System with GUI\n",
    "import os, json, sqlite3, shutil, warnings, time\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from typing import List, Dict, Any, Optional\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Compact config with OCR options\n",
    "CONFIG = {\n",
    "    'OCR_MODEL': 'paddleocr', 'OCR_CONFIDENCE_THRESHOLD': 0.6,\n",
    "    'LLM_PROVIDER': 'ollama', 'LLM_MODEL': 'llama3.2:3b', 'LLM_BASE_URL': 'http://localhost:11434',\n",
    "    'LLM_TEMPERATURE': 0.1, 'LLM_MAX_TOKENS': 1000,\n",
    "    'EMBEDDING_PROVIDER': 'huggingface', 'EMBEDDING_MODEL': 'sentence-transformers/all-MiniLM-L6-v2',\n",
    "    'VECTOR_STORE_PATH': './forensic_vectorstore', 'CHUNK_SIZE': 500, 'CHUNK_OVERLAP': 50,\n",
    "    'SUSPECTS_GALLERY_PATH': './suspects_gallery', 'DATABASE_PATH': './forensic_analysis_db',\n",
    "    'RESULTS_OUTPUT_PATH': './forensic_results', 'BATCH_SIZE': 4, 'MAX_RESULTS_DISPLAY': 10,\n",
    "}\n",
    "\n",
    "# OCR model options for different evidence types\n",
    "OCR_MODELS = {\n",
    "    'paddleocr': {'name': 'PaddleOCR', 'desc': 'Best overall, 80+ languages, handwriting capable', 'strengths': 'Asian text, complex layouts'},\n",
    "    'easyocr': {'name': 'EasyOCR', 'desc': 'Good for European languages, simple setup', 'strengths': 'European text, clean images'},\n",
    "    'tesseract': {'name': 'Tesseract', 'desc': 'Classic OCR, best for clean printed text', 'strengths': 'Printed documents, stable'},\n",
    "    'trocr': {'name': 'TrOCR (Transformers)', 'desc': 'AI-based, excellent for handwriting', 'strengths': 'Handwritten notes, degraded images'}\n",
    "}\n",
    "\n",
    "print(f\"üè† LOCAL FORENSIC SYSTEM | LLM: {CONFIG['LLM_PROVIDER']}-{CONFIG['LLM_MODEL']} | üîí 100% Private\")\n",
    "\n",
    "# Quick dependency check\n",
    "def check_deps():\n",
    "    deps = ['paddleocr', 'langchain', 'chromadb', 'sentence_transformers']\n",
    "    for dep in deps:\n",
    "        try: __import__(dep.replace('-', '_')); print(f\"‚úÖ {dep}\")\n",
    "        except ImportError: print(f\"‚ùå {dep} - Install: pip install {dep}\")\n",
    "\n",
    "def check_ollama():\n",
    "    try:\n",
    "        import requests\n",
    "        r = requests.get(f\"{CONFIG['LLM_BASE_URL']}/api/tags\", timeout=5)\n",
    "        if r.status_code == 200:\n",
    "            models = [m['name'] for m in r.json().get('models', [])]\n",
    "            print(f\"‚úÖ Ollama: {models}\")\n",
    "            return CONFIG['LLM_MODEL'] in models\n",
    "        return False\n",
    "    except: print(\"‚ùå Ollama not running\"); return False\n",
    "\n",
    "check_deps()\n",
    "ollama_ready = check_ollama() if CONFIG['LLM_PROVIDER'] == 'ollama' else True\n",
    "\n",
    "# Compact forensic system\n",
    "class CompactForensicSystem:\n",
    "    def __init__(self, config=None):\n",
    "        self.config = config or CONFIG.copy()\n",
    "        self._setup_dirs()\n",
    "        self._init_db()\n",
    "        self._init_ocr()\n",
    "        self._init_llm()\n",
    "\n",
    "    def _setup_dirs(self):\n",
    "        for k in ['SUSPECTS_GALLERY_PATH', 'DATABASE_PATH', 'RESULTS_OUTPUT_PATH', 'VECTOR_STORE_PATH']:\n",
    "            os.makedirs(self.config[k], exist_ok=True)\n",
    "\n",
    "    def _init_db(self):\n",
    "        db_path = os.path.join(self.config['DATABASE_PATH'], 'forensic.db')\n",
    "        self.conn = sqlite3.connect(db_path)\n",
    "        self.conn.execute('''CREATE TABLE IF NOT EXISTS forensic_images (\n",
    "            id INTEGER PRIMARY KEY, filename TEXT UNIQUE, full_path TEXT, extracted_text TEXT,\n",
    "            ocr_confidence REAL, processed_date TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
    "            local_analysis TEXT, risk_score REAL, contains_incriminating BOOLEAN DEFAULT 0,\n",
    "            vector_stored BOOLEAN DEFAULT 0)''')\n",
    "        self.conn.execute('''CREATE TABLE IF NOT EXISTS local_investigations (\n",
    "            id INTEGER PRIMARY KEY, query TEXT, investigation_date TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
    "            results_json TEXT, flagged_images TEXT, model_used TEXT, processing_time REAL)''')\n",
    "        self.conn.commit()\n",
    "\n",
    "    def _init_ocr(self):\n",
    "        try:\n",
    "            ocr_model = self.config['OCR_MODEL']\n",
    "            if ocr_model == 'paddleocr':\n",
    "                from paddleocr import PaddleOCR\n",
    "                self.ocr = PaddleOCR(use_textline_orientation=True, lang='en', show_log=False)\n",
    "            elif ocr_model == 'easyocr':\n",
    "                import easyocr\n",
    "                self.ocr = easyocr.Reader(['en'], gpu=False)\n",
    "            elif ocr_model == 'tesseract':\n",
    "                import pytesseract\n",
    "                self.ocr = pytesseract\n",
    "            elif ocr_model == 'trocr':\n",
    "                from transformers import TrOCRProcessor, VisionEncoderDecoderModel\n",
    "                self.ocr_processor = TrOCRProcessor.from_pretrained('microsoft/trocr-base-printed')\n",
    "                self.ocr_model = VisionEncoderDecoderModel.from_pretrained('microsoft/trocr-base-printed')\n",
    "                self.ocr = 'trocr'\n",
    "            print(f\"‚úÖ {OCR_MODELS[ocr_model]['name']} ready\")\n",
    "        except Exception as e: print(f\"‚ùå OCR error: {e}\"); self.ocr = None\n",
    "\n",
    "    def _init_llm(self):\n",
    "        try:\n",
    "            if self.config['LLM_PROVIDER'] == 'ollama':\n",
    "                from langchain_community.llms import Ollama\n",
    "                self.llm = Ollama(model=self.config['LLM_MODEL'], base_url=self.config['LLM_BASE_URL'],\n",
    "                                temperature=self.config['LLM_TEMPERATURE'])\n",
    "            elif self.config['LLM_PROVIDER'] == 'transformers':\n",
    "                from langchain_community.llms import HuggingFacePipeline\n",
    "                from transformers import pipeline\n",
    "                pipe = pipeline(\"text-generation\", model=self.config['LLM_MODEL'],\n",
    "                              max_new_tokens=self.config['LLM_MAX_TOKENS'])\n",
    "                self.llm = HuggingFacePipeline(pipeline=pipe)\n",
    "\n",
    "            from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "            from langchain_community.vectorstores import Chroma\n",
    "            from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "            self.embeddings = HuggingFaceEmbeddings(model_name=self.config['EMBEDDING_MODEL'],\n",
    "                                                  model_kwargs={'device': 'cpu'})\n",
    "            self.vectorstore = Chroma(persist_directory=self.config['VECTOR_STORE_PATH'],\n",
    "                                    embedding_function=self.embeddings)\n",
    "            self.text_splitter = RecursiveCharacterTextSplitter(chunk_size=self.config['CHUNK_SIZE'],\n",
    "                                                              chunk_overlap=self.config['CHUNK_OVERLAP'])\n",
    "            print(\"‚úÖ LangChain ready\")\n",
    "        except Exception as e: print(f\"‚ùå LLM error: {e}\")\n",
    "\n",
    "    def extract_text(self, img_path: str) -> Dict[str, Any]:\n",
    "        try:\n",
    "            img = Image.open(img_path).convert(\"RGB\")\n",
    "            result = {'filename': os.path.basename(img_path), 'full_path': img_path,\n",
    "                     'extracted_text': '', 'ocr_confidence': 0.0, 'error': None}\n",
    "\n",
    "            if self.ocr:\n",
    "                ocr_model = self.config['OCR_MODEL']\n",
    "\n",
    "                if ocr_model == 'paddleocr':\n",
    "                    ocr_result = self.ocr.ocr(np.array(img), cls=True)\n",
    "                    if ocr_result and ocr_result[0]:\n",
    "                        texts, confs = [], []\n",
    "                        for line in ocr_result:\n",
    "                            for detection in line:\n",
    "                                bbox, (text, conf) = detection\n",
    "                                if conf >= self.config['OCR_CONFIDENCE_THRESHOLD']:\n",
    "                                    texts.append(text); confs.append(conf)\n",
    "                        result.update({'extracted_text': ' '.join(texts),\n",
    "                                     'ocr_confidence': np.mean(confs) if confs else 0.0})\n",
    "\n",
    "                elif ocr_model == 'easyocr':\n",
    "                    ocr_result = self.ocr.readtext(np.array(img))\n",
    "                    texts, confs = [], []\n",
    "                    for detection in ocr_result:\n",
    "                        bbox, text, conf = detection\n",
    "                        if conf >= self.config['OCR_CONFIDENCE_THRESHOLD']:\n",
    "                            texts.append(text); confs.append(conf)\n",
    "                    result.update({'extracted_text': ' '.join(texts),\n",
    "                                 'ocr_confidence': np.mean(confs) if confs else 0.0})\n",
    "\n",
    "                elif ocr_model == 'tesseract':\n",
    "                    import pytesseract\n",
    "                    text = pytesseract.image_to_string(img, config='--psm 6')\n",
    "                    if text.strip():\n",
    "                        result.update({'extracted_text': text.strip(), 'ocr_confidence': 0.8})\n",
    "\n",
    "                elif ocr_model == 'trocr':\n",
    "                    pixel_values = self.ocr_processor(images=img, return_tensors=\"pt\").pixel_values\n",
    "                    generated_ids = self.ocr_model.generate(pixel_values)\n",
    "                    text = self.ocr_processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "                    if text.strip():\n",
    "                        result.update({'extracted_text': text.strip(), 'ocr_confidence': 0.9})\n",
    "\n",
    "            return result\n",
    "        except Exception as e:\n",
    "            return {'filename': os.path.basename(img_path), 'full_path': img_path,\n",
    "                   'extracted_text': '', 'ocr_confidence': 0.0, 'error': str(e)}\n",
    "\n",
    "    def analyze_text(self, text: str, filename: str) -> Dict[str, Any]:\n",
    "        prompt = f'''Analyze text from image '{filename}' for criminal evidence:\n",
    "Text: {text}\n",
    "Look for: weapons, drugs, threats, violence, financial crimes, personal info theft.\n",
    "Respond with JSON only:\n",
    "{{\"contains_incriminating\": true/false, \"risk_score\": 0.0-1.0,\n",
    "\"categories\": [\"weapons\",\"drugs\",\"threats\",\"financial_crimes\",\"violence\",\"personal_info\"],\n",
    "\"analysis\": \"explanation\", \"keywords\": [\"words\"], \"evidence_summary\": \"summary\"}}'''\n",
    "\n",
    "        try:\n",
    "            response = str(self.llm.invoke(prompt)).strip()\n",
    "            response = response.replace('```json', '').replace('```', '').strip()\n",
    "            start, end = response.find('{'), response.rfind('}') + 1\n",
    "            if start >= 0 and end > start:\n",
    "                parsed = json.loads(response[start:end])\n",
    "                return {k: parsed.get(k, v) for k, v in [\n",
    "                    ('contains_incriminating', False), ('risk_score', 0.0), ('categories', []),\n",
    "                    ('analysis', ''), ('keywords', []), ('evidence_summary', '')]}\n",
    "            else: return self._fallback_analysis(response, filename)\n",
    "        except: return self._fallback_analysis(response if 'response' in locals() else '', filename)\n",
    "\n",
    "    def _fallback_analysis(self, response: str, filename: str) -> Dict[str, Any]:\n",
    "        keywords = {'weapons': ['weapon','gun','knife','bomb'], 'drugs': ['drug','cocaine','meth'],\n",
    "                   'threats': ['threat','kill','attack'], 'financial_crimes': ['fraud','steal']}\n",
    "        found_cats, found_words, risk = [], [], 0.0\n",
    "        resp_lower = response.lower()\n",
    "        for cat, words in keywords.items():\n",
    "            for word in words:\n",
    "                if word in resp_lower: found_cats.append(cat); found_words.append(word); risk += 0.15\n",
    "        return {'contains_incriminating': risk > 0.3, 'risk_score': min(risk, 1.0),\n",
    "               'categories': list(set(found_cats)), 'analysis': f'Fallback analysis: {response[:100]}',\n",
    "               'keywords': found_words, 'evidence_summary': f'Found {len(found_words)} terms'}\n",
    "\n",
    "    def add_to_vectorstore(self, text: str, metadata: Dict[str, Any]):\n",
    "        try:\n",
    "            from langchain_core.documents import Document\n",
    "            chunks = self.text_splitter.split_text(text)\n",
    "            docs = [Document(page_content=chunk, metadata={**metadata, 'chunk_id': i})\n",
    "                   for i, chunk in enumerate(chunks)]\n",
    "            self.vectorstore.add_documents(docs); self.vectorstore.persist(); return True\n",
    "        except: return False\n",
    "\n",
    "    def process_gallery(self):\n",
    "        start_time = time.time()\n",
    "        gallery_path = Path(self.config['SUSPECTS_GALLERY_PATH'])\n",
    "        print(f\"üè† PROCESSING: {gallery_path} | Model: {self.config['LLM_MODEL']}\")\n",
    "\n",
    "        if not gallery_path.exists(): print(f\"‚ùå Path not found: {gallery_path}\"); return\n",
    "\n",
    "        exts = ['.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.webp']\n",
    "        files = [f for ext in exts for f in gallery_path.glob(f\"**/*{ext}\") + gallery_path.glob(f\"**/*{ext.upper()}\")]\n",
    "        total, processed, vector_stored, incriminating = len(files), 0, 0, 0\n",
    "\n",
    "        print(f\"üì∏ Found {total} images\")\n",
    "        if total == 0: print(\"‚ö†Ô∏è No images found!\"); return\n",
    "\n",
    "        for i, img_path in enumerate(files, 1):\n",
    "            filename = img_path.name\n",
    "            print(f\"[{i:3d}/{total}] ({i/total*100:5.1f}%) {filename[:40]}...\", end='')\n",
    "\n",
    "            # Skip if processed\n",
    "            if self.conn.execute(\"SELECT id FROM forensic_images WHERE filename = ?\", (filename,)).fetchone():\n",
    "                print(\" ‚è≠Ô∏è SKIP\"); continue\n",
    "\n",
    "            # Extract and analyze\n",
    "            ocr_result = self.extract_text(img_path)\n",
    "            if ocr_result.get('error'): print(\" ‚ùå ERROR\"); continue\n",
    "\n",
    "            text = ocr_result['extracted_text']\n",
    "            analysis = None\n",
    "            if text.strip():\n",
    "                analysis = self.analyze_text(text, filename)\n",
    "                metadata = {'filename': filename, 'full_path': str(img_path),\n",
    "                          'ocr_confidence': ocr_result['ocr_confidence']}\n",
    "                if self.add_to_vectorstore(text, metadata): vector_stored += 1\n",
    "\n",
    "            # Store in DB\n",
    "            risk = analysis['risk_score'] if analysis else 0.0\n",
    "            incrim = analysis['contains_incriminating'] if analysis else False\n",
    "            self.conn.execute('''INSERT OR REPLACE INTO forensic_images\n",
    "                (filename, full_path, extracted_text, ocr_confidence, local_analysis,\n",
    "                 risk_score, contains_incriminating, vector_stored) VALUES (?,?,?,?,?,?,?,?)''',\n",
    "                (filename, str(img_path), text, ocr_result['ocr_confidence'],\n",
    "                 json.dumps(analysis) if analysis else None, risk, incrim, vector_stored > 0))\n",
    "\n",
    "            if text.strip():\n",
    "                if incrim: incriminating += 1; print(f\" üö® INCRIMINATING ({risk:.2f})\")\n",
    "                else: print(\" ‚úÖ TEXT\")\n",
    "            else: print(\" ‚ö™ NO TEXT\")\n",
    "\n",
    "            processed += 1\n",
    "            if i % 10 == 0: self.conn.commit()\n",
    "\n",
    "        self.conn.commit()\n",
    "        print(f\"\\nüè† COMPLETE: {processed} processed, {vector_stored} vectorized, {incriminating} flagged, {time.time()-start_time:.1f}s\")\n",
    "\n",
    "    def investigate(self, query: str) -> Dict[str, Any]:\n",
    "        print(f\"üè† INVESTIGATING: '{query}'\")\n",
    "        try:\n",
    "            docs = self.vectorstore.similarity_search(query, k=5)\n",
    "            if not docs: return {'findings': [], 'summary': 'No evidence found', 'total_flagged': 0}\n",
    "\n",
    "            evidence, files = \"\", set()\n",
    "            for i, doc in enumerate(docs, 1):\n",
    "                filename = doc.metadata.get('filename', f'unknown_{i}')\n",
    "                files.add(filename)\n",
    "                evidence += f\"Evidence {i} - {filename}: {doc.page_content}\\n---\\n\"\n",
    "\n",
    "            prompt = f'''Forensic investigation: \"{query}\"\n",
    "Evidence: {evidence}\n",
    "Respond with JSON:\n",
    "{{\"findings\": [{{\"image_number\": 1, \"filename\": \"file.jpg\", \"matches_query\": true,\n",
    "\"risk_level\": \"high\", \"evidence_found\": \"desc\", \"relevant_text\": \"text\", \"confidence\": 0.8}}],\n",
    "\"summary\": \"summary\", \"total_flagged\": 2, \"highest_risk_image\": \"file.jpg\"}}'''\n",
    "\n",
    "            response = str(self.llm.invoke(prompt)).strip()\n",
    "            response = response.replace('```json', '').replace('```', '').strip()\n",
    "            start, end = response.find('{'), response.rfind('}') + 1\n",
    "\n",
    "            if start >= 0 and end > start:\n",
    "                results = json.loads(response[start:end])\n",
    "            else:\n",
    "                results = self._fallback_investigation(query, files)\n",
    "\n",
    "            # Store investigation\n",
    "            flagged = [f.get('filename', '') for f in results.get('findings', []) if f.get('matches_query')]\n",
    "            self.conn.execute('''INSERT INTO local_investigations\n",
    "                (query, results_json, flagged_images, model_used) VALUES (?,?,?,?)''',\n",
    "                (query, json.dumps(results), json.dumps(flagged), f\"{self.config['LLM_PROVIDER']}-{self.config['LLM_MODEL']}\"))\n",
    "            self.conn.commit()\n",
    "\n",
    "            print(f\"‚úÖ Found {results.get('total_flagged', 0)} matches\")\n",
    "            return results\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error: {e}\")\n",
    "            return {'findings': [], 'summary': f'Error: {e}', 'total_flagged': 0}\n",
    "\n",
    "    def _fallback_investigation(self, query: str, files: set) -> Dict[str, Any]:\n",
    "        findings = [{'image_number': i, 'filename': f, 'matches_query': True, 'risk_level': 'medium',\n",
    "                    'evidence_found': f'Related to: {query}', 'relevant_text': f'Matches: {query}', 'confidence': 0.7}\n",
    "                   for i, f in enumerate(list(files)[:5], 1)]\n",
    "        return {'findings': findings, 'summary': f'Fallback analysis for: {query}',\n",
    "               'total_flagged': len(findings), 'highest_risk_image': list(files)[0] if files else None}\n",
    "\n",
    "    def get_flagged(self, min_risk=0.3):\n",
    "        return self.conn.execute('''SELECT filename, full_path, extracted_text, risk_score,\n",
    "            local_analysis, ocr_confidence FROM forensic_images\n",
    "            WHERE contains_incriminating = 1 AND risk_score >= ? ORDER BY risk_score DESC''', (min_risk,)).fetchall()\n",
    "\n",
    "    def export_results(self, results: Dict[str, Any], query: str) -> str:\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        query_safe = query.replace(' ', '_')[:30]\n",
    "        output_path = Path(self.config['RESULTS_OUTPUT_PATH']) / f\"investigation_{query_safe}_{timestamp}\"\n",
    "        output_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        flagged = [f.get('filename', '') for f in results.get('findings', []) if f.get('matches_query')]\n",
    "        copied = []\n",
    "        for i, filename in enumerate(flagged, 1):\n",
    "            result = self.conn.execute(\"SELECT full_path FROM forensic_images WHERE filename = ?\", (filename,)).fetchone()\n",
    "            if result and Path(result[0]).exists():\n",
    "                dest = output_path / f\"{i:03d}_{filename}\"\n",
    "                shutil.copy2(result[0], dest); copied.append(str(dest))\n",
    "\n",
    "        # Save reports\n",
    "        report = {'query': query, 'timestamp': timestamp, 'model': f\"{self.config['LLM_PROVIDER']}-{self.config['LLM_MODEL']}\",\n",
    "                 'results': results, 'flagged_images': flagged, 'copied_files': copied}\n",
    "\n",
    "        with open(output_path / \"report.json\", 'w') as f: json.dump(report, f, indent=2)\n",
    "        with open(output_path / \"summary.txt\", 'w') as f:\n",
    "            f.write(f\"LOCAL FORENSIC REPORT\\nQuery: {query}\\nDate: {timestamp}\\n\")\n",
    "            f.write(f\"Model: {self.config['LLM_PROVIDER']}-{self.config['LLM_MODEL']}\\n\")\n",
    "            f.write(f\"Flagged: {len(flagged)}\\nSummary: {results.get('summary', 'N/A')}\\n\")\n",
    "\n",
    "        print(f\"üìã Exported to: {output_path}\")\n",
    "        return str(output_path)\n",
    "\n",
    "    def close(self):\n",
    "        if hasattr(self, 'conn') and self.conn: self.conn.close()\n",
    "\n",
    "# Compact GUI\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def create_compact_gui():\n",
    "    # Print debug info\n",
    "    print(\"üîß Creating GUI with OCR selector...\")\n",
    "    print(f\"Available OCR models: {list(OCR_MODELS.keys())}\")\n",
    "\n",
    "    # OCR Selector Widget - Make sure it's created first\n",
    "    ocr_selector = widgets.Dropdown(\n",
    "        options=[(f\"{info['name']} - {info['desc']}\", key) for key, info in OCR_MODELS.items()],\n",
    "        value=CONFIG['OCR_MODEL'],\n",
    "        description='OCR Engine:',\n",
    "        style={'description_width': 'initial'},\n",
    "        layout=widgets.Layout(width='500px')\n",
    "    )\n",
    "\n",
    "    # Debug: Print OCR selector options\n",
    "    print(f\"OCR selector options: {ocr_selector.options}\")\n",
    "    print(f\"OCR selector value: {ocr_selector.value}\")\n",
    "\n",
    "    # LLM Widgets\n",
    "    llm_provider = widgets.Dropdown(\n",
    "        options=[('Ollama', 'ollama'), ('Transformers', 'transformers')],\n",
    "        value=CONFIG['LLM_PROVIDER'],\n",
    "        description='LLM Provider:',\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "\n",
    "    llm_model = widgets.Text(\n",
    "        value=CONFIG['LLM_MODEL'],\n",
    "        description='LLM Model:',\n",
    "        style={'description_width': 'initial'},\n",
    "        layout=widgets.Layout(width='300px')\n",
    "    )\n",
    "\n",
    "    # Other widgets\n",
    "    gallery_path = widgets.Text(\n",
    "        value=CONFIG['SUSPECTS_GALLERY_PATH'],\n",
    "        description='Gallery Path:',\n",
    "        style={'description_width': 'initial'},\n",
    "        layout=widgets.Layout(width='400px')\n",
    "    )\n",
    "\n",
    "    query_input = widgets.Textarea(\n",
    "        value='Find weapons or violence mentions',\n",
    "        description='Investigation Query:',\n",
    "        style={'description_width': 'initial'},\n",
    "        layout=widgets.Layout(width='500px', height='60px')\n",
    "    )\n",
    "\n",
    "    confidence_slider = widgets.FloatSlider(\n",
    "        value=CONFIG['OCR_CONFIDENCE_THRESHOLD'],\n",
    "        min=0.1, max=0.9, step=0.05,\n",
    "        description='OCR Confidence:',\n",
    "        style={'description_width': 'initial'},\n",
    "        readout_format='.2f'\n",
    "    )\n",
    "\n",
    "    risk_slider = widgets.FloatSlider(\n",
    "        value=0.3,\n",
    "        min=0.1, max=1.0, step=0.1,\n",
    "        description='Risk Threshold:',\n",
    "        style={'description_width': 'initial'},\n",
    "        readout_format='.1f'\n",
    "    )\n",
    "\n",
    "    # Quick queries\n",
    "    quick_queries = [\"Find weapons\", \"Look for drugs\", \"Financial crimes\", \"Personal info theft\", \"Threats\", \"Illegal coordination\"]\n",
    "    quick_btns = [widgets.Button(description=q[:20], tooltip=q, layout=widgets.Layout(width='180px', margin='2px')) for q in quick_queries]\n",
    "\n",
    "    # Action buttons\n",
    "    test_btn = widgets.Button(description='üîç Test Setup', button_style='info', layout=widgets.Layout(width='120px'))\n",
    "    process_btn = widgets.Button(description='üìÅ Process', button_style='primary', layout=widgets.Layout(width='120px'))\n",
    "    investigate_btn = widgets.Button(description='ü§ñ Investigate', button_style='success', layout=widgets.Layout(width='120px'))\n",
    "    flagged_btn = widgets.Button(description='üö® Flagged', button_style='warning', layout=widgets.Layout(width='120px'))\n",
    "    export_btn = widgets.Button(description='üìã Export', button_style='success', layout=widgets.Layout(width='120px'), disabled=True)\n",
    "    clear_btn = widgets.Button(description='üóëÔ∏è Clear', layout=widgets.Layout(width='120px'))\n",
    "\n",
    "    status_label = widgets.HTML(value=\"<b>Status:</b> Ready\")\n",
    "    progress_bar = widgets.IntProgress(value=0, min=0, max=100, layout=widgets.Layout(width='400px'))\n",
    "    output_area = widgets.Output()\n",
    "\n",
    "    # State\n",
    "    current_system = None\n",
    "    current_results = None\n",
    "\n",
    "    def update_status(msg, progress=None):\n",
    "        status_label.value = f\"<b>Status:</b> {msg}\"\n",
    "        if progress is not None: progress_bar.value = progress\n",
    "\n",
    "    def init_system():\n",
    "        nonlocal current_system\n",
    "        try:\n",
    "            config = CONFIG.copy()\n",
    "            config.update({'OCR_MODEL': ocr_selector.value, 'LLM_PROVIDER': llm_provider.value, 'LLM_MODEL': llm_model.value,\n",
    "                          'SUSPECTS_GALLERY_PATH': gallery_path.value, 'OCR_CONFIDENCE_THRESHOLD': confidence_slider.value})\n",
    "            current_system = CompactForensicSystem(config)\n",
    "            return True\n",
    "        except Exception as e: print(f\"‚ùå Init error: {e}\"); return False\n",
    "\n",
    "    # Button handlers\n",
    "    def on_quick_query(query):\n",
    "        def handler(b): query_input.value = query\n",
    "        return handler\n",
    "\n",
    "    for i, btn in enumerate(quick_btns): btn.on_click(on_quick_query(quick_queries[i]))\n",
    "\n",
    "    def on_test(b):\n",
    "        with output_area:\n",
    "            clear_output(wait=True)\n",
    "            update_status(\"Testing setup...\", 20)\n",
    "            print(\"üîç TESTING LOCAL SETUP\")\n",
    "            print(\"=\"*40)\n",
    "\n",
    "            # Test OCR first\n",
    "            print(f\"Testing OCR: {ocr_selector.value}\")\n",
    "            ocr_info = OCR_MODELS.get(ocr_selector.value, {})\n",
    "            print(f\"Purpose: {ocr_info.get('strengths', 'General OCR')}\")\n",
    "\n",
    "            try:\n",
    "                if ocr_selector.value == 'paddleocr':\n",
    "                    import paddleocr; print(\"‚úÖ PaddleOCR available\")\n",
    "                elif ocr_selector.value == 'easyocr':\n",
    "                    import easyocr; print(\"‚úÖ EasyOCR available\")\n",
    "                elif ocr_selector.value == 'tesseract':\n",
    "                    import pytesseract; print(\"‚úÖ Tesseract available\")\n",
    "                elif ocr_selector.value == 'trocr':\n",
    "                    import transformers; print(\"‚úÖ TrOCR (Transformers) available\")\n",
    "            except ImportError as e: print(f\"‚ùå {ocr_selector.value} not found: {e}\")\n",
    "\n",
    "            # Test other dependencies\n",
    "            deps = [('paddleocr', 'PaddleOCR'), ('langchain', 'LangChain'), ('chromadb', 'ChromaDB'), ('sentence_transformers', 'Transformers')]\n",
    "            for dep, name in deps:\n",
    "                try: __import__(dep.replace('-', '_')); print(f\"‚úÖ {name}\")\n",
    "                except ImportError: print(f\"‚ùå {name} not found\")\n",
    "\n",
    "            # Test Ollama\n",
    "            if llm_provider.value == 'ollama':\n",
    "                update_status(\"Testing Ollama...\", 60)\n",
    "                try:\n",
    "                    import requests\n",
    "                    r = requests.get(\"http://localhost:11434/api/tags\", timeout=5)\n",
    "                    if r.status_code == 200:\n",
    "                        models = [m['name'] for m in r.json().get('models', [])]\n",
    "                        print(f\"‚úÖ Ollama: {models}\")\n",
    "                        if llm_model.value in models: print(f\"‚úÖ Model '{llm_model.value}' ready\")\n",
    "                        else: print(f\"‚ö†Ô∏è Model '{llm_model.value}' not found. Install: ollama pull {llm_model.value}\")\n",
    "                    else: print(\"‚ùå Ollama not responding\")\n",
    "                except: print(\"‚ùå Ollama connection failed. Start: ollama serve\")\n",
    "\n",
    "            update_status(\"Testing system init...\", 80)\n",
    "            if init_system(): print(\"‚úÖ System ready\"); update_status(\"Setup complete!\", 100)\n",
    "            else: print(\"‚ùå System init failed\"); update_status(\"Setup failed\", 0)\n",
    "\n",
    "    def on_process(b):\n",
    "        with output_area:\n",
    "            clear_output(wait=True)\n",
    "            update_status(\"Processing gallery...\", 20)\n",
    "            if not init_system(): update_status(\"Init failed\", 0); return\n",
    "\n",
    "            print(f\"üè† PROCESSING | OCR: {ocr_selector.value} | LLM: {llm_provider.value}-{llm_model.value}\")\n",
    "            try:\n",
    "                current_system.process_gallery()\n",
    "                update_status(\"Processing complete!\", 100)\n",
    "                flagged = current_system.get_flagged(risk_slider.value)\n",
    "                if flagged: print(f\"\\nüö® FLAGGED: {len(flagged)} images above risk {risk_slider.value}\")\n",
    "                else: print(\"\\n‚úÖ No high-risk content detected\")\n",
    "            except Exception as e: update_status(\"Processing error\", 0); print(f\"‚ùå Error: {e}\")\n",
    "\n",
    "    def on_investigate(b):\n",
    "        nonlocal current_results\n",
    "        with output_area:\n",
    "            clear_output(wait=True)\n",
    "            if not current_system and not init_system(): print(\"‚ùå System not ready\"); return\n",
    "\n",
    "            query = query_input.value.strip()\n",
    "            if not query: print(\"‚ö†Ô∏è Enter investigation query\"); return\n",
    "\n",
    "            update_status(\"Investigating...\", 50)\n",
    "            print(f\"üè† INVESTIGATING: '{query}' | Model: {llm_model.value}\")\n",
    "            try:\n",
    "                current_results = current_system.investigate(query)\n",
    "                if current_results.get('total_flagged', 0) > 0:\n",
    "                    update_status(f\"Found {current_results['total_flagged']} matches\", 100)\n",
    "                    export_btn.disabled = False\n",
    "                    print(f\"üìä Summary: {current_results.get('summary', 'N/A')}\")\n",
    "                    print(\"üö® FLAGGED:\")\n",
    "                    for f in current_results.get('findings', []):\n",
    "                        if f.get('matches_query'):\n",
    "                            print(f\"  {f['risk_level'].upper()}: {f['filename']} - {f['evidence_found']}\")\n",
    "\n",
    "                    # Display images\n",
    "                    flagged_files = [f['filename'] for f in current_results.get('findings', []) if f.get('matches_query')]\n",
    "                    if flagged_files: display_flagged_images(flagged_files[:6], current_system)\n",
    "                else:\n",
    "                    update_status(\"No matches\", 100); export_btn.disabled = True\n",
    "                    print(\"‚ùå No matches. Try different terms or lower risk threshold.\")\n",
    "            except Exception as e: update_status(\"Investigation error\", 0); print(f\"‚ùå Error: {e}\")\n",
    "\n",
    "    def on_flagged(b):\n",
    "        with output_area:\n",
    "            clear_output(wait=True)\n",
    "            if not current_system and not init_system(): print(\"‚ùå System not ready\"); return\n",
    "\n",
    "            update_status(\"Loading flagged images...\", 50)\n",
    "            try:\n",
    "                flagged = current_system.get_flagged(risk_slider.value)\n",
    "                if flagged:\n",
    "                    print(f\"üö® FLAGGED IMAGES (Risk ‚â• {risk_slider.value})\")\n",
    "                    for i, (filename, _, text, risk, analysis, conf) in enumerate(flagged, 1):\n",
    "                        level = \"CRITICAL\" if risk > 0.8 else \"HIGH\" if risk > 0.6 else \"MEDIUM\" if risk > 0.3 else \"LOW\"\n",
    "                        print(f\"{i}. {filename} | {level} ({risk:.3f}) | OCR: {conf:.3f}\")\n",
    "                        print(f\"   Text: {text[:100]}...\")\n",
    "                        if analysis:\n",
    "                            try:\n",
    "                                data = json.loads(analysis)\n",
    "                                cats = data.get('categories', [])\n",
    "                                if cats: print(f\"   Categories: {', '.join(cats)}\")\n",
    "                            except: pass\n",
    "                        print()\n",
    "\n",
    "                    files = [r[0] for r in flagged[:6]]\n",
    "                    display_flagged_images(files, current_system)\n",
    "                    update_status(f\"Showing {len(flagged)} flagged images\", 100)\n",
    "                else:\n",
    "                    print(f\"‚úÖ No images flagged above risk {risk_slider.value}\")\n",
    "                    update_status(\"No flagged images\", 100)\n",
    "            except Exception as e: update_status(\"Error loading flagged\", 0); print(f\"‚ùå Error: {e}\")\n",
    "\n",
    "    def on_export(b):\n",
    "        with output_area:\n",
    "            if not current_results: print(\"‚ö†Ô∏è No results to export\"); return\n",
    "            try:\n",
    "                update_status(\"Exporting...\", 50)\n",
    "                path = current_system.export_results(current_results, query_input.value or \"investigation\")\n",
    "                update_status(\"Export complete!\", 100)\n",
    "                print(f\"‚úÖ Results exported to: {path}\")\n",
    "            except Exception as e: update_status(\"Export error\", 0); print(f\"‚ùå Error: {e}\")\n",
    "\n",
    "    def on_clear(b):\n",
    "        nonlocal current_results\n",
    "        current_results = None; export_btn.disabled = True\n",
    "        with output_area: clear_output(); update_status(\"Cleared\", 0); print(\"üóëÔ∏è Cleared\")\n",
    "\n",
    "    # Connect events\n",
    "    test_btn.on_click(on_test); process_btn.on_click(on_process); investigate_btn.on_click(on_investigate)\n",
    "    flagged_btn.on_click(on_flagged); export_btn.on_click(on_export); clear_btn.on_click(on_clear)\n",
    "\n",
    "    # Layout\n",
    "    quick_grid = widgets.GridBox(quick_btns, layout=widgets.Layout(grid_template_columns='repeat(3, 1fr)', grid_gap='5px'))\n",
    "    controls = widgets.VBox([\n",
    "        widgets.HTML(\"<h3>üè† Compact Local Forensic System</h3>\"),\n",
    "        widgets.HBox([llm_provider, llm_model]), gallery_path, query_input,\n",
    "        widgets.HTML(\"<b>Quick Queries:</b>\"), quick_grid,\n",
    "        widgets.HBox([confidence_slider, risk_slider]),\n",
    "        widgets.HBox([test_btn, process_btn, investigate_btn, flagged_btn, export_btn, clear_btn]),\n",
    "        status_label, progress_bar, widgets.HTML(\"<hr>\")\n",
    "    ])\n",
    "\n",
    "    return widgets.VBox([controls, output_area])\n",
    "\n",
    "    for i, filename in enumerate(filenames[:num]):\n",
    "        ax = axes[i] if num > 1 else axes\n",
    "        try:\n",
    "            result = system.conn.execute('''SELECT full_path, extracted_text, risk_score, local_analysis\n",
    "                FROM forensic_images WHERE filename = ?''', (filename,)).fetchone()\n",
    "            if not result: ax.text(0.5, 0.5, f\"Not found\\n{filename}\", ha='center', va='center', transform=ax.transAxes); ax.axis('off'); continue\n",
    "\n",
    "            full_path, text, risk, analysis = result\n",
    "            try: img = plt.imread(full_path); ax.imshow(img)\n",
    "            except: ax.text(0.5, 0.5, f\"Load error\\n{filename}\", ha='center', va='center', transform=ax.transAxes); ax.axis('off'); continue\n",
    "\n",
    "            # Risk level and color\n",
    "            level, color = (\"CRITICAL\", \"red\") if risk > 0.8 else (\"HIGH\", \"orange\") if risk > 0.6 else (\"MEDIUM\", \"yellow\") if risk > 0.3 else (\"LOW\", \"green\")\n",
    "            ax.set_title(f\"{filename}\\n{level}: {risk:.2f}\", fontsize=10, color=color, fontweight='bold')\n",
    "\n",
    "            # Text overlay\n",
    "            text_preview = text[:80] if text else \"No text\"\n",
    "            ax.text(0.02, 0.98, f\"Text: {text_preview}...\", transform=ax.transAxes, fontsize=8,\n",
    "                   verticalalignment='top', bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=color, alpha=0.7))\n",
    "\n",
    "            # Categories\n",
    "            if analysis:\n",
    "                try:\n",
    "                    data = json.loads(analysis)\n",
    "                    cats = data.get('categories', [])\n",
    "                    if cats: ax.text(0.02, 0.02, f\"Cat: {', '.join(cats[:2])}\", transform=ax.transAxes, fontsize=7,\n",
    "                                   verticalalignment='bottom', bbox=dict(boxstyle=\"round,pad=0.2\", facecolor=\"lightblue\", alpha=0.8))\n",
    "                except: pass\n",
    "            ax.axis('off')\n",
    "        except Exception as e: ax.text(0.5, 0.5, f\"Error\\n{filename}\\n{str(e)[:30]}\", ha='center', va='center', transform=ax.transAxes); ax.axis('off')\n",
    "\n",
    "    for j in range(num, len(axes)): axes[j].axis('off')\n",
    "    plt.tight_layout(); plt.suptitle('üè† Local Forensic Results', fontsize=14, y=1.02); plt.show()\n",
    "\n",
    "# Quick functions\n",
    "def quick_setup():\n",
    "    print(\"üè† QUICK SETUP CHECK\")\n",
    "    deps = ['paddleocr', 'langchain', 'chromadb', 'sentence_transformers']\n",
    "    for dep in deps:\n",
    "        try: __import__(dep.replace('-', '_')); print(f\"‚úÖ {dep}\")\n",
    "        except ImportError: print(f\"‚ùå {dep} - pip install {dep}\")\n",
    "\n",
    "    try:\n",
    "        import requests\n",
    "        r = requests.get(\"http://localhost:11434/api/tags\", timeout=5)\n",
    "        if r.status_code == 200:\n",
    "            models = [m['name'] for m in r.json().get('models', [])]\n",
    "            print(f\"‚úÖ Ollama: {models}\")\n",
    "            if 'llama3.2:3b' in models: print(\"‚úÖ Recommended model ready\")\n",
    "            else: print(\"‚ö†Ô∏è Install: ollama pull llama3.2:3b\")\n",
    "        else: print(\"‚ùå Ollama not responding\")\n",
    "    except: print(\"‚ùå Ollama not available - Start: ollama serve\")\n",
    "\n",
    "def quick_investigate(query: str, gallery_path: str = './suspects_gallery'):\n",
    "    print(f\"üè† Quick Investigation: '{query}' | üîí 100% Local\")\n",
    "    try:\n",
    "        config = CONFIG.copy(); config['SUSPECTS_GALLERY_PATH'] = gallery_path\n",
    "        system = CompactForensicSystem(config)\n",
    "\n",
    "        # Check if processed\n",
    "        count = system.conn.execute(\"SELECT COUNT(*) FROM forensic_images WHERE vector_stored = 1\").fetchone()[0]\n",
    "        if count == 0: print(\"üìÅ Processing gallery first...\"); system.process_gallery()\n",
    "\n",
    "        results = system.investigate(query)\n",
    "        if results.get('total_flagged', 0) > 0:\n",
    "            path = system.export_results(results, query)\n",
    "            print(f\"üìã Exported to: {path}\")\n",
    "        system.close(); return results\n",
    "    except Exception as e: print(f\"‚ùå Error: {e}\"); return None\n",
    "\n",
    "# Display interface with debugging\n",
    "print(\"üè† Creating Compact Local Forensic Interface...\")\n",
    "print(\"üîß Debug: OCR models available:\", list(OCR_MODELS.keys()))\n",
    "\n",
    "compact_interface = create_compact_gui()\n",
    "\n",
    "# Verify the interface was created properly\n",
    "print(\"‚úÖ GUI created successfully\")\n",
    "print(\"üîç OCR selector should be visible at the top\")\n",
    "\n",
    "display(compact_interface)\n",
    "\n",
    "print(f\"\\nüè† COMPACT LOCAL FORENSIC SYSTEM READY!\")\n",
    "print(\"=\"*50)\n",
    "print(\"üîí PRIVACY: 100% local, no API calls, offline capable\")\n",
    "print(\"ü§ñ COMPONENTS: Multi-OCR + Ollama/Transformers + ChromaDB + SQLite\")\n",
    "print(\"üìù OCR OPTIONS: PaddleOCR, EasyOCR, Tesseract, TrOCR\")\n",
    "print(\"üöÄ SETUP: ollama serve ‚Üí ollama pull llama3.2:3b\")\n",
    "print(\"üí° QUICK: quick_setup() | quick_investigate('find weapons')\")\n",
    "print(\"=\"*50)\n",
    "print(\"\\nüîç OCR SELECTION GUIDE:\")\n",
    "print(\"‚Ä¢ PaddleOCR: Best overall, Asian languages, handwriting\")\n",
    "print(\"‚Ä¢ EasyOCR: European languages, clean text\")\n",
    "print(\"‚Ä¢ Tesseract: Printed documents, very stable\")\n",
    "print(\"‚Ä¢ TrOCR: Handwritten notes, degraded images\")\n",
    "print(\"=\"*50)"
   ],
   "id": "acb9398e012c66cb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üè† LOCAL FORENSIC SYSTEM | LLM: ollama-llama3.2:3b | üîí 100% Private\n",
      "‚úÖ paddleocr\n",
      "‚úÖ langchain\n",
      "‚úÖ chromadb\n",
      "‚úÖ sentence_transformers\n",
      "‚úÖ Ollama: ['deepseek-r1:1.5b', 'llama3.2:latest']\n",
      "üè† Creating Compact Local Forensic Interface...\n",
      "üîß Debug: OCR models available: ['paddleocr', 'easyocr', 'tesseract', 'trocr']\n",
      "üîß Creating GUI with OCR selector...\n",
      "Available OCR models: ['paddleocr', 'easyocr', 'tesseract', 'trocr']\n",
      "OCR selector options: (('PaddleOCR - Best overall, 80+ languages, handwriting capable', 'paddleocr'), ('EasyOCR - Good for European languages, simple setup', 'easyocr'), ('Tesseract - Classic OCR, best for clean printed text', 'tesseract'), ('TrOCR (Transformers) - AI-based, excellent for handwriting', 'trocr'))\n",
      "OCR selector value: paddleocr\n",
      "‚úÖ GUI created successfully\n",
      "üîç OCR selector should be visible at the top\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VBox(children=(VBox(children=(HTML(value='<h3>üè† Compact Local Forensic System</h3>'), HBox(children=(Dropdown(‚Ä¶"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8d02c0c33b9346179780b7062fbeab46"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üè† COMPACT LOCAL FORENSIC SYSTEM READY!\n",
      "==================================================\n",
      "üîí PRIVACY: 100% local, no API calls, offline capable\n",
      "ü§ñ COMPONENTS: Multi-OCR + Ollama/Transformers + ChromaDB + SQLite\n",
      "üìù OCR OPTIONS: PaddleOCR, EasyOCR, Tesseract, TrOCR\n",
      "üöÄ SETUP: ollama serve ‚Üí ollama pull llama3.2:3b\n",
      "üí° QUICK: quick_setup() | quick_investigate('find weapons')\n",
      "==================================================\n",
      "\n",
      "üîç OCR SELECTION GUIDE:\n",
      "‚Ä¢ PaddleOCR: Best overall, Asian languages, handwriting\n",
      "‚Ä¢ EasyOCR: European languages, clean text\n",
      "‚Ä¢ Tesseract: Printed documents, very stable\n",
      "‚Ä¢ TrOCR: Handwritten notes, degraded images\n",
      "==================================================\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-25T17:31:55.212972Z",
     "start_time": "2025-07-25T17:31:52.930187Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Compact Local Forensic OCR System with GUI\n",
    "import os, json, sqlite3, shutil, warnings, time\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from typing import List, Dict, Any, Optional\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Compact config with OCR options\n",
    "CONFIG = {\n",
    "    'OCR_MODEL': 'paddleocr', 'OCR_CONFIDENCE_THRESHOLD': 0.6,\n",
    "    'LLM_PROVIDER': 'ollama', 'LLM_MODEL': 'llama3.2:3b', 'LLM_BASE_URL': 'http://localhost:11434',\n",
    "    'LLM_TEMPERATURE': 0.1, 'LLM_MAX_TOKENS': 1000,\n",
    "    'EMBEDDING_PROVIDER': 'huggingface', 'EMBEDDING_MODEL': 'sentence-transformers/all-MiniLM-L6-v2',\n",
    "    'VECTOR_STORE_PATH': './forensic_vectorstore', 'CHUNK_SIZE': 500, 'CHUNK_OVERLAP': 50,\n",
    "    'SUSPECTS_GALLERY_PATH': '../../', 'DATABASE_PATH': './forensic_analysis_db',\n",
    "    'RESULTS_OUTPUT_PATH': './forensic_results', 'BATCH_SIZE': 4, 'MAX_RESULTS_DISPLAY': 10,\n",
    "}\n",
    "\n",
    "# OCR model options for different evidence types\n",
    "OCR_MODELS = {\n",
    "    'paddleocr': {'name': 'PaddleOCR', 'desc': 'Best overall, 80+ languages, handwriting capable', 'strengths': 'Asian text, complex layouts'},\n",
    "    'easyocr': {'name': 'EasyOCR', 'desc': 'Good for European languages, simple setup', 'strengths': 'European text, clean images'},\n",
    "    'tesseract': {'name': 'Tesseract', 'desc': 'Classic OCR, best for clean printed text', 'strengths': 'Printed documents, stable'},\n",
    "    'trocr': {'name': 'TrOCR (Transformers)', 'desc': 'AI-based, excellent for handwriting', 'strengths': 'Handwritten notes, degraded images'}\n",
    "}\n",
    "\n",
    "print(f\"üè† LOCAL FORENSIC SYSTEM | LLM: {CONFIG['LLM_PROVIDER']}-{CONFIG['LLM_MODEL']} | üîí 100% Private\")\n",
    "\n",
    "# Quick dependency check\n",
    "def check_deps():\n",
    "    deps = ['paddleocr', 'langchain', 'chromadb', 'sentence_transformers']\n",
    "    for dep in deps:\n",
    "        try: __import__(dep.replace('-', '_')); print(f\"‚úÖ {dep}\")\n",
    "        except ImportError: print(f\"‚ùå {dep} - Install: pip install {dep}\")\n",
    "\n",
    "def check_ollama():\n",
    "    try:\n",
    "        import requests\n",
    "        r = requests.get(f\"{CONFIG['LLM_BASE_URL']}/api/tags\", timeout=5)\n",
    "        if r.status_code == 200:\n",
    "            models = [m['name'] for m in r.json().get('models', [])]\n",
    "            print(f\"‚úÖ Ollama: {models}\")\n",
    "            return CONFIG['LLM_MODEL'] in models\n",
    "        return False\n",
    "    except: print(\"‚ùå Ollama not running\"); return False\n",
    "\n",
    "check_deps()\n",
    "ollama_ready = check_ollama() if CONFIG['LLM_PROVIDER'] == 'ollama' else True\n",
    "\n",
    "# Compact forensic system\n",
    "class CompactForensicSystem:\n",
    "    def __init__(self, config=None):\n",
    "        self.config = config or CONFIG.copy()\n",
    "        self._setup_dirs()\n",
    "        self._init_db()\n",
    "        self._init_ocr()\n",
    "        self._init_llm()\n",
    "\n",
    "    def _setup_dirs(self):\n",
    "        for k in ['SUSPECTS_GALLERY_PATH', 'DATABASE_PATH', 'RESULTS_OUTPUT_PATH', 'VECTOR_STORE_PATH']:\n",
    "            os.makedirs(self.config[k], exist_ok=True)\n",
    "\n",
    "    def _init_db(self):\n",
    "        db_path = os.path.join(self.config['DATABASE_PATH'], 'forensic.db')\n",
    "        self.conn = sqlite3.connect(db_path)\n",
    "        self.conn.execute('''CREATE TABLE IF NOT EXISTS forensic_images (\n",
    "            id INTEGER PRIMARY KEY, filename TEXT UNIQUE, full_path TEXT, extracted_text TEXT,\n",
    "            ocr_confidence REAL, processed_date TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
    "            local_analysis TEXT, risk_score REAL, contains_incriminating BOOLEAN DEFAULT 0,\n",
    "            vector_stored BOOLEAN DEFAULT 0)''')\n",
    "        self.conn.execute('''CREATE TABLE IF NOT EXISTS local_investigations (\n",
    "            id INTEGER PRIMARY KEY, query TEXT, investigation_date TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
    "            results_json TEXT, flagged_images TEXT, model_used TEXT, processing_time REAL)''')\n",
    "        self.conn.commit()\n",
    "\n",
    "    def _init_ocr(self):\n",
    "        try:\n",
    "            ocr_model = self.config['OCR_MODEL']\n",
    "            if ocr_model == 'paddleocr':\n",
    "                from paddleocr import PaddleOCR\n",
    "                self.ocr = PaddleOCR(use_textline_orientation=True, lang='en', show_log=False)\n",
    "            elif ocr_model == 'easyocr':\n",
    "                import easyocr\n",
    "                self.ocr = easyocr.Reader(['en'], gpu=False)\n",
    "            elif ocr_model == 'tesseract':\n",
    "                import pytesseract\n",
    "                self.ocr = pytesseract\n",
    "            elif ocr_model == 'trocr':\n",
    "                from transformers import TrOCRProcessor, VisionEncoderDecoderModel\n",
    "                self.ocr_processor = TrOCRProcessor.from_pretrained('microsoft/trocr-base-printed')\n",
    "                self.ocr_model = VisionEncoderDecoderModel.from_pretrained('microsoft/trocr-base-printed')\n",
    "                self.ocr = 'trocr'\n",
    "            print(f\"‚úÖ {OCR_MODELS[ocr_model]['name']} ready\")\n",
    "        except Exception as e: print(f\"‚ùå OCR error: {e}\"); self.ocr = None\n",
    "\n",
    "    def _init_llm(self):\n",
    "        try:\n",
    "            if self.config['LLM_PROVIDER'] == 'ollama':\n",
    "                from langchain_community.llms import Ollama\n",
    "                self.llm = Ollama(model=self.config['LLM_MODEL'], base_url=self.config['LLM_BASE_URL'],\n",
    "                                temperature=self.config['LLM_TEMPERATURE'])\n",
    "            elif self.config['LLM_PROVIDER'] == 'transformers':\n",
    "                from langchain_community.llms import HuggingFacePipeline\n",
    "                from transformers import pipeline\n",
    "                pipe = pipeline(\"text-generation\", model=self.config['LLM_MODEL'],\n",
    "                              max_new_tokens=self.config['LLM_MAX_TOKENS'])\n",
    "                self.llm = HuggingFacePipeline(pipeline=pipe)\n",
    "\n",
    "            from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "            from langchain_community.vectorstores import Chroma\n",
    "            from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "            self.embeddings = HuggingFaceEmbeddings(model_name=self.config['EMBEDDING_MODEL'],\n",
    "                                                  model_kwargs={'device': 'cpu'})\n",
    "            self.vectorstore = Chroma(persist_directory=self.config['VECTOR_STORE_PATH'],\n",
    "                                    embedding_function=self.embeddings)\n",
    "            self.text_splitter = RecursiveCharacterTextSplitter(chunk_size=self.config['CHUNK_SIZE'],\n",
    "                                                              chunk_overlap=self.config['CHUNK_OVERLAP'])\n",
    "            print(\"‚úÖ LangChain ready\")\n",
    "        except Exception as e: print(f\"‚ùå LLM error: {e}\")\n",
    "\n",
    "    def extract_text(self, img_path: str) -> Dict[str, Any]:\n",
    "        try:\n",
    "            img = Image.open(img_path).convert(\"RGB\")\n",
    "            result = {'filename': os.path.basename(img_path), 'full_path': img_path,\n",
    "                     'extracted_text': '', 'ocr_confidence': 0.0, 'error': None}\n",
    "\n",
    "            if self.ocr:\n",
    "                ocr_model = self.config['OCR_MODEL']\n",
    "\n",
    "                if ocr_model == 'paddleocr':\n",
    "                    ocr_result = self.ocr.ocr(np.array(img), cls=True)\n",
    "                    if ocr_result and ocr_result[0]:\n",
    "                        texts, confs = [], []\n",
    "                        for line in ocr_result:\n",
    "                            for detection in line:\n",
    "                                bbox, (text, conf) = detection\n",
    "                                if conf >= self.config['OCR_CONFIDENCE_THRESHOLD']:\n",
    "                                    texts.append(text); confs.append(conf)\n",
    "                        result.update({'extracted_text': ' '.join(texts),\n",
    "                                     'ocr_confidence': np.mean(confs) if confs else 0.0})\n",
    "\n",
    "                elif ocr_model == 'easyocr':\n",
    "                    ocr_result = self.ocr.readtext(np.array(img))\n",
    "                    texts, confs = [], []\n",
    "                    for detection in ocr_result:\n",
    "                        bbox, text, conf = detection\n",
    "                        if conf >= self.config['OCR_CONFIDENCE_THRESHOLD']:\n",
    "                            texts.append(text); confs.append(conf)\n",
    "                    result.update({'extracted_text': ' '.join(texts),\n",
    "                                 'ocr_confidence': np.mean(confs) if confs else 0.0})\n",
    "\n",
    "                elif ocr_model == 'tesseract':\n",
    "                    import pytesseract\n",
    "                    text = pytesseract.image_to_string(img, config='--psm 6')\n",
    "                    if text.strip():\n",
    "                        result.update({'extracted_text': text.strip(), 'ocr_confidence': 0.8})\n",
    "\n",
    "                elif ocr_model == 'trocr':\n",
    "                    pixel_values = self.ocr_processor(images=img, return_tensors=\"pt\").pixel_values\n",
    "                    generated_ids = self.ocr_model.generate(pixel_values)\n",
    "                    text = self.ocr_processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "                    if text.strip():\n",
    "                        result.update({'extracted_text': text.strip(), 'ocr_confidence': 0.9})\n",
    "\n",
    "            return result\n",
    "        except Exception as e:\n",
    "            return {'filename': os.path.basename(img_path), 'full_path': img_path,\n",
    "                   'extracted_text': '', 'ocr_confidence': 0.0, 'error': str(e)}\n",
    "\n",
    "    def analyze_text(self, text: str, filename: str) -> Dict[str, Any]:\n",
    "        prompt = f'''Analyze text from image '{filename}' for criminal evidence:\n",
    "Text: {text}\n",
    "Look for: weapons, drugs, threats, violence, financial crimes, personal info theft.\n",
    "Respond with JSON only:\n",
    "{{\"contains_incriminating\": true/false, \"risk_score\": 0.0-1.0,\n",
    "\"categories\": [\"weapons\",\"drugs\",\"threats\",\"financial_crimes\",\"violence\",\"personal_info\"],\n",
    "\"analysis\": \"explanation\", \"keywords\": [\"words\"], \"evidence_summary\": \"summary\"}}'''\n",
    "\n",
    "        try:\n",
    "            response = str(self.llm.invoke(prompt)).strip()\n",
    "            response = response.replace('```json', '').replace('```', '').strip()\n",
    "            start, end = response.find('{'), response.rfind('}') + 1\n",
    "            if start >= 0 and end > start:\n",
    "                parsed = json.loads(response[start:end])\n",
    "                return {k: parsed.get(k, v) for k, v in [\n",
    "                    ('contains_incriminating', False), ('risk_score', 0.0), ('categories', []),\n",
    "                    ('analysis', ''), ('keywords', []), ('evidence_summary', '')]}\n",
    "            else: return self._fallback_analysis(response, filename)\n",
    "        except: return self._fallback_analysis(response if 'response' in locals() else '', filename)\n",
    "\n",
    "    def _fallback_analysis(self, response: str, filename: str) -> Dict[str, Any]:\n",
    "        keywords = {'weapons': ['weapon','gun','knife','bomb'], 'drugs': ['drug','cocaine','meth'],\n",
    "                   'threats': ['threat','kill','attack'], 'financial_crimes': ['fraud','steal']}\n",
    "        found_cats, found_words, risk = [], [], 0.0\n",
    "        resp_lower = response.lower()\n",
    "        for cat, words in keywords.items():\n",
    "            for word in words:\n",
    "                if word in resp_lower: found_cats.append(cat); found_words.append(word); risk += 0.15\n",
    "        return {'contains_incriminating': risk > 0.3, 'risk_score': min(risk, 1.0),\n",
    "               'categories': list(set(found_cats)), 'analysis': f'Fallback analysis: {response[:100]}',\n",
    "               'keywords': found_words, 'evidence_summary': f'Found {len(found_words)} terms'}\n",
    "\n",
    "    def add_to_vectorstore(self, text: str, metadata: Dict[str, Any]):\n",
    "        try:\n",
    "            from langchain_core.documents import Document\n",
    "            chunks = self.text_splitter.split_text(text)\n",
    "            docs = [Document(page_content=chunk, metadata={**metadata, 'chunk_id': i})\n",
    "                   for i, chunk in enumerate(chunks)]\n",
    "            self.vectorstore.add_documents(docs); self.vectorstore.persist(); return True\n",
    "        except: return False\n",
    "\n",
    "    def process_gallery(self):\n",
    "        start_time = time.time()\n",
    "        gallery_path = Path(self.config['SUSPECTS_GALLERY_PATH'])\n",
    "        print(f\"üè† PROCESSING: {gallery_path} | Model: {self.config['LLM_MODEL']}\")\n",
    "\n",
    "        if not gallery_path.exists(): print(f\"‚ùå Path not found: {gallery_path}\"); return\n",
    "\n",
    "        exts = ['.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.webp']\n",
    "        files = [f for ext in exts for f in gallery_path.glob(f\"**/*{ext}\") + gallery_path.glob(f\"**/*{ext.upper()}\")]\n",
    "        total, processed, vector_stored, incriminating = len(files), 0, 0, 0\n",
    "\n",
    "        print(f\"üì∏ Found {total} images\")\n",
    "        if total == 0: print(\"‚ö†Ô∏è No images found!\"); return\n",
    "\n",
    "        for i, img_path in enumerate(files, 1):\n",
    "            filename = img_path.name\n",
    "            print(f\"[{i:3d}/{total}] ({i/total*100:5.1f}%) {filename[:40]}...\", end='')\n",
    "\n",
    "            # Skip if processed\n",
    "            if self.conn.execute(\"SELECT id FROM forensic_images WHERE filename = ?\", (filename,)).fetchone():\n",
    "                print(\" ‚è≠Ô∏è SKIP\"); continue\n",
    "\n",
    "            # Extract and analyze\n",
    "            ocr_result = self.extract_text(img_path)\n",
    "            if ocr_result.get('error'): print(\" ‚ùå ERROR\"); continue\n",
    "\n",
    "            text = ocr_result['extracted_text']\n",
    "            analysis = None\n",
    "            if text.strip():\n",
    "                analysis = self.analyze_text(text, filename)\n",
    "                metadata = {'filename': filename, 'full_path': str(img_path),\n",
    "                          'ocr_confidence': ocr_result['ocr_confidence']}\n",
    "                if self.add_to_vectorstore(text, metadata): vector_stored += 1\n",
    "\n",
    "            # Store in DB\n",
    "            risk = analysis['risk_score'] if analysis else 0.0\n",
    "            incrim = analysis['contains_incriminating'] if analysis else False\n",
    "            self.conn.execute('''INSERT OR REPLACE INTO forensic_images\n",
    "                (filename, full_path, extracted_text, ocr_confidence, local_analysis,\n",
    "                 risk_score, contains_incriminating, vector_stored) VALUES (?,?,?,?,?,?,?,?)''',\n",
    "                (filename, str(img_path), text, ocr_result['ocr_confidence'],\n",
    "                 json.dumps(analysis) if analysis else None, risk, incrim, vector_stored > 0))\n",
    "\n",
    "            if text.strip():\n",
    "                if incrim: incriminating += 1; print(f\" üö® INCRIMINATING ({risk:.2f})\")\n",
    "                else: print(\" ‚úÖ TEXT\")\n",
    "            else: print(\" ‚ö™ NO TEXT\")\n",
    "\n",
    "            processed += 1\n",
    "            if i % 10 == 0: self.conn.commit()\n",
    "\n",
    "        self.conn.commit()\n",
    "        print(f\"\\nüè† COMPLETE: {processed} processed, {vector_stored} vectorized, {incriminating} flagged, {time.time()-start_time:.1f}s\")\n",
    "\n",
    "    def investigate(self, query: str) -> Dict[str, Any]:\n",
    "        print(f\"üè† INVESTIGATING: '{query}'\")\n",
    "        try:\n",
    "            docs = self.vectorstore.similarity_search(query, k=5)\n",
    "            if not docs: return {'findings': [], 'summary': 'No evidence found', 'total_flagged': 0}\n",
    "\n",
    "            evidence, files = \"\", set()\n",
    "            for i, doc in enumerate(docs, 1):\n",
    "                filename = doc.metadata.get('filename', f'unknown_{i}')\n",
    "                files.add(filename)\n",
    "                evidence += f\"Evidence {i} - {filename}: {doc.page_content}\\n---\\n\"\n",
    "\n",
    "            prompt = f'''Forensic investigation: \"{query}\"\n",
    "Evidence: {evidence}\n",
    "Respond with JSON:\n",
    "{{\"findings\": [{{\"image_number\": 1, \"filename\": \"file.jpg\", \"matches_query\": true,\n",
    "\"risk_level\": \"high\", \"evidence_found\": \"desc\", \"relevant_text\": \"text\", \"confidence\": 0.8}}],\n",
    "\"summary\": \"summary\", \"total_flagged\": 2, \"highest_risk_image\": \"file.jpg\"}}'''\n",
    "\n",
    "            response = str(self.llm.invoke(prompt)).strip()\n",
    "            response = response.replace('```json', '').replace('```', '').strip()\n",
    "            start, end = response.find('{'), response.rfind('}') + 1\n",
    "\n",
    "            if start >= 0 and end > start:\n",
    "                results = json.loads(response[start:end])\n",
    "            else:\n",
    "                results = self._fallback_investigation(query, files)\n",
    "\n",
    "            # Store investigation\n",
    "            flagged = [f.get('filename', '') for f in results.get('findings', []) if f.get('matches_query')]\n",
    "            self.conn.execute('''INSERT INTO local_investigations\n",
    "                (query, results_json, flagged_images, model_used) VALUES (?,?,?,?)''',\n",
    "                (query, json.dumps(results), json.dumps(flagged), f\"{self.config['LLM_PROVIDER']}-{self.config['LLM_MODEL']}\"))\n",
    "            self.conn.commit()\n",
    "\n",
    "            print(f\"‚úÖ Found {results.get('total_flagged', 0)} matches\")\n",
    "            return results\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error: {e}\")\n",
    "            return {'findings': [], 'summary': f'Error: {e}', 'total_flagged': 0}\n",
    "\n",
    "    def _fallback_investigation(self, query: str, files: set) -> Dict[str, Any]:\n",
    "        findings = [{'image_number': i, 'filename': f, 'matches_query': True, 'risk_level': 'medium',\n",
    "                    'evidence_found': f'Related to: {query}', 'relevant_text': f'Matches: {query}', 'confidence': 0.7}\n",
    "                   for i, f in enumerate(list(files)[:5], 1)]\n",
    "        return {'findings': findings, 'summary': f'Fallback analysis for: {query}',\n",
    "               'total_flagged': len(findings), 'highest_risk_image': list(files)[0] if files else None}\n",
    "\n",
    "    def get_flagged(self, min_risk=0.3):\n",
    "        return self.conn.execute('''SELECT filename, full_path, extracted_text, risk_score,\n",
    "            local_analysis, ocr_confidence FROM forensic_images\n",
    "            WHERE contains_incriminating = 1 AND risk_score >= ? ORDER BY risk_score DESC''', (min_risk,)).fetchall()\n",
    "\n",
    "    def export_results(self, results: Dict[str, Any], query: str) -> str:\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        query_safe = query.replace(' ', '_')[:30]\n",
    "        output_path = Path(self.config['RESULTS_OUTPUT_PATH']) / f\"investigation_{query_safe}_{timestamp}\"\n",
    "        output_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        flagged = [f.get('filename', '') for f in results.get('findings', []) if f.get('matches_query')]\n",
    "        copied = []\n",
    "        for i, filename in enumerate(flagged, 1):\n",
    "            result = self.conn.execute(\"SELECT full_path FROM forensic_images WHERE filename = ?\", (filename,)).fetchone()\n",
    "            if result and Path(result[0]).exists():\n",
    "                dest = output_path / f\"{i:03d}_{filename}\"\n",
    "                shutil.copy2(result[0], dest); copied.append(str(dest))\n",
    "\n",
    "        # Save reports\n",
    "        report = {'query': query, 'timestamp': timestamp, 'model': f\"{self.config['LLM_PROVIDER']}-{self.config['LLM_MODEL']}\",\n",
    "                 'results': results, 'flagged_images': flagged, 'copied_files': copied}\n",
    "\n",
    "        with open(output_path / \"report.json\", 'w') as f: json.dump(report, f, indent=2)\n",
    "        with open(output_path / \"summary.txt\", 'w') as f:\n",
    "            f.write(f\"LOCAL FORENSIC REPORT\\nQuery: {query}\\nDate: {timestamp}\\n\")\n",
    "            f.write(f\"Model: {self.config['LLM_PROVIDER']}-{self.config['LLM_MODEL']}\\n\")\n",
    "            f.write(f\"Flagged: {len(flagged)}\\nSummary: {results.get('summary', 'N/A')}\\n\")\n",
    "\n",
    "        print(f\"üìã Exported to: {output_path}\")\n",
    "        return str(output_path)\n",
    "\n",
    "    def close(self):\n",
    "        if hasattr(self, 'conn') and self.conn: self.conn.close()\n",
    "\n",
    "# Compact GUI\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def create_compact_gui():\n",
    "    # OCR Configuration - ADD THIS TO EXISTING INTERFACE\n",
    "    ocr_selector = widgets.Dropdown(\n",
    "        options=[\n",
    "            ('PaddleOCR - Best overall, 80+ languages', 'paddleocr'),\n",
    "            ('EasyOCR - Good for European languages', 'easyocr'),\n",
    "            ('Tesseract - Classic OCR for printed text', 'tesseract'),\n",
    "            ('TrOCR - AI-based OCR for handwriting', 'trocr')\n",
    "        ],\n",
    "        value='paddleocr',\n",
    "        description='OCR Engine:',\n",
    "        style={'description_width': 'initial'},\n",
    "        layout=widgets.Layout(width='500px')\n",
    "    )\n",
    "\n",
    "    # Existing widgets from your current interface\n",
    "    llm_provider = widgets.Dropdown(\n",
    "        options=[('Ollama', 'ollama'), ('Transformers', 'transformers')],\n",
    "        value='ollama',\n",
    "        description='LLM Provider:',\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "\n",
    "    llm_model = widgets.Text(\n",
    "        value='llama3.2:3b',\n",
    "        description='LLM Model:',\n",
    "        style={'description_width': 'initial'},\n",
    "        layout=widgets.Layout(width='300px')\n",
    "    )\n",
    "\n",
    "    gallery_path = widgets.Text(\n",
    "        value='./suspects_gallery',\n",
    "        description='Gallery Path:',\n",
    "        style={'description_width': 'initial'},\n",
    "        layout=widgets.Layout(width='400px')\n",
    "    )\n",
    "\n",
    "    query_input = widgets.Textarea(\n",
    "        value='Find weapons or violence mentions',\n",
    "        description='Investigation Query:',\n",
    "        style={'description_width': 'initial'},\n",
    "        layout=widgets.Layout(width='500px', height='60px')\n",
    "    )\n",
    "\n",
    "    confidence_slider = widgets.FloatSlider(\n",
    "        value=0.60,\n",
    "        min=0.1, max=0.9, step=0.05,\n",
    "        description='OCR Confidence:',\n",
    "        style={'description_width': 'initial'},\n",
    "        readout_format='.2f'\n",
    "    )\n",
    "\n",
    "    risk_slider = widgets.FloatSlider(\n",
    "        value=0.3,\n",
    "        min=0.1, max=1.0, step=0.1,\n",
    "        description='Risk Threshold:',\n",
    "        style={'description_width': 'initial'},\n",
    "        readout_format='.1f'\n",
    "    )\n",
    "\n",
    "    # Quick queries (same as your existing interface)\n",
    "    quick_queries = [\"Find weapons\", \"Look for drugs\", \"Financial crimes\", \"Personal info theft\", \"Threats\", \"Illegal coordination\"]\n",
    "    quick_btns = [widgets.Button(description=q, tooltip=q, layout=widgets.Layout(width='180px', margin='2px')) for q in quick_queries]\n",
    "\n",
    "    # Action buttons (same as your existing interface)\n",
    "    test_btn = widgets.Button(description='üîç Test Setup', button_style='info', layout=widgets.Layout(width='120px'))\n",
    "    process_btn = widgets.Button(description='üìÅ Process', button_style='primary', layout=widgets.Layout(width='120px'))\n",
    "    investigate_btn = widgets.Button(description='ü§ñ Investigate', button_style='success', layout=widgets.Layout(width='120px'))\n",
    "    flagged_btn = widgets.Button(description='üö® Flagged', button_style='warning', layout=widgets.Layout(width='120px'))\n",
    "    export_btn = widgets.Button(description='üìã Export', button_style='success', layout=widgets.Layout(width='120px'), disabled=True)\n",
    "    clear_btn = widgets.Button(description='üóëÔ∏è Clear', layout=widgets.Layout(width='120px'))\n",
    "\n",
    "    status_label = widgets.HTML(value=\"<b>Status:</b> Ready\")\n",
    "    progress_bar = widgets.IntProgress(value=0, min=0, max=100, layout=widgets.Layout(width='400px'))\n",
    "    output_area = widgets.Output()\n",
    "\n",
    "    # State\n",
    "    current_system = None\n",
    "    current_results = None\n",
    "\n",
    "    def update_status(msg, progress=None):\n",
    "        status_label.value = f\"<b>Status:</b> {msg}\"\n",
    "        if progress is not None: progress_bar.value = progress\n",
    "\n",
    "    def init_system():\n",
    "        nonlocal current_system\n",
    "        try:\n",
    "            config = CONFIG.copy()\n",
    "            config.update({\n",
    "                'OCR_MODEL': ocr_selector.value,  # NOW USES SELECTED OCR\n",
    "                'LLM_PROVIDER': llm_provider.value,\n",
    "                'LLM_MODEL': llm_model.value,\n",
    "                'SUSPECTS_GALLERY_PATH': gallery_path.value,\n",
    "                'OCR_CONFIDENCE_THRESHOLD': confidence_slider.value\n",
    "            })\n",
    "            current_system = CompactForensicSystem(config)\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Init error: {e}\")\n",
    "            return False\n",
    "\n",
    "    # Button handlers (same functionality, now with OCR support)\n",
    "    def on_quick_query(query):\n",
    "        def handler(b): query_input.value = query\n",
    "        return handler\n",
    "\n",
    "    for i, btn in enumerate(quick_btns):\n",
    "        btn.on_click(on_quick_query(quick_queries[i]))\n",
    "\n",
    "    def on_test(b):\n",
    "        with output_area:\n",
    "            clear_output(wait=True)\n",
    "            update_status(\"Testing setup...\", 20)\n",
    "            print(\"üîç TESTING LOCAL SETUP\")\n",
    "            print(\"=\"*40)\n",
    "\n",
    "            # Test OCR first\n",
    "            print(f\"üîç Selected OCR: {ocr_selector.value}\")\n",
    "            ocr_info = {\n",
    "                'paddleocr': 'Best overall, 80+ languages, handwriting',\n",
    "                'easyocr': 'Good for European languages, clean text',\n",
    "                'tesseract': 'Excellent for printed documents, stable',\n",
    "                'trocr': 'Perfect for handwritten notes, degraded images'\n",
    "            }\n",
    "            if ocr_selector.value in ocr_info:\n",
    "                print(f\"   Purpose: {ocr_info[ocr_selector.value]}\")\n",
    "\n",
    "            # Test OCR availability\n",
    "            try:\n",
    "                if ocr_selector.value == 'paddleocr':\n",
    "                    import paddleocr; print(\"‚úÖ PaddleOCR available\")\n",
    "                elif ocr_selector.value == 'easyocr':\n",
    "                    import easyocr; print(\"‚úÖ EasyOCR available\")\n",
    "                elif ocr_selector.value == 'tesseract':\n",
    "                    import pytesseract; print(\"‚úÖ Tesseract available\")\n",
    "                elif ocr_selector.value == 'trocr':\n",
    "                    import transformers; print(\"‚úÖ TrOCR available\")\n",
    "            except ImportError:\n",
    "                print(f\"‚ùå {ocr_selector.value} not installed\")\n",
    "\n",
    "            # Test other dependencies\n",
    "            deps = [('langchain', 'LangChain'), ('chromadb', 'ChromaDB'), ('sentence_transformers', 'Transformers')]\n",
    "            for dep, name in deps:\n",
    "                try: __import__(dep.replace('-', '_')); print(f\"‚úÖ {name}\")\n",
    "                except ImportError: print(f\"‚ùå {name} not found\")\n",
    "\n",
    "            # Test Ollama\n",
    "            if llm_provider.value == 'ollama':\n",
    "                update_status(\"Testing Ollama...\", 60)\n",
    "                try:\n",
    "                    import requests\n",
    "                    r = requests.get(\"http://localhost:11434/api/tags\", timeout=5)\n",
    "                    if r.status_code == 200:\n",
    "                        models = [m['name'] for m in r.json().get('models', [])]\n",
    "                        print(f\"‚úÖ Ollama: {models}\")\n",
    "                        if llm_model.value in models:\n",
    "                            print(f\"‚úÖ Model '{llm_model.value}' ready\")\n",
    "                        else:\n",
    "                            print(f\"‚ö†Ô∏è Model '{llm_model.value}' not found. Install: ollama pull {llm_model.value}\")\n",
    "                    else: print(\"‚ùå Ollama not responding\")\n",
    "                except: print(\"‚ùå Ollama connection failed. Start: ollama serve\")\n",
    "\n",
    "            update_status(\"Testing system init...\", 80)\n",
    "            if init_system():\n",
    "                print(\"‚úÖ System ready with selected OCR\");\n",
    "                update_status(\"Setup complete!\", 100)\n",
    "            else:\n",
    "                print(\"‚ùå System init failed\");\n",
    "                update_status(\"Setup failed\", 0)\n",
    "\n",
    "    def on_process(b):\n",
    "        with output_area:\n",
    "            clear_output(wait=True)\n",
    "            update_status(\"Processing gallery...\", 20)\n",
    "            if not init_system():\n",
    "                update_status(\"Init failed\", 0); return\n",
    "\n",
    "            print(f\"üè† PROCESSING | OCR: {ocr_selector.value} | LLM: {llm_provider.value}-{llm_model.value}\")\n",
    "            try:\n",
    "                current_system.process_gallery()\n",
    "                update_status(\"Processing complete!\", 100)\n",
    "                flagged = current_system.get_flagged(risk_slider.value)\n",
    "                if flagged: print(f\"\\nüö® FLAGGED: {len(flagged)} images above risk {risk_slider.value}\")\n",
    "                else: print(\"\\n‚úÖ No high-risk content detected\")\n",
    "            except Exception as e: update_status(\"Processing error\", 0); print(f\"‚ùå Error: {e}\")\n",
    "\n",
    "    def on_investigate(b):\n",
    "        nonlocal current_results\n",
    "        with output_area:\n",
    "            clear_output(wait=True)\n",
    "            if not current_system and not init_system(): print(\"‚ùå System not ready\"); return\n",
    "\n",
    "            query = query_input.value.strip()\n",
    "            if not query: print(\"‚ö†Ô∏è Enter investigation query\"); return\n",
    "\n",
    "            update_status(\"Investigating...\", 50)\n",
    "            print(f\"üè† INVESTIGATING: '{query}' | OCR: {ocr_selector.value} | LLM: {llm_model.value}\")\n",
    "            try:\n",
    "                current_results = current_system.investigate(query)\n",
    "                if current_results.get('total_flagged', 0) > 0:\n",
    "                    update_status(f\"Found {current_results['total_flagged']} matches\", 100)\n",
    "                    export_btn.disabled = False\n",
    "                    print(f\"üìä Summary: {current_results.get('summary', 'N/A')}\")\n",
    "                    print(\"üö® FLAGGED:\")\n",
    "                    for f in current_results.get('findings', []):\n",
    "                        if f.get('matches_query'):\n",
    "                            print(f\"  {f['risk_level'].upper()}: {f['filename']} - {f['evidence_found']}\")\n",
    "\n",
    "                    # Display images\n",
    "                    flagged_files = [f['filename'] for f in current_results.get('findings', []) if f.get('matches_query')]\n",
    "                    if flagged_files:\n",
    "                        print(f\"üñºÔ∏è Displaying {len(flagged_files)} flagged images...\")\n",
    "                        display_flagged_images(flagged_files[:6], current_system)\n",
    "                else:\n",
    "                    update_status(\"No matches\", 100); export_btn.disabled = True\n",
    "                    print(\"‚ùå No matches. Try different terms or lower risk threshold.\")\n",
    "            except Exception as e: update_status(\"Investigation error\", 0); print(f\"‚ùå Error: {e}\")\n",
    "\n",
    "    def on_flagged(b):\n",
    "        with output_area:\n",
    "            clear_output(wait=True)\n",
    "            if not current_system and not init_system(): print(\"‚ùå System not ready\"); return\n",
    "\n",
    "            update_status(\"Loading flagged images...\", 50)\n",
    "            try:\n",
    "                flagged = current_system.get_flagged(risk_slider.value)\n",
    "                if flagged:\n",
    "                    print(f\"üö® FLAGGED IMAGES (Risk ‚â• {risk_slider.value})\")\n",
    "                    for i, (filename, _, text, risk, analysis, conf) in enumerate(flagged, 1):\n",
    "                        level = \"CRITICAL\" if risk > 0.8 else \"HIGH\" if risk > 0.6 else \"MEDIUM\" if risk > 0.3 else \"LOW\"\n",
    "                        print(f\"{i}. {filename} | {level} ({risk:.3f}) | OCR: {conf:.3f}\")\n",
    "                        print(f\"   Text: {text[:100]}...\")\n",
    "                        if analysis:\n",
    "                            try:\n",
    "                                data = json.loads(analysis)\n",
    "                                cats = data.get('categories', [])\n",
    "                                if cats: print(f\"   Categories: {', '.join(cats)}\")\n",
    "                            except: pass\n",
    "                        print()\n",
    "\n",
    "                    files = [r[0] for r in flagged[:6]]\n",
    "                    print(f\"üñºÔ∏è Displaying {len(files)} flagged images...\")\n",
    "                    display_flagged_images(files, current_system)\n",
    "                    update_status(f\"Showing {len(flagged)} flagged images\", 100)\n",
    "                else:\n",
    "                    print(f\"‚úÖ No images flagged above risk {risk_slider.value}\")\n",
    "                    update_status(\"No flagged images\", 100)\n",
    "            except Exception as e: update_status(\"Error loading flagged\", 0); print(f\"‚ùå Error: {e}\")\n",
    "\n",
    "    def on_export(b):\n",
    "        with output_area:\n",
    "            if not current_results: print(\"‚ö†Ô∏è No results to export\"); return\n",
    "            try:\n",
    "                update_status(\"Exporting...\", 50)\n",
    "                path = current_system.export_results(current_results, query_input.value or \"investigation\")\n",
    "                update_status(\"Export complete!\", 100)\n",
    "                print(f\"‚úÖ Results exported to: {path}\")\n",
    "            except Exception as e: update_status(\"Export error\", 0); print(f\"‚ùå Error: {e}\")\n",
    "\n",
    "    def on_clear(b):\n",
    "        nonlocal current_results\n",
    "        current_results = None; export_btn.disabled = True\n",
    "        with output_area: clear_output(); update_status(\"Cleared\", 0); print(\"üóëÔ∏è Cleared\")\n",
    "\n",
    "    # Connect events\n",
    "    test_btn.on_click(on_test); process_btn.on_click(on_process); investigate_btn.on_click(on_investigate)\n",
    "    flagged_btn.on_click(on_flagged); export_btn.on_click(on_export); clear_btn.on_click(on_clear)\n",
    "\n",
    "    # Quick query grid\n",
    "    quick_grid = widgets.GridBox(quick_btns, layout=widgets.Layout(grid_template_columns='repeat(3, 1fr)', grid_gap='5px'))\n",
    "\n",
    "    # UPDATED LAYOUT: Add OCR selector at the top\n",
    "    controls = widgets.VBox([\n",
    "        widgets.HTML(\"<h3>üè† Compact Local Forensic System</h3>\"),\n",
    "\n",
    "        # ADD OCR SELECTOR AT THE TOP\n",
    "        widgets.HTML(\"<b>üîç OCR Engine Selection:</b>\"),\n",
    "        ocr_selector,\n",
    "        widgets.HTML(\"<br>\"),\n",
    "\n",
    "        # Existing LLM configuration\n",
    "        widgets.HBox([llm_provider, llm_model]),\n",
    "        gallery_path,\n",
    "        query_input,\n",
    "        widgets.HTML(\"<b>Quick Queries:</b>\"),\n",
    "        quick_grid,\n",
    "        widgets.HBox([confidence_slider, risk_slider]),\n",
    "        widgets.HBox([test_btn, process_btn, investigate_btn, flagged_btn, export_btn, clear_btn]),\n",
    "        status_label,\n",
    "        progress_bar,\n",
    "        widgets.HTML(\"<hr>\")\n",
    "    ])\n",
    "\n",
    "    return widgets.VBox([controls, output_area])\n",
    "\n",
    "    confidence_slider = widgets.FloatSlider(\n",
    "        value=CONFIG['OCR_CONFIDENCE_THRESHOLD'],\n",
    "        min=0.1, max=0.9, step=0.05,\n",
    "        description='OCR Confidence:',\n",
    "        style={'description_width': 'initial'},\n",
    "        readout_format='.2f'\n",
    "    )\n",
    "\n",
    "    risk_slider = widgets.FloatSlider(\n",
    "        value=0.3,\n",
    "        min=0.1, max=1.0, step=0.1,\n",
    "        description='Risk Threshold:',\n",
    "        style={'description_width': 'initial'},\n",
    "        readout_format='.1f'\n",
    "    )\n",
    "\n",
    "    # Quick queries\n",
    "    quick_queries = [\"Find weapons\", \"Look for drugs\", \"Financial crimes\", \"Personal info theft\", \"Threats\", \"Illegal coordination\"]\n",
    "    quick_btns = [widgets.Button(description=q[:20], tooltip=q, layout=widgets.Layout(width='180px', margin='2px')) for q in quick_queries]\n",
    "\n",
    "    # Action buttons\n",
    "    test_btn = widgets.Button(description='üîç Test Setup', button_style='info', layout=widgets.Layout(width='120px'))\n",
    "    process_btn = widgets.Button(description='üìÅ Process', button_style='primary', layout=widgets.Layout(width='120px'))\n",
    "    investigate_btn = widgets.Button(description='ü§ñ Investigate', button_style='success', layout=widgets.Layout(width='120px'))\n",
    "    flagged_btn = widgets.Button(description='üö® Flagged', button_style='warning', layout=widgets.Layout(width='120px'))\n",
    "    export_btn = widgets.Button(description='üìã Export', button_style='success', layout=widgets.Layout(width='120px'), disabled=True)\n",
    "    clear_btn = widgets.Button(description='üóëÔ∏è Clear', layout=widgets.Layout(width='120px'))\n",
    "\n",
    "    status_label = widgets.HTML(value=\"<b>Status:</b> Ready\")\n",
    "    progress_bar = widgets.IntProgress(value=0, min=0, max=100, layout=widgets.Layout(width='400px'))\n",
    "    output_area = widgets.Output()\n",
    "\n",
    "    # State\n",
    "    current_system = None\n",
    "    current_results = None\n",
    "\n",
    "    def update_status(msg, progress=None):\n",
    "        status_label.value = f\"<b>Status:</b> {msg}\"\n",
    "        if progress is not None: progress_bar.value = progress\n",
    "\n",
    "    def init_system():\n",
    "        nonlocal current_system\n",
    "        try:\n",
    "            config = CONFIG.copy()\n",
    "            config.update({\n",
    "                'OCR_MODEL': ocr_selector.value,\n",
    "                'LLM_PROVIDER': llm_provider.value,\n",
    "                'LLM_MODEL': llm_model.value,\n",
    "                'SUSPECTS_GALLERY_PATH': gallery_path.value,\n",
    "                'OCR_CONFIDENCE_THRESHOLD': confidence_slider.value\n",
    "            })\n",
    "            current_system = CompactForensicSystem(config)\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Init error: {e}\")\n",
    "            return False\n",
    "\n",
    "    # Button handlers\n",
    "    def on_quick_query(query):\n",
    "        def handler(b): query_input.value = query\n",
    "        return handler\n",
    "\n",
    "    for i, btn in enumerate(quick_btns): btn.on_click(on_quick_query(quick_queries[i]))\n",
    "\n",
    "    def on_test(b):\n",
    "        with output_area:\n",
    "            clear_output(wait=True)\n",
    "            update_status(\"Testing setup...\", 20)\n",
    "            print(\"üîç TESTING LOCAL SETUP\")\n",
    "            print(\"=\"*40)\n",
    "\n",
    "            # Test OCR first\n",
    "            print(f\"Testing OCR: {ocr_selector.value}\")\n",
    "            ocr_info = OCR_MODELS.get(ocr_selector.value, {})\n",
    "            print(f\"Purpose: {ocr_info.get('strengths', 'General OCR')}\")\n",
    "\n",
    "            try:\n",
    "                if ocr_selector.value == 'paddleocr':\n",
    "                    import paddleocr; print(\"‚úÖ PaddleOCR available\")\n",
    "                elif ocr_selector.value == 'easyocr':\n",
    "                    import easyocr; print(\"‚úÖ EasyOCR available\")\n",
    "                elif ocr_selector.value == 'tesseract':\n",
    "                    import pytesseract; print(\"‚úÖ Tesseract available\")\n",
    "                elif ocr_selector.value == 'trocr':\n",
    "                    import transformers; print(\"‚úÖ TrOCR (Transformers) available\")\n",
    "            except ImportError as e: print(f\"‚ùå {ocr_selector.value} not found: {e}\")\n",
    "\n",
    "            # Test other dependencies\n",
    "            deps = [('paddleocr', 'PaddleOCR'), ('langchain', 'LangChain'), ('chromadb', 'ChromaDB'), ('sentence_transformers', 'Transformers')]\n",
    "            for dep, name in deps:\n",
    "                try: __import__(dep.replace('-', '_')); print(f\"‚úÖ {name}\")\n",
    "                except ImportError: print(f\"‚ùå {name} not found\")\n",
    "\n",
    "            # Test Ollama\n",
    "            if llm_provider.value == 'ollama':\n",
    "                update_status(\"Testing Ollama...\", 60)\n",
    "                try:\n",
    "                    import requests\n",
    "                    r = requests.get(\"http://localhost:11434/api/tags\", timeout=5)\n",
    "                    if r.status_code == 200:\n",
    "                        models = [m['name'] for m in r.json().get('models', [])]\n",
    "                        print(f\"‚úÖ Ollama: {models}\")\n",
    "                        if llm_model.value in models: print(f\"‚úÖ Model '{llm_model.value}' ready\")\n",
    "                        else: print(f\"‚ö†Ô∏è Model '{llm_model.value}' not found. Install: ollama pull {llm_model.value}\")\n",
    "                    else: print(\"‚ùå Ollama not responding\")\n",
    "                except: print(\"‚ùå Ollama connection failed. Start: ollama serve\")\n",
    "\n",
    "            update_status(\"Testing system init...\", 80)\n",
    "            if init_system(): print(\"‚úÖ System ready\"); update_status(\"Setup complete!\", 100)\n",
    "            else: print(\"‚ùå System init failed\"); update_status(\"Setup failed\", 0)\n",
    "\n",
    "    def on_process(b):\n",
    "        with output_area:\n",
    "            clear_output(wait=True)\n",
    "            update_status(\"Processing gallery...\", 20)\n",
    "            if not init_system(): update_status(\"Init failed\", 0); return\n",
    "\n",
    "            print(f\"üè† PROCESSING | OCR: {ocr_selector.value} | LLM: {llm_provider.value}-{llm_model.value}\")\n",
    "            try:\n",
    "                current_system.process_gallery()\n",
    "                update_status(\"Processing complete!\", 100)\n",
    "                flagged = current_system.get_flagged(risk_slider.value)\n",
    "                if flagged: print(f\"\\nüö® FLAGGED: {len(flagged)} images above risk {risk_slider.value}\")\n",
    "                else: print(\"\\n‚úÖ No high-risk content detected\")\n",
    "            except Exception as e: update_status(\"Processing error\", 0); print(f\"‚ùå Error: {e}\")\n",
    "\n",
    "    def on_investigate(b):\n",
    "        nonlocal current_results\n",
    "        with output_area:\n",
    "            clear_output(wait=True)\n",
    "            if not current_system and not init_system(): print(\"‚ùå System not ready\"); return\n",
    "\n",
    "            query = query_input.value.strip()\n",
    "            if not query: print(\"‚ö†Ô∏è Enter investigation query\"); return\n",
    "\n",
    "            update_status(\"Investigating...\", 50)\n",
    "            print(f\"üè† INVESTIGATING: '{query}' | Model: {llm_model.value}\")\n",
    "            try:\n",
    "                current_results = current_system.investigate(query)\n",
    "                if current_results.get('total_flagged', 0) > 0:\n",
    "                    update_status(f\"Found {current_results['total_flagged']} matches\", 100)\n",
    "                    export_btn.disabled = False\n",
    "                    print(f\"üìä Summary: {current_results.get('summary', 'N/A')}\")\n",
    "                    print(\"üö® FLAGGED:\")\n",
    "                    for f in current_results.get('findings', []):\n",
    "                        if f.get('matches_query'):\n",
    "                            print(f\"  {f['risk_level'].upper()}: {f['filename']} - {f['evidence_found']}\")\n",
    "\n",
    "                    # Display images\n",
    "                    flagged_files = [f['filename'] for f in current_results.get('findings', []) if f.get('matches_query')]\n",
    "                    if flagged_files:\n",
    "                        print(f\"üñºÔ∏è Displaying {len(flagged_files)} flagged images...\")\n",
    "                        display_flagged_images(flagged_files[:6], current_system)\n",
    "                else:\n",
    "                    update_status(\"No matches\", 100); export_btn.disabled = True\n",
    "                    print(\"‚ùå No matches. Try different terms or lower risk threshold.\")\n",
    "            except Exception as e: update_status(\"Investigation error\", 0); print(f\"‚ùå Error: {e}\")\n",
    "\n",
    "    def on_flagged(b):\n",
    "        with output_area:\n",
    "            clear_output(wait=True)\n",
    "            if not current_system and not init_system(): print(\"‚ùå System not ready\"); return\n",
    "\n",
    "            update_status(\"Loading flagged images...\", 50)\n",
    "            try:\n",
    "                flagged = current_system.get_flagged(risk_slider.value)\n",
    "                if flagged:\n",
    "                    print(f\"üö® FLAGGED IMAGES (Risk ‚â• {risk_slider.value})\")\n",
    "                    for i, (filename, _, text, risk, analysis, conf) in enumerate(flagged, 1):\n",
    "                        level = \"CRITICAL\" if risk > 0.8 else \"HIGH\" if risk > 0.6 else \"MEDIUM\" if risk > 0.3 else \"LOW\"\n",
    "                        print(f\"{i}. {filename} | {level} ({risk:.3f}) | OCR: {conf:.3f}\")\n",
    "                        print(f\"   Text: {text[:100]}...\")\n",
    "                        if analysis:\n",
    "                            try:\n",
    "                                data = json.loads(analysis)\n",
    "                                cats = data.get('categories', [])\n",
    "                                if cats: print(f\"   Categories: {', '.join(cats)}\")\n",
    "                            except: pass\n",
    "                        print()\n",
    "\n",
    "                    files = [r[0] for r in flagged[:6]]\n",
    "                    display_flagged_images(files, current_system)\n",
    "                    update_status(f\"Showing {len(flagged)} flagged images\", 100)\n",
    "                else:\n",
    "                    print(f\"‚úÖ No images flagged above risk {risk_slider.value}\")\n",
    "                    update_status(\"No flagged images\", 100)\n",
    "            except Exception as e: update_status(\"Error loading flagged\", 0); print(f\"‚ùå Error: {e}\")\n",
    "\n",
    "    def on_export(b):\n",
    "        with output_area:\n",
    "            if not current_results: print(\"‚ö†Ô∏è No results to export\"); return\n",
    "            try:\n",
    "                update_status(\"Exporting...\", 50)\n",
    "                path = current_system.export_results(current_results, query_input.value or \"investigation\")\n",
    "                update_status(\"Export complete!\", 100)\n",
    "                print(f\"‚úÖ Results exported to: {path}\")\n",
    "            except Exception as e: update_status(\"Export error\", 0); print(f\"‚ùå Error: {e}\")\n",
    "\n",
    "    def on_clear(b):\n",
    "        nonlocal current_results\n",
    "        current_results = None; export_btn.disabled = True\n",
    "        with output_area: clear_output(); update_status(\"Cleared\", 0); print(\"üóëÔ∏è Cleared\")\n",
    "\n",
    "    # Connect events\n",
    "    test_btn.on_click(on_test); process_btn.on_click(on_process); investigate_btn.on_click(on_investigate)\n",
    "    flagged_btn.on_click(on_flagged); export_btn.on_click(on_export); clear_btn.on_click(on_clear)\n",
    "\n",
    "    # Layout\n",
    "    quick_grid = widgets.GridBox(quick_btns, layout=widgets.Layout(grid_template_columns='repeat(3, 1fr)', grid_gap='5px'))\n",
    "    controls = widgets.VBox([\n",
    "        widgets.HTML(\"<h3>üè† Compact Local Forensic System</h3>\"),\n",
    "        widgets.HBox([llm_provider, llm_model]), gallery_path, query_input,\n",
    "        widgets.HTML(\"<b>Quick Queries:</b>\"), quick_grid,\n",
    "        widgets.HBox([confidence_slider, risk_slider]),\n",
    "        widgets.HBox([test_btn, process_btn, investigate_btn, flagged_btn, export_btn, clear_btn]),\n",
    "        status_label, progress_bar, widgets.HTML(\"<hr>\")\n",
    "    ])\n",
    "\n",
    "    return widgets.VBox([controls, output_area])\n",
    "\n",
    "    for i, filename in enumerate(filenames[:num]):\n",
    "        ax = axes[i] if num > 1 else axes\n",
    "        try:\n",
    "            result = system.conn.execute('''SELECT full_path, extracted_text, risk_score, local_analysis\n",
    "                FROM forensic_images WHERE filename = ?''', (filename,)).fetchone()\n",
    "            if not result: ax.text(0.5, 0.5, f\"Not found\\n{filename}\", ha='center', va='center', transform=ax.transAxes); ax.axis('off'); continue\n",
    "\n",
    "            full_path, text, risk, analysis = result\n",
    "            try: img = plt.imread(full_path); ax.imshow(img)\n",
    "            except: ax.text(0.5, 0.5, f\"Load error\\n{filename}\", ha='center', va='center', transform=ax.transAxes); ax.axis('off'); continue\n",
    "\n",
    "            # Risk level and color\n",
    "            level, color = (\"CRITICAL\", \"red\") if risk > 0.8 else (\"HIGH\", \"orange\") if risk > 0.6 else (\"MEDIUM\", \"yellow\") if risk > 0.3 else (\"LOW\", \"green\")\n",
    "            ax.set_title(f\"{filename}\\n{level}: {risk:.2f}\", fontsize=10, color=color, fontweight='bold')\n",
    "\n",
    "            # Text overlay\n",
    "            text_preview = text[:80] if text else \"No text\"\n",
    "            ax.text(0.02, 0.98, f\"Text: {text_preview}...\", transform=ax.transAxes, fontsize=8,\n",
    "                   verticalalignment='top', bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=color, alpha=0.7))\n",
    "\n",
    "            # Categories\n",
    "            if analysis:\n",
    "                try:\n",
    "                    data = json.loads(analysis)\n",
    "                    cats = data.get('categories', [])\n",
    "                    if cats: ax.text(0.02, 0.02, f\"Cat: {', '.join(cats[:2])}\", transform=ax.transAxes, fontsize=7,\n",
    "                                   verticalalignment='bottom', bbox=dict(boxstyle=\"round,pad=0.2\", facecolor=\"lightblue\", alpha=0.8))\n",
    "                except: pass\n",
    "            ax.axis('off')\n",
    "        except Exception as e: ax.text(0.5, 0.5, f\"Error\\n{filename}\\n{str(e)[:30]}\", ha='center', va='center', transform=ax.transAxes); ax.axis('off')\n",
    "\n",
    "    for j in range(num, len(axes)): axes[j].axis('off')\n",
    "    plt.tight_layout(); plt.suptitle('üè† Local Forensic Results', fontsize=14, y=1.02); plt.show()\n",
    "\n",
    "# Quick functions\n",
    "def quick_setup():\n",
    "    print(\"üè† QUICK SETUP CHECK\")\n",
    "    deps = ['paddleocr', 'langchain', 'chromadb', 'sentence_transformers']\n",
    "    for dep in deps:\n",
    "        try: __import__(dep.replace('-', '_')); print(f\"‚úÖ {dep}\")\n",
    "        except ImportError: print(f\"‚ùå {dep} - pip install {dep}\")\n",
    "\n",
    "    try:\n",
    "        import requests\n",
    "        r = requests.get(\"http://localhost:11434/api/tags\", timeout=5)\n",
    "        if r.status_code == 200:\n",
    "            models = [m['name'] for m in r.json().get('models', [])]\n",
    "            print(f\"‚úÖ Ollama: {models}\")\n",
    "            if 'llama3.2:3b' in models: print(\"‚úÖ Recommended model ready\")\n",
    "            else: print(\"‚ö†Ô∏è Install: ollama pull llama3.2:3b\")\n",
    "        else: print(\"‚ùå Ollama not responding\")\n",
    "    except: print(\"‚ùå Ollama not available - Start: ollama serve\")\n",
    "\n",
    "def quick_investigate(query: str, gallery_path: str = './suspects_gallery'):\n",
    "    print(f\"üè† Quick Investigation: '{query}' | üîí 100% Local\")\n",
    "    try:\n",
    "        config = CONFIG.copy(); config['SUSPECTS_GALLERY_PATH'] = gallery_path\n",
    "        system = CompactForensicSystem(config)\n",
    "\n",
    "        # Check if processed\n",
    "        count = system.conn.execute(\"SELECT COUNT(*) FROM forensic_images WHERE vector_stored = 1\").fetchone()[0]\n",
    "        if count == 0: print(\"üìÅ Processing gallery first...\"); system.process_gallery()\n",
    "\n",
    "        results = system.investigate(query)\n",
    "        if results.get('total_flagged', 0) > 0:\n",
    "            path = system.export_results(results, query)\n",
    "            print(f\"üìã Exported to: {path}\")\n",
    "        system.close(); return results\n",
    "    except Exception as e: print(f\"‚ùå Error: {e}\"); return None\n",
    "\n",
    "# Display interface with debugging\n",
    "print(\"üè† Creating Compact Local Forensic Interface...\")\n",
    "print(\"üîß Debug: OCR models available:\", list(OCR_MODELS.keys()))\n",
    "\n",
    "compact_interface = create_compact_gui()\n",
    "\n",
    "# Verify the interface was created properly\n",
    "print(\"‚úÖ GUI created successfully\")\n",
    "print(\"üîç OCR selector should be visible at the top\")\n",
    "\n",
    "display(compact_interface)\n",
    "\n",
    "print(f\"\\nüè† COMPACT LOCAL FORENSIC SYSTEM READY!\")\n",
    "print(\"=\"*50)\n",
    "print(\"üîí PRIVACY: 100% local, no API calls, offline capable\")\n",
    "print(\"ü§ñ COMPONENTS: Multi-OCR + Ollama/Transformers + ChromaDB + SQLite\")\n",
    "print(\"üìù OCR OPTIONS: PaddleOCR, EasyOCR, Tesseract, TrOCR\")\n",
    "print(\"üöÄ SETUP: ollama serve ‚Üí ollama pull llama3.2:3b\")\n",
    "print(\"üí° QUICK: quick_setup() | quick_investigate('find weapons')\")\n",
    "print(\"=\"*50)\n",
    "print(\"\\nüîç OCR SELECTION GUIDE:\")\n",
    "print(\"‚Ä¢ PaddleOCR: Best overall, Asian languages, handwriting\")\n",
    "print(\"‚Ä¢ EasyOCR: European languages, clean text\")\n",
    "print(\"‚Ä¢ Tesseract: Printed documents, very stable\")\n",
    "print(\"‚Ä¢ TrOCR: Handwritten notes, degraded images\")\n",
    "print(\"=\"*50)"
   ],
   "id": "239d202e8fbba834",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üè† LOCAL FORENSIC SYSTEM | LLM: ollama-llama3.2:3b | üîí 100% Private\n",
      "‚úÖ paddleocr\n",
      "‚úÖ langchain\n",
      "‚úÖ chromadb\n",
      "‚úÖ sentence_transformers\n",
      "‚úÖ Ollama: ['deepseek-r1:1.5b', 'llama3.2:latest']\n",
      "üè† Creating Compact Local Forensic Interface...\n",
      "üîß Debug: OCR models available: ['paddleocr', 'easyocr', 'tesseract', 'trocr']\n",
      "‚úÖ GUI created successfully\n",
      "üîç OCR selector should be visible at the top\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VBox(children=(VBox(children=(HTML(value='<h3>üè† Compact Local Forensic System</h3>'), HTML(value='<b>üîç OCR Eng‚Ä¶"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2defe24f02fa49fb9384cb98577abc01"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üè† COMPACT LOCAL FORENSIC SYSTEM READY!\n",
      "==================================================\n",
      "üîí PRIVACY: 100% local, no API calls, offline capable\n",
      "ü§ñ COMPONENTS: Multi-OCR + Ollama/Transformers + ChromaDB + SQLite\n",
      "üìù OCR OPTIONS: PaddleOCR, EasyOCR, Tesseract, TrOCR\n",
      "üöÄ SETUP: ollama serve ‚Üí ollama pull llama3.2:3b\n",
      "üí° QUICK: quick_setup() | quick_investigate('find weapons')\n",
      "==================================================\n",
      "\n",
      "üîç OCR SELECTION GUIDE:\n",
      "‚Ä¢ PaddleOCR: Best overall, Asian languages, handwriting\n",
      "‚Ä¢ EasyOCR: European languages, clean text\n",
      "‚Ä¢ Tesseract: Printed documents, very stable\n",
      "‚Ä¢ TrOCR: Handwritten notes, degraded images\n",
      "==================================================\n"
     ]
    }
   ],
   "execution_count": 16
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
