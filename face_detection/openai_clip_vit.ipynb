{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5b51758e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in d:\\interpreters\\python\\projects\\ai_forensics\\.venv\\lib\\site-packages (2.7.1)\n",
      "Requirement already satisfied: transformers in d:\\interpreters\\python\\projects\\ai_forensics\\.venv\\lib\\site-packages (4.52.4)\n",
      "Requirement already satisfied: pillow in d:\\interpreters\\python\\projects\\ai_forensics\\.venv\\lib\\site-packages (11.2.1)\n",
      "Requirement already satisfied: scikit-learn in d:\\interpreters\\python\\projects\\ai_forensics\\.venv\\lib\\site-packages (1.7.0)\n",
      "Requirement already satisfied: pathlib in d:\\interpreters\\python\\projects\\ai_forensics\\.venv\\lib\\site-packages (1.0.1)\n",
      "Requirement already satisfied: matplotlib in d:\\interpreters\\python\\projects\\ai_forensics\\.venv\\lib\\site-packages (3.10.3)\n",
      "Requirement already satisfied: pandas in d:\\interpreters\\python\\projects\\ai_forensics\\.venv\\lib\\site-packages (2.3.0)\n",
      "Collecting ipywidgets\n",
      "  Downloading ipywidgets-8.1.7-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: filelock in d:\\interpreters\\python\\projects\\ai_forensics\\.venv\\lib\\site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in d:\\interpreters\\python\\projects\\ai_forensics\\.venv\\lib\\site-packages (from torch) (4.14.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in d:\\interpreters\\python\\projects\\ai_forensics\\.venv\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in d:\\interpreters\\python\\projects\\ai_forensics\\.venv\\lib\\site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in d:\\interpreters\\python\\projects\\ai_forensics\\.venv\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in d:\\interpreters\\python\\projects\\ai_forensics\\.venv\\lib\\site-packages (from torch) (2025.5.1)\n",
      "Requirement already satisfied: setuptools in d:\\interpreters\\python\\projects\\ai_forensics\\.venv\\lib\\site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in d:\\interpreters\\python\\projects\\ai_forensics\\.venv\\lib\\site-packages (from transformers) (0.32.4)\n",
      "Requirement already satisfied: numpy>=1.17 in d:\\interpreters\\python\\projects\\ai_forensics\\.venv\\lib\\site-packages (from transformers) (2.3.0)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\interpreters\\python\\projects\\ai_forensics\\.venv\\lib\\site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in d:\\interpreters\\python\\projects\\ai_forensics\\.venv\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in d:\\interpreters\\python\\projects\\ai_forensics\\.venv\\lib\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in d:\\interpreters\\python\\projects\\ai_forensics\\.venv\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in d:\\interpreters\\python\\projects\\ai_forensics\\.venv\\lib\\site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in d:\\interpreters\\python\\projects\\ai_forensics\\.venv\\lib\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in d:\\interpreters\\python\\projects\\ai_forensics\\.venv\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: scipy>=1.8.0 in d:\\interpreters\\python\\projects\\ai_forensics\\.venv\\lib\\site-packages (from scikit-learn) (1.15.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in d:\\interpreters\\python\\projects\\ai_forensics\\.venv\\lib\\site-packages (from scikit-learn) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in d:\\interpreters\\python\\projects\\ai_forensics\\.venv\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in d:\\interpreters\\python\\projects\\ai_forensics\\.venv\\lib\\site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in d:\\interpreters\\python\\projects\\ai_forensics\\.venv\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in d:\\interpreters\\python\\projects\\ai_forensics\\.venv\\lib\\site-packages (from matplotlib) (4.58.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in d:\\interpreters\\python\\projects\\ai_forensics\\.venv\\lib\\site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in d:\\interpreters\\python\\projects\\ai_forensics\\.venv\\lib\\site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in d:\\interpreters\\python\\projects\\ai_forensics\\.venv\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\interpreters\\python\\projects\\ai_forensics\\.venv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in d:\\interpreters\\python\\projects\\ai_forensics\\.venv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: comm>=0.1.3 in d:\\interpreters\\python\\projects\\ai_forensics\\.venv\\lib\\site-packages (from ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in d:\\interpreters\\python\\projects\\ai_forensics\\.venv\\lib\\site-packages (from ipywidgets) (9.3.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in d:\\interpreters\\python\\projects\\ai_forensics\\.venv\\lib\\site-packages (from ipywidgets) (5.14.3)\n",
      "Collecting widgetsnbextension~=4.0.14 (from ipywidgets)\n",
      "  Downloading widgetsnbextension-4.0.14-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting jupyterlab_widgets~=3.0.15 (from ipywidgets)\n",
      "  Downloading jupyterlab_widgets-3.0.15-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: colorama in d:\\interpreters\\python\\projects\\ai_forensics\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.4.6)\n",
      "Requirement already satisfied: decorator in d:\\interpreters\\python\\projects\\ai_forensics\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers in d:\\interpreters\\python\\projects\\ai_forensics\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in d:\\interpreters\\python\\projects\\ai_forensics\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in d:\\interpreters\\python\\projects\\ai_forensics\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in d:\\interpreters\\python\\projects\\ai_forensics\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (3.0.51)\n",
      "Requirement already satisfied: pygments>=2.4.0 in d:\\interpreters\\python\\projects\\ai_forensics\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (2.19.1)\n",
      "Requirement already satisfied: stack_data in d:\\interpreters\\python\\projects\\ai_forensics\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: wcwidth in d:\\interpreters\\python\\projects\\ai_forensics\\.venv\\lib\\site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in d:\\interpreters\\python\\projects\\ai_forensics\\.venv\\lib\\site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: six>=1.5 in d:\\interpreters\\python\\projects\\ai_forensics\\.venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in d:\\interpreters\\python\\projects\\ai_forensics\\.venv\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\interpreters\\python\\projects\\ai_forensics\\.venv\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\interpreters\\python\\projects\\ai_forensics\\.venv\\lib\\site-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\interpreters\\python\\projects\\ai_forensics\\.venv\\lib\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\interpreters\\python\\projects\\ai_forensics\\.venv\\lib\\site-packages (from requests->transformers) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\interpreters\\python\\projects\\ai_forensics\\.venv\\lib\\site-packages (from requests->transformers) (2025.4.26)\n",
      "Requirement already satisfied: executing>=1.2.0 in d:\\interpreters\\python\\projects\\ai_forensics\\.venv\\lib\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (2.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in d:\\interpreters\\python\\projects\\ai_forensics\\.venv\\lib\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in d:\\interpreters\\python\\projects\\ai_forensics\\.venv\\lib\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (0.2.3)\n",
      "Downloading ipywidgets-8.1.7-py3-none-any.whl (139 kB)\n",
      "Downloading jupyterlab_widgets-3.0.15-py3-none-any.whl (216 kB)\n",
      "Downloading widgetsnbextension-4.0.14-py3-none-any.whl (2.2 MB)\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.2/2.2 MB 30.7 MB/s eta 0:00:00\n",
      "Installing collected packages: widgetsnbextension, jupyterlab_widgets, ipywidgets\n",
      "\n",
      "   ------------- -------------------------- 1/3 [jupyterlab_widgets]\n",
      "   -------------------------- ------------- 2/3 [ipywidgets]\n",
      "   -------------------------- ------------- 2/3 [ipywidgets]\n",
      "   -------------------------- ------------- 2/3 [ipywidgets]\n",
      "   -------------------------- ------------- 2/3 [ipywidgets]\n",
      "   -------------------------- ------------- 2/3 [ipywidgets]\n",
      "   -------------------------- ------------- 2/3 [ipywidgets]\n",
      "   -------------------------- ------------- 2/3 [ipywidgets]\n",
      "   -------------------------- ------------- 2/3 [ipywidgets]\n",
      "   -------------------------- ------------- 2/3 [ipywidgets]\n",
      "   ---------------------------------------- 3/3 [ipywidgets]\n",
      "\n",
      "Successfully installed ipywidgets-8.1.7 jupyterlab_widgets-3.0.15 widgetsnbextension-4.0.14\n"
     ]
    }
   ],
   "source": [
    "!pip install torch transformers pillow scikit-learn pathlib matplotlib pandas ipywidgets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba0588c5",
   "metadata": {},
   "source": [
    "# Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a9e70737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ All modules imported successfully\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CELL 1: IMPORTS AND SETUP\n",
    "# ============================================================================\n",
    "\n",
    "import torch\n",
    "import os\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "import json\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from pathlib import Path\n",
    "import logging\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, HTML\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"✓ All modules imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6f0d77",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3b939ef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration loaded:\n",
      "  reference_folder: ../datasets/images/face/reference_images\n",
      "  gallery_folder: ../datasets/images/face/gallery\n",
      "  output_folder: /..datasets/images/face/matched_images\n",
      "  similarity_threshold: 0.7\n",
      "  max_matches: None\n",
      "  model_name: openai/clip-vit-base-patch32\n",
      "  show_progress: True\n",
      "  create_visualizations: True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\scott\\\\OneDrive\\\\Documents\\\\Protocols\\\\Python\\\\PyCharm\\\\workspaces\\\\pycharm_windows\\\\AI_Projects\\\\ai_cyberforensics\\\\object_detection'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CELL 2: CONFIGURATION\n",
    "# ============================================================================\n",
    "\n",
    "# CONFIGURATION - MODIFY THESE PATHS FOR YOUR CASE\n",
    "CONFIG = {\n",
    "    'reference_folder': '../datasets/images/face/reference_images',      # Folder with 3-4 reference images\n",
    "    'gallery_folder': '../datasets/images/face/gallery',          # Folder with gallery images to search\n",
    "    'output_folder': '/..datasets/images/face/matched_images',          # Output folder for matches\n",
    "    'similarity_threshold': 0.70,                 # Similarity threshold (0.6-0.8 typical)\n",
    "    'max_matches': None,                          # Maximum matches to find (None = unlimited)\n",
    "    'model_name': 'openai/clip-vit-base-patch32', # CLIP model to use\n",
    "    'show_progress': True,                        # Show progress bars\n",
    "    'create_visualizations': True                 # Create match visualizations\n",
    "}\n",
    "\n",
    "print(\"Configuration loaded:\")\n",
    "for key, value in CONFIG.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714edb06",
   "metadata": {},
   "source": [
    "# Module: ForensicImageProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ec13851a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELL 3: CORE CLASSES AND FUNCTIONS\n",
    "# ============================================================================\n",
    "\n",
    "class ForensicImageProcessor:\n",
    "    \"\"\"Core image processing functionality\"\"\"\n",
    "    \n",
    "    def __init__(self, model_name=\"openai/clip-vit-base-patch32\"):\n",
    "        self.model_name = model_name\n",
    "        self.model = None\n",
    "        self.processor = None\n",
    "        \n",
    "    def load_model(self):\n",
    "        \"\"\"Load CLIP model and processor\"\"\"\n",
    "        print(\"Loading CLIP model...\")\n",
    "        self.model = CLIPModel.from_pretrained(self.model_name)\n",
    "        self.processor = CLIPProcessor.from_pretrained(self.model_name)\n",
    "        self.model.eval()\n",
    "        print(\"✓ CLIP model loaded successfully\")\n",
    "        \n",
    "    def generate_embedding(self, image_path):\n",
    "        \"\"\"Generate CLIP embedding for a single image\"\"\"\n",
    "        try:\n",
    "            image = Image.open(image_path).convert('RGB')\n",
    "            inputs = self.processor(images=image, return_tensors=\"pt\")\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                embeddings = self.model.get_image_features(**inputs)\n",
    "                embeddings = embeddings / embeddings.norm(dim=-1, keepdim=True)\n",
    "            \n",
    "            return embeddings.numpy().flatten()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {image_path}: {str(e)}\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45c1825",
   "metadata": {},
   "source": [
    "# Module: ReferenceManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "31dffa67",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReferenceManager:\n",
    "    \"\"\"Manages reference suspect images\"\"\"\n",
    "    \n",
    "    def __init__(self, processor):\n",
    "        self.processor = processor\n",
    "        self.embeddings = []\n",
    "        self.image_paths = []\n",
    "        self.valid_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.tif'}\n",
    "        \n",
    "    def load_references(self, reference_folder):\n",
    "        \"\"\"Load and process 3-4 reference images\"\"\"\n",
    "        print(f\"Loading reference images from: {reference_folder}\")\n",
    "        \n",
    "        # Find reference files\n",
    "        reference_files = []\n",
    "        for file_path in Path(reference_folder).iterdir():\n",
    "            if file_path.suffix.lower() in self.valid_extensions:\n",
    "                reference_files.append(file_path)\n",
    "        \n",
    "        if len(reference_files) < 3:\n",
    "            raise ValueError(f\"Need at least 3 reference images. Found {len(reference_files)}\")\n",
    "        \n",
    "        if len(reference_files) > 4:\n",
    "            print(f\"Found {len(reference_files)} images. Using first 4 for reference.\")\n",
    "            reference_files = reference_files[:4]\n",
    "        \n",
    "        # Process reference images\n",
    "        self.embeddings = []\n",
    "        self.image_paths = []\n",
    "        \n",
    "        for ref_path in tqdm(reference_files, desc=\"Processing references\"):\n",
    "            embedding = self.processor.generate_embedding(str(ref_path))\n",
    "            \n",
    "            if embedding is not None:\n",
    "                self.embeddings.append(embedding)\n",
    "                self.image_paths.append(str(ref_path))\n",
    "                print(f\"✓ Processed: {ref_path.name}\")\n",
    "            else:\n",
    "                print(f\"✗ Failed: {ref_path.name}\")\n",
    "        \n",
    "        if len(self.embeddings) == 0:\n",
    "            raise ValueError(\"No reference images could be processed\")\n",
    "        \n",
    "        # Stack embeddings\n",
    "        self.embeddings = np.vstack(self.embeddings)\n",
    "        print(f\"✓ Loaded {len(self.image_paths)} reference images\")\n",
    "        \n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def show_references(self):\n",
    "        \"\"\"Display reference images\"\"\"\n",
    "        if not self.image_paths:\n",
    "            print(\"No reference images loaded\")\n",
    "            return\n",
    "            \n",
    "        fig, axes = plt.subplots(1, len(self.image_paths), figsize=(15, 4))\n",
    "        if len(self.image_paths) == 1:\n",
    "            axes = [axes]\n",
    "            \n",
    "        for i, img_path in enumerate(self.image_paths):\n",
    "            img = Image.open(img_path)\n",
    "            axes[i].imshow(img)\n",
    "            axes[i].set_title(f\"Reference {i+1}\\n{Path(img_path).name}\")\n",
    "            axes[i].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a305f7",
   "metadata": {},
   "source": [
    "# Module: GallerySearcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c33e29c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GallerySearcher:\n",
    "    \"\"\"Searches through gallery images for matches\"\"\"\n",
    "    \n",
    "    def __init__(self, processor, reference_manager):\n",
    "        self.processor = processor\n",
    "        self.reference_manager = reference_manager\n",
    "        self.valid_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.tif'}\n",
    "        \n",
    "    def find_gallery_images(self, gallery_folder):\n",
    "        \"\"\"Find all images in gallery folder\"\"\"\n",
    "        gallery_images = []\n",
    "        for root, dirs, files in os.walk(gallery_folder):\n",
    "            for file in files:\n",
    "                if Path(file).suffix.lower() in self.valid_extensions:\n",
    "                    gallery_images.append(os.path.join(root, file))\n",
    "        return gallery_images\n",
    "    \n",
    "    def search_gallery(self, gallery_folder, similarity_threshold=0.70, max_matches=None):\n",
    "        \"\"\"Search gallery for similar images\"\"\"\n",
    "        print(f\"Searching gallery: {gallery_folder}\")\n",
    "        print(f\"Similarity threshold: {similarity_threshold}\")\n",
    "        \n",
    "        # Find gallery images\n",
    "        gallery_images = self.find_gallery_images(gallery_folder)\n",
    "        print(f\"Found {len(gallery_images)} images in gallery\")\n",
    "        \n",
    "        if len(gallery_images) == 0:\n",
    "            print(\"No images found in gallery!\")\n",
    "            return []\n",
    "        \n",
    "        # Search for matches\n",
    "        matches = []\n",
    "        \n",
    "        progress_bar = tqdm(gallery_images, desc=\"Searching gallery\") if CONFIG['show_progress'] else gallery_images\n",
    "        \n",
    "        for gallery_image_path in progress_bar:\n",
    "            # Generate embedding\n",
    "            gallery_embedding = self.processor.generate_embedding(gallery_image_path)\n",
    "            \n",
    "            if gallery_embedding is None:\n",
    "                continue\n",
    "            \n",
    "            # Calculate similarities with all references\n",
    "            similarities = cosine_similarity(\n",
    "                gallery_embedding.reshape(1, -1), \n",
    "                self.reference_manager.embeddings\n",
    "            )[0]\n",
    "            \n",
    "            # Check if any similarity exceeds threshold\n",
    "            max_similarity = np.max(similarities)\n",
    "            best_reference_idx = np.argmax(similarities)\n",
    "            \n",
    "            if max_similarity >= similarity_threshold:\n",
    "                match_info = {\n",
    "                    'gallery_image': gallery_image_path,\n",
    "                    'similarity_score': float(max_similarity),\n",
    "                    'best_reference_match': self.reference_manager.image_paths[best_reference_idx],\n",
    "                    'all_similarities': [float(s) for s in similarities],\n",
    "                    'timestamp': datetime.now().isoformat()\n",
    "                }\n",
    "                matches.append(match_info)\n",
    "                \n",
    "                # Only call set_postfix if using tqdm\n",
    "                if CONFIG['show_progress'] and hasattr(progress_bar, \"set_postfix\"):\n",
    "                    progress_bar.set_postfix({'matches': len(matches)})\n",
    "            \n",
    "            # Stop if max matches reached\n",
    "            if max_matches and len(matches) >= max_matches:\n",
    "                break\n",
    "        \n",
    "        print(f\"✓ Found {len(matches)} matches\")\n",
    "        return matches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2049655e",
   "metadata": {},
   "source": [
    "# Module: ResultsManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "811a1454",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResultsManager:\n",
    "    \"\"\"Manages search results and creates outputs\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "        \n",
    "    def copy_matches(self, matches, output_folder):\n",
    "        \"\"\"Copy matched images to output folder\"\"\"\n",
    "        if not matches:\n",
    "            print(\"No matches to copy\")\n",
    "            return []\n",
    "        \n",
    "        # Create output folder\n",
    "        output_path = Path(output_folder)\n",
    "        output_path.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        copied_matches = []\n",
    "        \n",
    "        print(f\"Copying {len(matches)} matches to {output_folder}\")\n",
    "        \n",
    "        for match in tqdm(matches, desc=\"Copying matches\"):\n",
    "            try:\n",
    "                # Generate output filename with similarity score\n",
    "                original_name = Path(match['gallery_image']).stem\n",
    "                extension = Path(match['gallery_image']).suffix\n",
    "                similarity = match['similarity_score']\n",
    "                output_filename = f\"{original_name}_sim{similarity:.3f}{extension}\"\n",
    "                output_file_path = output_path / output_filename\n",
    "                \n",
    "                # Copy file\n",
    "                shutil.copy2(match['gallery_image'], output_file_path)\n",
    "                \n",
    "                # Update match info\n",
    "                match['output_path'] = str(output_file_path)\n",
    "                match['output_filename'] = output_filename\n",
    "                copied_matches.append(match)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Failed to copy {match['gallery_image']}: {str(e)}\")\n",
    "        \n",
    "        print(f\"✓ Copied {len(copied_matches)} matches successfully\")\n",
    "        return copied_matches\n",
    "    \n",
    "    def save_report(self, matches, output_folder, config):\n",
    "        \"\"\"Save analysis report as JSON\"\"\"\n",
    "        output_path = Path(output_folder)\n",
    "        metadata_folder = output_path / \"analysis_metadata\"\n",
    "        metadata_folder.mkdir(exist_ok=True)\n",
    "        \n",
    "        report_file = metadata_folder / f\"analysis_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"\n",
    "        \n",
    "        analysis_report = {\n",
    "            'analysis_metadata': {\n",
    "                'timestamp': datetime.now().isoformat(),\n",
    "                'configuration': config,\n",
    "                'total_matches': len(matches)\n",
    "            },\n",
    "            'matches': matches\n",
    "        }\n",
    "        \n",
    "        with open(report_file, 'w') as f:\n",
    "            json.dump(analysis_report, f, indent=2)\n",
    "        \n",
    "        print(f\"✓ Report saved: {report_file}\")\n",
    "        return str(report_file)\n",
    "    \n",
    "    def show_matches_summary(self, matches):\n",
    "        \"\"\"Display summary of matches\"\"\"\n",
    "        if not matches:\n",
    "            print(\"No matches found\")\n",
    "            return\n",
    "        \n",
    "        # Create summary DataFrame\n",
    "        summary_data = []\n",
    "        for match in matches:\n",
    "            summary_data.append({\n",
    "                'Image': Path(match['gallery_image']).name,\n",
    "                'Similarity': f\"{match['similarity_score']:.3f}\",\n",
    "                'Best_Reference': Path(match['best_reference_match']).name,\n",
    "                'Output_File': match.get('output_filename', 'Not copied')\n",
    "            })\n",
    "        \n",
    "        df = pd.DataFrame(summary_data)\n",
    "        df = df.sort_values('Similarity', ascending=False).reset_index(drop=True)\n",
    "        \n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"MATCH SUMMARY - {len(matches)} matches found\")\n",
    "        print(f\"{'='*60}\")\n",
    "        display(df)\n",
    "        \n",
    "    def show_top_matches(self, matches, top_n=5):\n",
    "        \"\"\"Visualize top matches\"\"\"\n",
    "        if not matches or not CONFIG['create_visualizations']:\n",
    "            return\n",
    "            \n",
    "        # Sort by similarity\n",
    "        sorted_matches = sorted(matches, key=lambda x: x['similarity_score'], reverse=True)\n",
    "        top_matches = sorted_matches[:min(top_n, len(sorted_matches))]\n",
    "        \n",
    "        if not top_matches:\n",
    "            return\n",
    "        \n",
    "        print(f\"\\nTop {len(top_matches)} Matches:\")\n",
    "        \n",
    "        fig, axes = plt.subplots(2, len(top_matches), figsize=(15, 8))\n",
    "        if len(top_matches) == 1:\n",
    "            axes = axes.reshape(2, 1)\n",
    "        \n",
    "        for i, match in enumerate(top_matches):\n",
    "            # Show gallery image (top row)\n",
    "            gallery_img = Image.open(match['gallery_image'])\n",
    "            axes[0, i].imshow(gallery_img)\n",
    "            axes[0, i].set_title(f\"Match {i+1}\\nSim: {match['similarity_score']:.3f}\")\n",
    "            axes[0, i].axis('off')\n",
    "            \n",
    "            # Show best reference match (bottom row)\n",
    "            ref_img = Image.open(match['best_reference_match'])\n",
    "            axes[1, i].imshow(ref_img)\n",
    "            axes[1, i].set_title(f\"Reference\\n{Path(match['best_reference_match']).name}\")\n",
    "            axes[1, i].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "86a9b23a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing forensic image matching system...\n",
      "Loading CLIP model...\n",
      "✓ CLIP model loaded successfully\n",
      "✓ System initialized successfully\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CELL 4: INITIALIZE SYSTEM\n",
    "# ============================================================================\n",
    "\n",
    "# Initialize components\n",
    "print(\"Initializing forensic image matching system...\")\n",
    "processor = ForensicImageProcessor(CONFIG['model_name'])\n",
    "processor.load_model()\n",
    "\n",
    "reference_manager = ReferenceManager(processor)\n",
    "searcher = GallerySearcher(processor, reference_manager)\n",
    "results_manager = ResultsManager()\n",
    "\n",
    "print(\"✓ System initialized successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "34b4111d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function tqdm.__del__ at 0x0000018B2B585620>\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Interpreters\\Python\\Projects\\ai_forensics\\.venv\\Lib\\site-packages\\tqdm\\std.py\", line 1148, in __del__\n",
      "    self.close()\n",
      "  File \"d:\\Interpreters\\Python\\Projects\\ai_forensics\\.venv\\Lib\\site-packages\\tqdm\\notebook.py\", line 279, in close\n",
      "    self.disp(bar_style='danger', check_delay=False)\n",
      "    ^^^^^^^^^\n",
      "AttributeError: 'tqdm_notebook' object has no attribute 'disp'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading reference images from: ../datasets/images/face/reference_images\n",
      "Found 6 images. Using first 4 for reference.\n",
      "Error loading references: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "Please check your reference folder path and ensure it contains 3-4 images\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CELL 5: LOAD REFERENCE IMAGES\n",
    "# ============================================================================\n",
    "\n",
    "# Load reference images\n",
    "try:\n",
    "    num_references = reference_manager.load_references(CONFIG['reference_folder'])\n",
    "    print(f\"\\n✓ Loaded {num_references} reference images\")\n",
    "    \n",
    "    # Display reference images\n",
    "    if CONFIG['create_visualizations']:\n",
    "        reference_manager.show_references()\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Error loading references: {e}\")\n",
    "    print(\"Please check your reference folder path and ensure it contains 3-4 images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7da1d3e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function tqdm.__del__ at 0x0000018B2B585620>\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Interpreters\\Python\\Projects\\ai_forensics\\.venv\\Lib\\site-packages\\tqdm\\std.py\", line 1148, in __del__\n",
      "    self.close()\n",
      "  File \"d:\\Interpreters\\Python\\Projects\\ai_forensics\\.venv\\Lib\\site-packages\\tqdm\\notebook.py\", line 279, in close\n",
      "    self.disp(bar_style='danger', check_delay=False)\n",
      "    ^^^^^^^^^\n",
      "AttributeError: 'tqdm_notebook' object has no attribute 'disp'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching gallery: ../datasets/images/face/gallery\n",
      "Similarity threshold: 0.7\n",
      "Found 130 images in gallery\n",
      "Error during gallery search: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CELL 6: SEARCH GALLERY\n",
    "# ============================================================================\n",
    "\n",
    "# Search gallery for matches\n",
    "try:\n",
    "    matches = searcher.search_gallery(\n",
    "        gallery_folder=CONFIG['gallery_folder'],\n",
    "        similarity_threshold=CONFIG['similarity_threshold'],\n",
    "        max_matches=CONFIG['max_matches']\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n✓ Search complete: {len(matches)} matches found\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error during gallery search: {e}\")\n",
    "    matches = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0d98443c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "No matches found. Consider:\n",
      "- Lowering similarity threshold\n",
      "- Checking image quality\n",
      "- Verifying gallery folder path\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CELL 7: PROCESS RESULTS\n",
    "# ============================================================================\n",
    "\n",
    "if matches:\n",
    "    # Copy matches to output folder\n",
    "    copied_matches = results_manager.copy_matches(matches, CONFIG['output_folder'])\n",
    "    \n",
    "    # Save analysis report\n",
    "    report_file = results_manager.save_report(copied_matches, CONFIG['output_folder'], CONFIG)\n",
    "    \n",
    "    # Show results summary\n",
    "    results_manager.show_matches_summary(copied_matches)\n",
    "    \n",
    "    # Show visualizations of top matches\n",
    "    if CONFIG['create_visualizations']:\n",
    "        results_manager.show_top_matches(copied_matches, top_n=5)\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"ANALYSIS COMPLETE\")\n",
    "    print(f\"✓ {len(copied_matches)} matches copied to: {CONFIG['output_folder']}\")\n",
    "    print(f\"✓ Report saved: {report_file}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "else:\n",
    "    print(\"\\nNo matches found. Consider:\")\n",
    "    print(\"- Lowering similarity threshold\")\n",
    "    print(\"- Checking image quality\")\n",
    "    print(\"- Verifying gallery folder path\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "04836a6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "NOTEBOOK SETUP COMPLETE\n",
      "============================================================\n",
      "You can now:\n",
      "1. Modify CONFIG and re-run cells 5-7\n",
      "2. Use analyze_with_threshold() for quick tests\n",
      "3. Run individual components as needed\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CELL 8: INTERACTIVE ANALYSIS (OPTIONAL)\n",
    "# ============================================================================\n",
    "\n",
    "def analyze_with_threshold(threshold):\n",
    "    \"\"\"Quick analysis with different threshold\"\"\"\n",
    "    print(f\"Analyzing with threshold: {threshold}\")\n",
    "    \n",
    "    new_matches = searcher.search_gallery(\n",
    "        gallery_folder=CONFIG['gallery_folder'],\n",
    "        similarity_threshold=threshold,\n",
    "        max_matches=20  # Limit for quick analysis\n",
    "    )\n",
    "    \n",
    "    print(f\"Found {len(new_matches)} matches with threshold {threshold}\")\n",
    "    \n",
    "    if new_matches:\n",
    "        # Quick summary\n",
    "        similarities = [m['similarity_score'] for m in new_matches]\n",
    "        print(f\"Similarity range: {min(similarities):.3f} - {max(similarities):.3f}\")\n",
    "        \n",
    "        # Show top 3\n",
    "        if CONFIG['create_visualizations']:\n",
    "            results_manager.show_top_matches(new_matches, top_n=3)\n",
    "    \n",
    "    return new_matches\n",
    "\n",
    "# Example usage - uncomment to use:\n",
    "# test_matches_high = analyze_with_threshold(0.80)  # High confidence\n",
    "# test_matches_med = analyze_with_threshold(0.65)   # Medium confidence\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"NOTEBOOK SETUP COMPLETE\")\n",
    "print(\"=\"*60)\n",
    "print(\"You can now:\")\n",
    "print(\"1. Modify CONFIG and re-run cells 5-7\")\n",
    "print(\"2. Use analyze_with_threshold() for quick tests\")\n",
    "print(\"3. Run individual components as needed\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
