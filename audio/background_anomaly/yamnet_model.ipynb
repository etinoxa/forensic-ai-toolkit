{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\"\"\"\n",
    "Background Sound Event Timeline with YAMNet (local)\n",
    "---------------------------------------------------\n",
    "- Loads a single audio file (any common format) and converts it to 16 kHz mono\n",
    "- Runs YAMNet to get frame-wise event probabilities (~0.96 s per frame)\n",
    "- (Optional) suppresses frames dominated by 'Speech' so you focus on background\n",
    "- Groups contiguous frames of the same top event into segments\n",
    "- Exports a CSV: start_sec, end_sec, label, max_prob\n",
    "- (Optional) plots a simple timeline of top-K events over time\n",
    "\n",
    "Requirements:\n",
    "  pip install tensorflow tensorflow-hub librosa soundfile numpy pandas matplotlib imageio-ffmpeg\n",
    "\"\"\"\n",
    "\n",
    "from pathlib import Path\n",
    "import subprocess, tempfile, math, csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio_ffmpeg as ffmpegio\n",
    "\n",
    "# ----------------------------\n",
    "# HARD-CODED PARAMETERS\n",
    "# ----------------------------\n",
    "AUDIO_PATH = Path(\"../../datasets/audio/Voice 250810_182638.m4a\")  # any format (.wav, .mp3, .m4a, .flac, .ogg)\n",
    "OUTPUT_CSV = Path(\"yamnet_event_timeline.csv\")\n",
    "\n",
    "TARGET_SR = 16000\n",
    "TOP_K = 3                 # keep top-K classes per frame (for optional plotting)\n",
    "EVENT_THRESHOLD = 0.35    # minimum probability to accept an event frame\n",
    "SUPPRESS_SPEECH = True    # drop frames where 'Speech' prob >= this threshold\n",
    "SPEECH_THRESH = 0.50\n",
    "PLOT_TIMELINE = True\n",
    "\n",
    "# ----------------------------\n",
    "# Utility: convert any format to temp WAV 16k mono (venv FFmpeg)\n",
    "# ----------------------------\n",
    "FFMPEG_BIN = ffmpegio.get_ffmpeg_exe()\n",
    "\n",
    "def to_temp_wav_16k_mono(src: Path) -> Path:\n",
    "    tmpdir = Path(tempfile.mkdtemp(prefix=\"yamnet_\"))\n",
    "    dst = tmpdir / (src.stem + \"_16k_mono.wav\")\n",
    "    cmd = [FFMPEG_BIN, \"-y\", \"-loglevel\", \"error\", \"-i\", str(src), \"-ar\", str(TARGET_SR), \"-ac\", \"1\", str(dst)]\n",
    "    subprocess.run(cmd, check=True)\n",
    "    return dst\n",
    "\n",
    "# ----------------------------\n",
    "# Load YAMNet model and labels\n",
    "# ----------------------------\n",
    "# Model from TF Hub: https://tfhub.dev/google/yamnet/1\n",
    "yamnet = hub.load(\"https://tfhub.dev/google/yamnet/1\")\n",
    "# Class map CSV (included in the model assets)\n",
    "labels_path = yamnet.assets[\"yamnet_class_map.csv\"].numpy().decode(\"utf-8\")\n",
    "# Read labels\n",
    "class_names = []\n",
    "with tf.io.gfile.GFile(labels_path) as f:\n",
    "    reader = csv.reader(f)\n",
    "    next(reader)  # skip header: display_name, mid\n",
    "    for row in reader:\n",
    "        class_names.append(row[0])\n",
    "\n",
    "# Find the 'Speech' class index (for suppression)\n",
    "try:\n",
    "    SPEECH_IDX = class_names.index(\"Speech\")\n",
    "except ValueError:\n",
    "    SPEECH_IDX = None\n",
    "\n",
    "# ----------------------------\n",
    "# Load audio (16 kHz mono)\n",
    "# ----------------------------\n",
    "wav16_path = to_temp_wav_16k_mono(AUDIO_PATH)\n",
    "wav, sr = librosa.load(wav16_path, sr=TARGET_SR, mono=True)\n",
    "wav = wav.astype(np.float32)\n",
    "\n",
    "# ----------------------------\n",
    "# Inference\n",
    "# ----------------------------\n",
    "# YAMNet expects mono float32 16 kHz waveform. It returns (scores, embeddings, spectrogram)\n",
    "scores, embeddings, spectrogram = yamnet(wav)\n",
    "\n",
    "# Convert to numpy\n",
    "scores_np = scores.numpy()             # shape: [num_frames, 521]\n",
    "num_frames, num_classes = scores_np.shape\n",
    "frame_hop_seconds = 0.48               # YAMNet hop ~0.48s; each frame covers ~0.96s\n",
    "frame_win_seconds = 0.96\n",
    "\n",
    "# Optional: drop frames dominated by 'Speech'\n",
    "if SUPPRESS_SPEECH and SPEECH_IDX is not None:\n",
    "    mask = scores_np[:, SPEECH_IDX] < SPEECH_THRESH\n",
    "    # If you drop frames, you also need their time indices. We'll keep all frames\n",
    "    # but mark speech-dominated frames as 'no event' by zeroing their scores.\n",
    "    scores_np = scores_np * mask[:, None].astype(np.float32)\n",
    "\n",
    "# ----------------------------\n",
    "# Build per-frame top class and time mapping\n",
    "# ----------------------------\n",
    "top_class_idx = scores_np.argmax(axis=1)\n",
    "top_class_prob = scores_np.max(axis=1)\n",
    "\n",
    "# Time helpers\n",
    "frame_starts = np.arange(num_frames) * frame_hop_seconds\n",
    "frame_ends = frame_starts + frame_win_seconds\n",
    "\n",
    "# ----------------------------\n",
    "# Segmenting: group contiguous frames where top event label is the same and >= threshold\n",
    "# ----------------------------\n",
    "segments = []\n",
    "if num_frames > 0:\n",
    "    current_idx = None\n",
    "    current_start = None\n",
    "    current_max_prob = 0.0\n",
    "\n",
    "    for i in range(num_frames):\n",
    "        label_idx = int(top_class_idx[i])\n",
    "        prob = float(top_class_prob[i])\n",
    "\n",
    "        # If below threshold, treat as \"no event\"\n",
    "        if prob < EVENT_THRESHOLD:\n",
    "            label_idx = -1  # no event\n",
    "\n",
    "        if current_idx is None:\n",
    "            # start new segment if label valid\n",
    "            if label_idx != -1:\n",
    "                current_idx = label_idx\n",
    "                current_start = frame_starts[i]\n",
    "                current_max_prob = prob\n",
    "            continue\n",
    "\n",
    "        if label_idx == current_idx:\n",
    "            # continue segment; update max prob\n",
    "            current_max_prob = max(current_max_prob, prob)\n",
    "        else:\n",
    "            # close previous if it was valid\n",
    "            if current_idx != -1:\n",
    "                seg_end = frame_ends[i - 1]\n",
    "                segments.append({\n",
    "                    \"start_sec\": round(float(current_start), 2),\n",
    "                    \"end_sec\": round(float(seg_end), 2),\n",
    "                    \"label\": class_names[current_idx],\n",
    "                    \"max_prob\": round(float(current_max_prob), 3),\n",
    "                })\n",
    "            # start new (or idle)\n",
    "            if label_idx != -1:\n",
    "                current_idx = label_idx\n",
    "                current_start = frame_starts[i]\n",
    "                current_max_prob = prob\n",
    "            else:\n",
    "                current_idx = None\n",
    "                current_start = None\n",
    "                current_max_prob = 0.0\n",
    "\n",
    "    # flush tail\n",
    "    if current_idx is not None and current_idx != -1:\n",
    "        seg_end = frame_ends[-1]\n",
    "        segments.append({\n",
    "            \"start_sec\": round(float(current_start), 2),\n",
    "            \"end_sec\": round(float(seg_end), 2),\n",
    "            \"label\": class_names[current_idx],\n",
    "            \"max_prob\": round(float(current_max_prob), 3),\n",
    "        })\n",
    "\n",
    "# ----------------------------\n",
    "# Save CSV\n",
    "# ----------------------------\n",
    "df = pd.DataFrame(segments, columns=[\"start_sec\", \"end_sec\", \"label\", \"max_prob\"])\n",
    "df.to_csv(OUTPUT_CSV, index=False)\n",
    "print(f\"Saved timeline with {len(df)} segments â†’ {OUTPUT_CSV}\")\n",
    "df.head(10)\n"
   ],
   "id": "72305862f828f56e"
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
